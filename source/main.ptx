<?xml version='1.0' encoding='utf-8'?>

<pretext xml:lang="en-US" xmlns:xi="http://www.w3.org/2001/XInclude">

  <docinfo>

    <!-- the other option is "long" which will produce an -->
    <!-- entire front matter section with more headings   -->
    <author-biographies length="short" />

    <!--
    <brandlogo url="http://abstract.pugetsound.edu" source="images/cover_aata_2014.png" />
    -->

    <!--
    <covers front="images/original-front-cover-aata.pdf"
            back="images/plain-back-cover-aata.pdf"/>
    -->

    <!-- Prefix to enhance Sage notebook contents -->
    <!--
    <initialism>AATA</initialism>
    -->

    <macros>
        <!-- Operators     -->
        \def\ann{\operatorname{ann}}
        \newcommand{\Ass}{\operatorname{Ass}}
        \def\Aut{\operatorname{Aut}}
        \def\can{{\mathrm {can}}}
        \def\char{\operatorname{char}}
        \def\cp{\operatorname{CharPoly}}
        \def\codim{\operatorname{codim}} 
        \def\coker{\operatorname{coker}}
        \DeclareMathOperator*{\colim}{colim} 
        \def\cont{\operatorname{cont}} 
        \def\diam{\operatorname{diam}} 
        \def\dm{\operatorname{dim}} 
        \DeclareMathOperator{\edim}{embdim} 
        \def\End{\operatorname{End}} 
        \def\eval{\operatorname{eval}} 
        \def\Ext{\operatorname{Ext}} 
        \def\Frac{\operatorname{Frac}}
        \def\Fun{\operatorname{Fun}}
        \def\Gal{\operatorname{Gal}}
        \def\gcd{\operatorname{gcd}}
        \newcommand{\GL}{\operatorname{GL}} 
        \newcommand{\ht}{\operatorname{height}} 
        \def\Hom{\operatorname{Hom}} 
        \def\id{\operatorname{id}} 
        \def\im{\operatorname{im}} 
        \def\Inn{\operatorname{Inn}}
        \def\ker{\operatorname{ker}}
        \def\lcm{\operatorname{lcm}} 
        \def\Mat{\operatorname{Mat}}
        \newcommand{\Min}{\operatorname{Min}}
        \def\mp{\operatorname{MinPoly}}
        \def\mSpec{\operatorname{mSpec}}
        \def\MSpec{\operatorname{MSpec}}
        \def\null{\operatorname{Nul}}
        \DeclareMathOperator{\ns}{nullspace}
        \newcommand{\opp}{\operatorname{opp}}
        \def\Orb{\operatorname{Orb}} 
        \def\Out{\operatorname{Out}}
        \def\Perm{\operatorname{Perm}}
        \def\ptstab{\operatorname{PtStab}} 
        \def\rad{\operatorname{rad}}
        \DeclareMathOperator{\range}{range}
        \def\rank{\operatorname{rank}}
        \def\res{\operatorname{res}}
        \def\setstab{\operatorname{SetStab}}
        \def\sign{{\operatorname{sign}}}
        \newcommand{\SL}{\operatorname{SL}}
        \def\Span{\operatorname{Span}}
        \def\Spec{\operatorname{Spec}}
        \def\Stab{\operatorname{Stab}} 
        \DeclareMathOperator{\Supp}{Supp}
        \def\Syl{\operatorname{Syl}}
        \def\Tor{\operatorname{Tor}}
        \def\trace{\operatorname{trace}}
        \def\uSpec{\operatorname{\underline{Spec}}}
        <!-- Categories     -->
        \newcommand{\Ob}{\mathrm{Ob}}
        \newcommand{\Set}{\mathbf{Set}}
        \newcommand{\Grp}{\mathbf{Grp}}
        \newcommand{\Ab}{\mathbf{Ab}}
        \newcommand{\Sgrp}{\mathbf{Sgrp}}
        \newcommand{\Ring}{\mathbf{Ring}} 
        \newcommand{\Fld}{\mathbf{Fld}}
        \newcommand{\cRing}{\mathbf{cRing}}
        \newcommand{\Mod}[1]{#1-\mathbf{Mod}} 
        \newcommand{\Cx}[1]{#1-\mathbf{Comp}} 
        \newcommand{\vs}[1]{#1-\mathbf{vect}}
        \newcommand{\Vs}[1]{#1-\mathbf{Vect}}
        \newcommand{\vsp}[1]{#1-\mathbf{vect}^+} 
        \newcommand{\Top}{\mathbf{Top}} 
        \newcommand{\Setp}{\mathbf{Set}_*} 
        \newcommand{\Alg}[1]{#1-\mathbf{Alg}} 
        \newcommand{\cAlg}[1]{#1-\mathbf{cAlg}} 
        \newcommand{\PO}{\mathbf{PO}}
        \newcommand{\Cont}{\mathrm{Cont}}
        \newcommand{\MaT}[1]{\mathbf{Mat}_{#1}}
        \newcommand{\Rep}[2]{\mathbf{Rep}_{#1}(#2)}
        <!-- Greek     -->
        \def\l{\lambda}
        \def\lx{\lambda_x}
        \newcommand{\a}{\alpha}
        \def\b{\beta}
        \def\d{\delta}
        \def\e{\varepsilon}
        \def\g{\gamma}
        \def\t{\theta}
        \def\s{\sigma}
        \def\z{\zeta}
        \def\vp{\varphi}
        <!-- Letters     -->
        <!-- MathBB     -->
        \newcommand{\A}{\mathbb{A}}
        \newcommand{\B}{\mathbb{B}}
        \newcommand{\C}{\mathbb{C}}
        \newcommand{\D}{\mathbb{D}}
        \newcommand{\E}{\mathbb{E}}
        \newcommand{\F}{\mathbb{F}}
        \newcommand{\G}{\mathbb{G}}
        \newcommand{\H}{\mathbb{H}}
        \newcommand{\I}{\mathbb{I}}
        \newcommand{\J}{\mathbb{J}}
        \newcommand{\K}{\mathbb{K}}
        \newcommand{\L}{\mathbb{L}} 
        \newcommand{\M}{\mathbb{M}}
        \newcommand{\N}{\mathbb{N}}
        \newcommand{\O}{\mathbb{O}}
        \newcommand{\P}{\mathbb{P}}
        \newcommand{\Q}{\mathbb{Q}} 
        \newcommand{\R}{\mathbb{R}} 
        \newcommand{\S}{\mathbb{S}}
        \newcommand{\T}{\mathbb{T}}
        \newcommand{\U}{\mathbb{U}}
        \newcommand{\V}{\mathbb{V}}
        \newcommand{\W}{\mathbb{W}}
        \newcommand{\X}{\mathbb{X}}
        \newcommand{\Y}{\mathbb{Y}}
        \newcommand{\Z}{\mathbb{Z}} 
        \newcommand{\ON}{\mathbb{ON}}
        <!-- MathCal     -->
        \def\cA{\mathcal A} 
        \def\cB{\mathcal B} 
        \def\cC{\mathcal C} 
        \def\cD{\mathcal D} 
        \def\cE{\mathcal E} 
        \def\cF{\mathcal F} 
        \def\cG{\mathcal G} 
        \def\cH{\mathcal H} 
        \def\cI{\mathcal I} 
        \def\cJ{\mathcal J} 
        \def\cK{\mathcal K} 
        \def\cL{\mathcal L}
        \def\cM{\mathcal M} 
        \def\cN{\mathcal N} 
        \def\cO{\mathcal O} 
        \def\cP{\mathcal P} 
        \def\cQ{\mathcal Q} 
        \def\cR{\mathcal R} 
        \def\cS{\mathcal S} 
        \def\cT{\mathcal T} 
        \def\cU{\mathcal U} 
        \def\cV{\mathcal V} 
        \def\cW{\mathcal W} 
        \def\cX{\mathcal X} 
        \def\cY{\mathcal Y} 
        \def\cZ{\mathcal Z} 
        <!-- MathFrak     -->
        \newcommand{\fa}{{\mathfrak a}} 
        \newcommand{\fb}{{\mathfrak b}} 
        \newcommand{\fc}{{\mathfrak c}} 
        \newcommand{\fd}{{\mathfrak d}} 
        \newcommand{\fe}{{\mathfrak e}}
        \newcommand{\fm}{{\mathfrak m}} 
        \newcommand{\fp}{{\mathfrak p}} 
        \newcommand{\fq}{{\mathfrak q}} 
        \newcommand{\fK}{{\mathfrak K}} 
        \newcommand{\fR}{{\mathfrak R}} 
        <!-- MathScr     -->
        \def\sA{\mathscr A} 
        \def\sB{\mathscr B} 
        \def\sC{\mathscr C} 
        \def\sD{\mathscr D} 
        \def\sE{\mathscr E} 
        \def\sF{\mathscr F} 
        \def\sG{\mathscr G} 
        \def\sH{\mathscr H} 
        \def\sI{\mathscr I} 
        \def\sJ{\mathscr J} 
        \def\sK{\mathscr K} 
        \def\sL{\mathscr L}
        \def\sM{\mathscr M}
        \def\sN{\mathscr N}
        \def\sO{\mathscr O}
        \def\sP{\mathscr P}
        \def\sQ{\mathscr Q}
        \def\sR{\mathscr R}
        \def\sS{\mathscr S}
        \def\sT{\mathscr T}
        \def\sU{\mathscr U}
        \def\sV{\mathscr V}
        \def\sW{\mathscr W}
        \def\sX{\mathscr X}
        \def\sY{\mathscr Y}
        \def\sZ{\mathscr Z}
        <!-- Tildes     -->
        \def\tS{\tilde{S}}
        <!-- Algebra     -->
        \def\sdp{\rtimes}
        \newcommand{\tensor}{\otimes} 
        \newcommand{\igen}[1]{\langle #1 \rangle} 
        \def\nsg{\unlhd} 
        \def\kval{{k-\mathrm{valued}}} 
        \def\kalg{{k-\mathrm{alg}}}
        \newcommand\GG[2]{\Gal(#1/#2)}
        <!-- Matrices     -->
        \newcommand{\MF}[3]{\Mat_{#1\times #2}(#3)}
        \newcommand{\vectwo}[2]{\begin{bmatrix} #1 \\ #2 \end{bmatrix}} 
        \newcommand{\vecthree}[3]{\begin{bmatrix} #1 \\ #2 \\ #3\end{bmatrix}} 
        \def\ob{{\mathfrak{ob}} }
        <!-- Misc     -->
        \def\qed{\square}
        \def\sse{\subseteq}
        \def\ss{\subset} 
        \def\ssne{\subsetneq}
        \def\sm{\setminus}
        \def\inv{^{-1}} 
        \newcommand{\es}{\emptyset} 
        \newcommand{\Zm}[1]{\Z/({#1})} 
        \def\ov#1{\overline{#1}} 
        \def\xdots{x_1, \dots, x_n} 
        \def\adots{a_1, \dots, a_n} 
        \def\bdots{b_1, \dots, b_n} 
        \def\udots{u_1, \dots, u_n} 
        \newcommand{\leg}[2]{\left(\frac{{#1}}{{#2}}\right)} 
        \def\th{^{th}} 
        \def\htpy{\simeq_{\mathrm{htpc}}} 
        <!-- Math Text     -->
        \def\textand{ \, \text{and} \, } 
        \def\textor{ \, \text{or} \, } 
        \def\textfor{ \, \text{for} \, } 
        \def\textfa{ \, \text{for all} \, } 
        \def\textst{ \, \text{such that} \, } 
        \def\textin{ \, \text{in} \, } 
        \def\fg{ \, \text{finitely generated} \, }
        \newcommand{\op}{\mathrm{op}}
        <!-- Arrows     -->
        \newcommand{\xra}[1]{\xrightarrow{#1}} 
        \newcommand{\xora}[1]{\xtwoheadrightarrow{#1}} 
        \newcommand{\xira}[1]{\xhookrightarrow{#1}} 
        \newcommand{\xla}[1]{\xleftarrow{#1}} 
        \def\lra{\longrightarrow}
        \def\into{\hookrightarrow}
        \def\onto{\twoheadrightarrow}
        <!-- Vectors     -->
        \newcommand{\vv}[1]{\mathbf{#1}}
        \newcommand{\lm}[2]{{#1}\,\l + {#2}\,\mu} 
        \renewcommand{\v}{\vv{v}}
        \renewcommand{\u}{\vv{u}}
        \newcommand{\w}{\vv{w}}
        \newcommand{\x}{\vv{x}}
        \renewcommand{\k}{\vv{k}}
        \newcommand{\0}{\vv{0}}
        \newcommand{\1}{\vv{1}}
        \newcommand{\vecs}[2]{#1_1,#1_2,\dots,#1_{#2}}
        \newcommand{\us}[1][n]{\vecs{\u}{#1}}
        \newcommand{\vs}[1][n]{\vecs{\v}{#1}}
        \newcommand{\ws}[1][n]{\vecs{\w}{#1}}
        \newcommand{\vps}[1][n']{\vecs{\v'}{#1}}
        \newcommand{\ls}[1][n]{\vecs{\l}{#1}}
        \newcommand{\mus}[1][n]{\vecs{\mu}{#1}} 
        \newcommand{\lps}[1][n]{\vecs{\l'}{#1}}
        \def\td{\tilde{\delta}}
        \def\oo{\overline{\omega}}
        \def\ctJ{\tilde{\mathcal J}}
        \def\tPhi{\tilde{\Phi}}
        \def\te{\tilde{e}}
        \def\M{\operatorname{M}}
        \newcommand{\homotopic}{\simeq}
        \newcommand{\homeq}{\cong}
        \newcommand{\iso}{\approx}
        \newcommand{\dual}{\vee} 
        \DeclarePairedDelimiter{\abs}{|}{|}
        \newcommand{\bv}{{\bar{v}}}
        \newcommand{\bu}{{\bar{u}}}
        \newcommand{\bw}{{\bar{w}}}
        \newcommand{\by}{{\bar{y}}}
        \newcommand{\ba}{{\bar{a}}}
        \newcommand{\bb}{{\bar{b}}}
        \newcommand{\bx}{{\bar{x}}}
        \DeclarePairedDelimiterX\setof[2]{\{}{\}}{#1\,|\,#2}
        \newcommand{\vx}{\underline{x}}
        \renewcommand{mod}[1]{\text{(mod }{#1})}
        \newcommand{\Slv}[3]{\sum_{{#2}=1}^{{#3}} {#1}_{{#2}} \v_{{#2}}}
    </macros>

    <!-- this is the default, but supresses a warning -->
    <cross-references text="type-global" />

    <!-- tikz package and libraries for images -->
    <latex-image-preamble>
    \usepackage{tikz}
    \usetikzlibrary{backgrounds}
    \usetikzlibrary{arrows,matrix}
    \usetikzlibrary{snakes}
    </latex-image-preamble>

    <rename element="insight">Structure</rename>  
    <rename element="inlineexercise">Exploration</rename>
    <rename element="exploration">Discussion</rename> 

  </docinfo>

  <book xml:id="compendium-theoretica"><title>Foundations of Advanced Mathematics</title>

    <frontmatter xml:id="frontmatter">

      <titlepage>
        <author>
          <personname>Sam Macdonald</personname>
          <department>Department of Mathematics</department>
          <institution>Univeristy of Nebraska -- Lincoln</institution>
        </author>
        <date>
          <today />
        </date>
      </titlepage>

      <colophon>

        <website>
          <name>
            <c>example.org</c>
          </name>
          <address>https://example.org</address>
        </website>

        <copyright>
          <year>2020<ndash />2023</year>
          <holder>You</holder>
          <shortlicense> 
            This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit <url href="http://creativecommons.org/licenses/by-sa/4.0/" visual="creativecommons.org/licenses/by-sa/4.0"> CreativeCommons.org</url>
          </shortlicense>
        </copyright>
      </colophon>

      <preface><title>How to Use This Book (*)</title>

        <p>
          Similarly to music and art, mathematics is learned by doing, not just by reading texts and listening to lectures. 
          Doing the exercises in this text is the best way to get a feel for the material, to see what you understand, and to identify what needs further study. 
          Exercises range from routine examples to rather tricky proofs. 
          The exercises have been arranged in order so that in the course of working on an exercise, you may use any previous theorem or exercise (whether or not you did it), but not any subsequent result (unless stated otherwise). 
          Some exercises are used in the text, and are so labeled.
        </p>
        

      </preface>

    </frontmatter>

    <part xml:id="foundations"><title>Foundations of Advanced Mathematics</title>

      <chapter xml:id="ch-logic"><title>Informal Logic</title>

        <introduction>
          <p>
            Logic is the framework upon which rigorous proofs are built. 
            Without some basic logical concepts, which we will study in this chapter, it would not be possible to structure proofs properly. 
            It will suffice for our purposes to approach these logical concepts informally (and briefly). 
            Though logic is the foundation of mathematical reasoning, it is important not to overemphasize the use of formal logic in mathematics. 
            Outside of the field of mathematical logic, proofs in mathematics almost never involve formal logic, nor do they generally involve logical symbols (although we will need such symbols in the present chapter).
          </p>

          <p>
            In this chapter, and throughout this text, we will use the basic properties of the integers, rational numbers and real numbers in some of our examples. 
            We will assume that the reader is informally familiar with these numbers. 
          </p>
        </introduction>

        <section xml:id="sec-statements"><title>Statements</title>

          <subsection xml:id="subsec-statements"><title>What is a Statement?</title>

            <blockquote>
              <p>
                <q>
                  Each of our acts makes a statement as to our purpose.
                </q>
              </p>
              <attribution>Leo Buscaglia</attribution>
            </blockquote>

            <p>
              When we prove theorems in mathematics, we are demonstrating the truth of certain statements. 
              We therefore need to start our discussion of logic with a look at statements, and at how we recognize certain statements as true or false.
            </p>
          
            <definition xml:id="def-statement">
              <statement>
                <p>
                  A <term>statement</term> is anything we can say, write or otherwise express that is either true or false.
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                We will be making two assumptions when dealing with statements: every statement is either true or false, and no statement is both true and false. 
                The first of these assumptions, often referred to as the Law of the Excluded Middle (and known formally as bivalence), may seem innocuous enough, but in fact some mathematicians have chosen to work without this powerful axiom.
              </p>
            </remark>

            <example><title>Statement Examples</title>
              <p>
                <ul>
                  <li>
                    <p>
                      <q>The sky is blue</q> is a statement, as it is either true or false.
                    </p>
                  </li>

                  <li>
                    <p>
                      <q>Your birthday is October 23rd</q> is a statement, as it is either your birtday or it isn't.
                    </p>
                  </li>

                  <li>
                    <p>
                      <q>The mitochondria is the powerhouse of the cell</q> is a statement.
                    </p>
                  </li>

                  <li>
                    <p>
                      <q>Do a backflip</q> is <em>not</em> a statement, because it cannot be said to be either true or false.
                    </p>
                  </li>
                </ul>
              </p>
            </example>

            <p>
              For something to be a statement, it has to be either true or false in principle; it does not matter whether we personally can verify its truth or falsity.
            </p>

          </subsection>

          <subsection xml:id="subsec-combining-statements"><title>Combining Statements</title>

            <blockquote>
              <p>
                <q>
                  Conjunction junction, what's your function?
                </q>
              </p>
              <attribution>Schoolhouse Rock</attribution>
            </blockquote>

            <p>
              What makes statements valuable for our purposes is that there are a number of useful ways of forming new statements out of old ones. 
              An analog to this would be the ways we have of combining numbers to get new ones, such as addition and multiplication; if we did not have these operations, then numbers would not be very interesting.
            </p>

            <p>
              In this section we will discuss five ways of forming new statements out of old ones, corresponding to the English expressions: and; or; not; if, then; if and only if. 
            </p>

            <definition xml:id="def-conjunction">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements.
                  The <term>conjunction</term> of <m>P</m> and <m>Q</m>, which is denoted <m>P \wedge   Q</m>, is the statement that, intuitively, is true if both <m>P</m> and <m>Q</m> are true, and is false otherwise.
                  We read <m>P \wedge   Q</m> as “<m>P</m> and <m>Q</m>.” The precise definition of <m>P \wedge   Q</m> is given by the “truth table” 
                </p>
              </statement>
            </definition>

            <example>
              <p>
                Let <m>P =</m> “it is raining today,” and let <m>Q =</m> “it is cold today.” 
                The statement <m>P \wedge   Q</m> would formally be “it is raining today and it is cold today.”
              </p>
            </example>

            <p>
              We could express the same idea more succinctly in English by saying “it is raining and cold today.” 
              In general, we will try to use statements that read well in English, as well as being logically correct.
            </p>

            <warning>
              <p>
                The colloquial use of the word “and” differs from the mathematical usage stated above. 
                The mathematical usage means the above truth table, and nothing else, while colloquially there are other meanings in addition to this one. 
                One source of confusion involving the word “and” that is well worth avoiding is the colloquial use of this word in the sense of “therefore.”
              </p>
            </warning>

            <definition xml:id="def-disjunction">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements.
                  The <term>disjunction</term> of <m>P</m> and <m>Q</m>, which is denoted <m>P \vee  Q</m>, is the statement that, intuitively, is true if either <m>P</m> is true or <m>Q</m> is true or both are true, and is false otherwise. 
                  We read <m>P \vee  Q</m> as “<m>P</m> or <m>Q</m>.” The precise definition of <m>P \vee  Q</m> is given by the truth table
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                The mathematical use of the word “or” always means an inclusive “or,” so that if “<m>P</m> or <m>Q</m>” is true, then either <m>P</m> is true, or <m>Q</m> is true, or both <m>P</m> and <m>Q</m> are true.
              </p>
            </remark>

            <example>
              <p>
                A simple example of a disjunction is the statement “my car is red or it will rain today.” 
                This statement has the form <m>P \vee  Q</m>, where <m>P =</m> “my car is red,” and <m>Q =</m> “it will rain today.” 
                The truth of this statement implies that at least one of the statements “my car is red” or “it will rain today” is true. 
                The only thing not allowed is that both “my car is red” and “it will rain today” are false.
              </p>
            </example>

            <definition xml:id="def-negation">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements.
                  The <term>negation</term> of <m>P</m>, which is denoted <m>¬P</m>, is the statement that, intuitively, is true if <m>P</m> is false, and is false if <m>P</m> is true. 
                  We read <m>¬P</m> as “not <m>P</m>.” 
                  The precise definition of <m>¬P</m> is given in the truth table
                </p>
              </statement>
            </definition>

            <definition xml:id="def-conditional">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements.
                  The <term>conditional</term> from <m>P</m> to <m>Q</m>, which is denoted <m>P \to  Q</m>, is the statement that, intuitively, is true if it is never the case that <m>P</m> is true and <m>Q</m> is false. 
                  We read <m>P \to Q</m> as if <q><m>P</m> then <m>Q</m></q>.
                  The precise definition of P \to  Q is given in the truth table
                </p>
              </statement>
            </definition>

            <example>
              <p>
                A simple example of a conditional statement is <q>if it rains today, then I will see a movie this evening.</q>
                This statement has the form <m>P \to Q</m>, where <m>P =</m> “it rains today,” and <m>Q =</m> “I will see a movie this evening.” 
                The truth of this statement does not say that it is raining today, nor that I will see a movie this evening.
                It only says what will happen if it rains today, which is that I will see a movie this evening. 
                If it does not rain, I still might see a movie this evening, or I might not; both of these possibilities would be consistent with the truth of the original statement “if it rains today, then I will see a movie this evening.”
              </p>
            </example>

            <convention>
              <p>
                There are a number of variations as to how to write the statement <m>P \to  Q</m> in English. 
                In addition to writing “if <m>P</m> then <m>Q</m>,” we could just as well write any of the following:
                <ul>
                  <li>
                    <p>
                      If <m>P</m>, <m>Q</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>Q</m> if <m>P</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>P</m> only if <m>Q</m>;
                    </p>
                  </li>
                  
                  <li>
                    <p>
                      <m>Q</m> provided that <m>P</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      Assuming that <m>P</m>, then <m>Q</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>Q</m> given that <m>P</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>P</m> is sufficient for <m>Q</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>Q</m> is necessary for <m>P</m>.
                    </p>
                  </li>
                </ul>
              </p>
            </convention>

            <definition xml:id="def-biconditional">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements.
                  The <term>biconditional</term> from <m>P</m> to <m>Q</m>, which is denoted <m>P ↔ Q</m>, is the statement that, intuitively, is true if <m>P</m> and <m>Q</m> are both true or both false, and is false otherwise. 
                  We read <m>P ↔ Q</m> as “<m>P</m> if and only if <m>Q</m>.” 
                  The phrase “if and only if” is often abbreviated as “iff.” 
                  The precise definition of <m>P ↔ Q</m> is given in the truth table
                </p>
              </statement>
            </definition>

            <example>
              <p>
                An example of a biconditional statement is “I will go for a walk if and only if Fred will join me.” 
                This statement has the form <m>P ↔ Q</m>, where <m>P =</m> “I will go for a walk,” and <m>Q =</m> “Fred will join me.” 
                The truth of this statement does not say that I will go for a walk, or that Fred will join me. 
                It says that either Fred will join me and I will go for a walk, or that neither of these things will happen. 
                In other words, it could not be the case that Fred joins me and yet I do not go for a walk, and it also could not be the case that I go for a walk, and yet Fred has not joined me.
              </p>
            </example>

            <convention>
              <p>
                There are some variations as to how to write the statement <m>P ↔ Q</m> in English. 
                In addition to writing “<m>P</m> if and only if <m>Q</m>,” it is common to write “<m>P</m> is necessary and sufficient for <m>Q</m>.”
              </p>
            </convention>

            <p>
              Rather than memorizing the truth tables, for many people it is easier to remember the rules summarized in <xref ref="table-operators"/>
            </p>

            <table xml:id="table-operators"><title>Logical Operators</title>
              <tabular>
                <row bottom="major">
                  <cell><term>Operator</term></cell> <cell><term>Symbolic Form</term></cell> <cell><term>Truth Values</term></cell>
                </row>

                <row>
                  <cell>Conjunction</cell> <cell><m>P\wedge Q</m></cell> <cell>True only when both <m>P</m> and <m>Q</m> are true.</cell>
                </row>

                <row>
                  <cell>Disjunction</cell> <cell><m>P\vee Q</m></cell> <cell>False only when both <m>P</m> and <m>Q</m> are false.</cell>
                </row>

                <row>
                  <cell>Negation</cell> <cell><m>\neg P</m></cell> <cell>Opposite truth value of <m>P</m></cell>
                </row>

                <row>
                  <cell>Conditional</cell> <cell><m>P\to Q</m></cell> <cell>False only when <m>P</m> is true and <m>Q</m> is false.</cell>
                </row>

                <row>
                  <cell>Biconditional</cell> <cell><m>P ↔ Q</m></cell> <cell>True when either both <m>P</m> and <m>Q</m> are true or when <m>P</m> and <m>Q</m> are false</cell>
                </row>
              </tabular>
            </table>

          </subsection>

          <subsection xml:id="subsec-tautology"><title>Tautologies and Contradictions</title>

            <blockquote>
              <p>
                <q>
                  Do I contradict myself? Very well, then, I contradict myself; I am large - I contain multitudes.
                </q>
              </p>
              <attribution>Walt Whitman</attribution>
            </blockquote>

            <definition xml:id="def-tautology">
              <statement>
                <p>
                  A <term>tautology</term> is a statement that is always true by logical necessity, regardless of whether the component statements are true or false, and regardless of what we happen to observe in the real world.
                </p>
              </statement>
            </definition>

            <example>
              <p>
                An example of a tautology is the statement “Irene has red hair or she does not have red hair.” 
                It seems intuitively clear that this statement is a tautology, and we can verify this fact formally by using truth tables. 
                Let <m>P =</m> “Irene has red hair.” 
                Then our purported tautology is the statement <m>P \vee  ¬P</m>. 
                The truth table for this statement is

                We see in column <m>3</m> that the statement <m>P \vee  ¬P</m> is always true, regardless of whether <m>P</m> is true or false. 
                This fact tells us that <m>P \vee  ¬P</m> is a tautology. 
                In general, a statement is a tautology if, as verified using a truth table, it is always true, regardless of whether its component statements are true or false.
              </p>
            </example>

            <definition xml:id="def-contradiction">
              <statement>
                <p>
                  A <term>contradiction</term> is a statement that is always false by logical necessity.
                </p>
              </statement>
            </definition>
            
            <example>
              <p>
                The statement “Irene has red hair and she does not have red hair” is a contradiction. 
                In symbols this statement is <m>P \wedge   ¬P</m>, and it has truth table


                The statement <m>P \wedge   ¬P</m> is always false, regardless of whether <m>P</m> is true or false. 
                In general, a statement is a contradiction if, as verified using a truth table, it is always false, regardless of whether its component statements are true or false.
              </p>
            </example>
          </subsection>

        </section>

        <section xml:id="sec-statement-relations"><title>Relations Between Statements</title>

          <introduction>
            <p>
              Up until now we have constructed statements; now we want to discuss relations between them.
              Relations between statements are not formal statements in themselves, but are “meta-statements” that we make about statements.
              The two types of such relations we will study, namely, implication and equivalence, are the meta-statement analogs of conditionals and biconditionals.
            </p>
          </introduction>

          <subsection xml:id="subsec-implication"><title>Implications</title>

            <blockquote>
              <p>
                <q>
                  Implication is thus the very texture of our web of belief, and logic is the theory that traces it.
                </q>
              </p>
              <attribution>Willard Van Orman Quine</attribution>
            </blockquote>

            <definition xml:id="def-implication">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements. 
                  We say that <m>P</m> <term>implies</term> <m>Q</m> if the statement <m>P \to  Q</m> is a tautology. 
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                We abbreviate the English expression “<m>P</m> implies <m>Q</m>” with the notation “<m>P ⇒ Q</m>.”
              </p>
            </convention>

            <p>
              The intuitive idea of logical implication is that statement <m>P</m> implies statement <m>Q</m> if necessarily <m>Q</m> is true whenever <m>P</m> is true. 
              In other words, it can never be the case that <m>P</m> is true and <m>Q</m> is false. 
              Necessity is the key here, because one statement implying another should not simply be a matter of coincidentally appropriate truth values.
            </p>

            <remark>
              <p>
                It is important to note the difference between the notations “<m>P ⇒ Q</m>” and “<m>P \to  Q</m>.” 
                The notation “<m>P \to  Q</m>” is a statement; it is a compound statement built up out of the statements <m>P</m> and <m>Q</m>. 
                The notation “<m>P ⇒ Q</m>” is a meta-statement, which is simply a shorthand way of writing the English expression “<m>P</m> implies <m>Q</m>,” and it means that <m>P \to  Q</m> is not just true in some particular instances, but is a tautology.
              </p>
            </remark>

            <p>
              It might appear at first glance as if we are not introducing anything new here, given that we are defining implication in terms of conditional statements, but there is a significant new idea in the present discussion, which is that we single out those situations where <m>P → Q</m> is not just a statement (which is always the case), but where <m>P → Q</m> is a tautology.
            </p>

            <p>
              In particular, the following implications will be used extensively.
            </p>

            <example xml:id="ex-implications"><title>Important Implications</title>
              <p>
                Let <m>P, Q, R</m> and <m>S</m> be statements.
                <ol>
                  <li xml:id="ident-modus-ponens"><title>Modus Ponens</title>
                    <p>
                       <m>(P \to  Q) \wedge   P ⇒ Q</m>
                    </p>
                  </li>

                  <li><title>Modus Tollens</title>
                    <p>
                      <m>(P \to  Q) \wedge   ¬Q ⇒ ¬P</m>
                    </p>
                  </li>

                  <li><title>Simplification</title>
                    <p>
                      <m>P \wedge   Q ⇒ P</m>
                    </p>
                  </li>

                  <li><title>Simplification</title>
                    <p>
                       <m>P \wedge   Q ⇒ Q</m>
                    </p>
                  </li>

                  <li><title>Addition</title>
                    <p>
                      <m>P ⇒ P \vee  Q</m>
                    </p>
                  </li>

                  <li><title>Addition</title>
                    <p>
                      <m>Q ⇒ P \vee  Q</m>
                    </p>
                  </li>

                  <li><title>Modus Tollendo Ponens</title> 
                    <p>
                      <m>(P \vee  Q) \wedge   ¬P ⇒ Q</m>
                    </p>
                  </li>

                  <li><title>Modus Tollendo Ponens</title> 
                    <p>
                      <m>(P \vee  Q) \wedge   ¬Q ⇒ P</m>
                    </p>
                  </li>

                  <li><title>Biconditional-Conditional</title>
                    <p>
                      <m>P ↔ Q ⇒ P \to  Q</m>
                    </p>
                  </li>

                  <li><title>Biconditional-Conditional</title>
                    <p>
                      <m>P ↔ Q ⇒ Q \to  P</m>
                    </p>
                  </li>

                  <li><title>Conditional-Biconditional</title>
                    <p>
                      <m>(P \to  Q) \wedge   (Q \to  P) ⇒ P ↔ Q</m>
                    </p>
                  </li>

                  <li><title>Hypothetical Syllogism</title>
                    <p>
                      <m>(P \to  Q) \wedge   (Q \to  R) ⇒ P \to  R</m>
                    </p>
                  </li>

                  <li><title>Constructive Dilemma</title>
                    <p>
                      <m>(P \to  Q) \wedge   (R \to  S) \wedge   (P \vee  R) ⇒ Q \vee  S</m>
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <p>
              The implications stated in <xref ref="ex-implications"/> were chosen because they are symbolic statements of various rules of valid argumentation.
            </p>

          </subsection>

          <subsection xml:id="subsec-equivalent-statements"><title>Equivalent Statements</title>

            <blockquote>
              <p>
                <q>
                  Too much may be the equivalent of none at all.
                </q>
              </p>
              <attribution>Lee Loevinger</attribution>
            </blockquote>

            <p>
              Logical implication is not always reversible.
            </p>

            <example>
              <p>
                Written in symbols, we saw that <m>¬(P → Q) ⇒ P ∨ Q</m>.
                On the other hand, the same truth tables used to establish this implication also show that <m>P ∨ Q</m> does not imply <m>¬(P → Q)</m>.
                For example, when P and Q are both true, then <m>P ∨ Q</m> is true, but <m>¬(P → Q)</m> is false. 
                Alternatively, it can be seen by a truth table that <m>(P ∨ Q) → [¬(P → Q)]</m> is not a tautology.
              </p>
            </example>

            <p>
              Some logical implications, however, are reversible. 
              Such implications are very convenient, and they convey the idea of logical equivalence, to which we now turn.
            </p>

            <definition xml:id="def-equivalent-statements">
              <statement>
                <p>
                  Let <m>P</m> and <m>Q</m> be statements. 
                  We say that <m>P</m> and <m>Q</m> are <term>equivalent</term> if the statement <m>P ↔ Q</m> is a tautology. 
                  We abbreviate the English expression “<m>P</m> and <m>Q</m> are equivalent” with the notation “<m>P ⇔ Q</m>.”
                </p>
              </statement>
            </definition>

            <p>
              The intuitive idea of equivalence of statements is that to claim that statements <m>P</m> and <m>Q</m> are equivalent means that necessarily <m>P</m> is true if and only if <m>Q</m> is true.
              Necessity is once again the key here.
            </p>

            <p>
              Such equivalences will allow us to find alternative forms of the statements of some theorems, and these alternative forms are sometimes easier to prove than the originals.
            </p>

            <remark>
              <p>
                Certainly, two different English sentences can convey equivalent statements, for example “if it rains I will stay home” and “I will stay home if it rains.” 
                These two statements are both English variants of <m>P → Q</m>, where <m>P = </m>“it rains,” and <m>Q = </m>“I will stay home.” 
                The difference between these two statements is an issue only of the flexibility of the English language; symbolically, these two statements are identical, not just equivalent.
              </p>
            </remark>

            <warning>
              <p>
                It is important to note the difference between the notations “<m>P ⇔ Q</m>” and “<m>P ↔ Q</m>.” 
                The latter is a statement, whereas the former is a meta-statement, which is simply a shorthand way of writing the English expression “<m>P</m> is equivalent to <m>Q</m>.”
              </p>
            </warning>

            <example xml:id="ident-double-negation"><title>Double Negation</title>
              <statement>
                <p>
                  <m>¬(¬P) ⇔ P</m>.
                </p>
              </statement>
            </example>

            <remark>
              <p>
                <xref ref="ident-double-negation"/> might appear innocuous, but this equivalence plays a very important role in standard mathematical proofs. 
                In informal terms, the equivalence of <m>¬(¬P)</m> and <m>P</m> means that “two negatives cancel each other out.”
              </p>
            </remark>

            <example><title>Important Equivalent Statements</title>
              <p>
                Let <m>P</m>, <m>Q</m> and <m>R</m> be statements.
                <ol>
                  <li><title>Commutative Law</title>
                    <p>
                      <m>P ∨ Q ⇔ Q ∨ P</m>.
                    </p>
                  </li>

                  <li><title>Commutative Law</title>
                    <p>
                      <m>P ∧ Q ⇔ Q ∧ P</m>.
                    </p>
                  </li>

                  <li><title>Associative Law</title>
                    <p>
                      <m>(P ∨ Q) ∨ R ⇔ P ∨ (Q ∨ R)</m>.
                    </p>
                  </li>

                  <li><title>Associative Law</title>
                    <p>
                      <m>(P ∧ Q) ∧ R ⇔ P ∧ (Q ∧ R)</m>.
                    </p>
                  </li>

                  <li><title>Distributive Law</title>
                    <p>
                      <m>P ∧ (Q ∨ R) ⇔ (P ∧ Q) ∨ (P ∧ R</m>.
                    </p>
                  </li>

                  <li><title>Distributive Law</title>
                    <p>
                      <m>P ∨ (Q ∧ R) ⇔ (P ∨ Q) ∧ (P ∨ R)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>P → Q ⇔ ¬P ∨ Q</m>.
                    </p>
                  </li>

                  <li><title>Contrapositive</title>
                    <p>
                      <m>P → Q ⇔ ¬Q → ¬P</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>P ↔ Q ⇔ Q ↔ P</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>P ↔ Q ⇔ (P → Q) ∧ (Q → P)</m>.
                    </p>
                  </li>

                  <li><title>De Morgan’s Law</title>
                    <p>
                      <m>¬(P ∧ Q) ⇔ ¬P ∨ ¬Q</m>.
                    </p>
                  </li>

                  <li><title>De Morgan’s Law</title>
                    <p>
                      <m>¬(P ∨ Q) ⇔ ¬P ∧ ¬Q</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>¬(P → Q) ⇔ P ∧ ¬Q</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>¬(P ↔ Q) ⇔ (P ∧ ¬Q) ∨ (¬P ∧ Q)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </example>

          </subsection> 

          <subsection xml:id="subsec-contrapositive-converse-inverse"><title>Contrapositive, Converse, Inverse</title>

            <blockquote>
              <p>
                <q>
                  Logic is the hygiene the mathematician practices to keep his ideas healthy and strong.
                </q>
              </p>
              <attribution>Hermann Weyl</attribution>
            </blockquote>

            <definition xml:id="def-contrapositive">
              <statement>
                <p>
                  Given a conditional statement of the form <m>P \to  Q</m>, we call <m>¬Q \to  ¬P</m> the <term>contrapositive</term> of the original statement.
                </p>
              </statement>
            </definition>

            <p>
              <xref ref="def-contrapositive"/> gives a reformulation of the biconditional in terms of conditionals.
            </p>

            <example>
              <p>
                For example, the contrapositive of “if I eat too much I will feel sick” is “if I do not feel sick I did not eat too much.”
              </p>
            </example>

            <p>
              We also give names to two other variants of statements of the form <m>P → Q</m>.
            </p>

            <definition xml:id="def-converse-statement">
              <statement>
                <p>
                  For a statement <m>P \to  Q</m>, we call <m>Q \to  P</m> the <term>converse</term> of the original statement.
                </p>
              </statement>
            </definition>

            <definition xml:id="def-inverse-statement">
              <statement>
                <p>
                  For a statement <m>P \to  Q</m>, we call <m>¬P \to  ¬Q</m> the <term>inverse</term> of the original statement.
                </p>
              </statement>
            </definition>

            <example>
              <p>
                Continuing the example of the previous paragraph, the converse of “if I eat too much I will feel sick” is “if I feel sick then I ate too much”; the inverse of the original statement is “if I did not eat too much then I will not feel sick.”
              </p>
            </example>

            <warning>
              <p>
                It is important to recognize that neither the converse nor the inverse is equivalent to the original statement, as the reader can verify by constructing the appropriate truth tables.
              </p>
            </warning>

            <remark>
              <p>
                Although the converse and inverse of a statement are not equivalent to the original statement, we note that, however, that the converse and the inverse are equivalent to each another, as can be seen by applying Fact 1.3.2 (9) to the statement <m>Q → P</m>.
              </p>
            </remark>

            <exercise>
              <statement>
                <p>
                  Let <m>P, Q, A</m> and <m>B</m> be statements. 
                  Show that the following are true.
                  <ol>
                    <li>
                      <p>
                        <m>P ⇔ P \vee  (P \wedge   Q)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>P ⇔ P \wedge   (P \vee  Q)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>P ↔ Q ⇔ (P \to  Q) \wedge   (¬P \to  ¬Q)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>P \to  (A \wedge  B) ⇔ (P \to  A) \wedge   (P \to B)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>P \to  (A \vee B) ⇔ (P \wedge   ¬A) \to B</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>(A \vee B) \to  Q ⇔ (A \to  Q) \wedge   (B \to  Q)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>(A \wedge  B) \to  Q ⇔ (A \to  Q) \vee  (B \to  Q)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>(A \wedge  B) \to  Q ⇔ A \to  (B \to  Q)</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
            </exercise>

          </subsection>

        </section>

        <section xml:id="sec-valid-arguments"><title>Valid Arguments</title>

          <introduction>
            <p>
              In the previous sections of this chapter we looked at statements from the point of view of truth and falsity. 
              We verified the truth or falsity of statements via truth tables, which allowed us to consider all possible ways in which various component statements might be true or false. 
              This approach, while the most basic way to treat the truth or falsity of statements, does not appear to resemble the way mathematicians prove theorems, which is by starting with the hypotheses, and then writing one new statement at a time, each of which is implied by the previous statements, until the conclusion is reached. 
              In this section we look at the analogous construction in logic, that is, the rules of logical argumentation, and we will see the relation of this approach to what was discussed in the previous sections of this chapter.
            </p>
          </introduction>

          <subsection xml:id="subsec-arguments"><title>Logical Arguments</title>
          
            <definition xml:id="def-logical-argument">
              <statement>
                <p>
                  A logical argument is a collection of statements, the last of which is the conclusion of the argument, and the rest of which are the premises of the argument.
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                The use of the word “argument” in logic is different from the colloquial use of the word, where it could mean the reasons given for thinking that something is true, or it could mean a heated (and not necessarily logical) discussion.
              </p>
            </remark>

            <example>
              <p>
                Consider the following collection of statements, which has a number of premises together with a conclusion.
              </p>

              <p>
                If the poodle-o-matic is cheap or is energy efficient, then it will not make money for the manufacturer. 
                If the poodle-o-matic is painted red, then it will make money for the manufacturer. 
                The poodle-o-matic is cheap. 
                Therefore the poodle-o-matic is not painted red.
              </p>
            </example>

            <p>
              An argument is a collection of statements that are broken up into premises and a conclusion. 
              However, a random collection of statements, in which there is no inherent connection between those designated as premises and the one designated as conclusion, will not be of much use.
            </p>

            <definition xml:id="def-valid">
              <statement>
                <p>
                  An argument is valid if the conclusion necessarily follows from the premises.
                </p>
              </statement>
            </definition>

            <p>
              To a mathematician, what logicians call an argument would simply correspond to the statement of a theorem; the justification that an argument is valid would correspond to what mathematicians call the proof of the theorem.
            </p>

          <tabular>
            <row>
              <cell>Modus Ponens</cell> <cell><m>P\to Q</m></cell>
            </row>
          </tabular>

          </subsection>

        </section>

        <section xml:id="sec-quantifiers"><title>Quantifiers</title>

          <introduction>
            <p>
              We are now ready for a closer look at the two types of quantifiers that we will use.
            </p>
          </introduction>

          <subsection xml:id="subsec-universal-quantifiers"><title>Universal Quantifiers</title>

            <convention>
              <p>
                When using variables in a statement <m>P</m>, it is often useful to write <m>P(x)</m> instead of <m>P</m> to indicate that <m>x</m> is subject to change. 
                If in a statement <m>Q</m> both <m>x</m> and <m>y</m> are variables, and we would denote that by writing <m>Q(x, y)</m>.
              </p>
            </convention>
            
            <definition xml:id="def-universal-quantifier">
              <statement>
                <p>
                  Let <m>P(x)</m> be an expression with free variable <m>x</m>. Let <m>U</m> denote a collection of possible values of <m>x</m>. 
                  A universal quantifier applied to <m>P(x)</m> is the statement, denoted <m>(\forall x \text{ in } U)P(x)</m>, which is true if <m>P(x)</m> is true for all possible values of <m>x</m> in <m>U</m>.
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                If the collection <m>U</m> is understood from the context, then we will write <m>(\forall x)P(x)</m>.
              </p>
            </convention>

            <remark>
              <p>
                One way to think of the statement <m>(∀x in U)P(x)</m> is to view it as the conditional statement “if <m>x</m> is in <m>U</m>, then <m>P(x)</m> is true.”
              </p>
            </remark>

            <convention>
              <p>
                There are a variety of ways to write <m>(∀x in U)P(x)</m> in English, for example:
                <ul>
                  <li>
                    <p>
                      For all values of <m>x</m> in <m>U</m>, the statement <m>P(x)</m> is true;
                    </p>
                  </li>

                  <li>
                    <p>
                      For each <m>x</m> in <m>U</m>, the statement <m>P(x)</m> is true;
                    </p>
                  </li>

                  <li>
                    <p>
                      The statement <m>P(x)</m> is true for all <m>x</m> in <m>U</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      All values of <m>x</m> in <m>U</m> satisfy the <m>P(x)</m>.
                    </p>
                  </li>
                </ul>
              </p>
            </convention>

            <example>
              <p>
                Let <m>P(α) = </m>“person <m>α</m> has red hair,” and let <m>W</m> be the collection of all people in the world. 
                The statement <m>(∀α in W )P(α)</m> would mean that “all people in the world have red hair” (which is certainly not a true statement).
              </p>
            </example>

            <warning>
              <p>
                Changing the collection <m>U</m> in a statement of the form <m>(∀x in U)P(x)</m> can change the truth or falsity of the statement, so that the choice of <m>U</m> is crucial.
              </p>
            </warning>

            <example>
              <p>
                Let <m>R(x) = </m>“the number <m>x</m> has a square root.” 
                If we let <m>U</m> be the collection of positive real numbers, then the statement <m>(∀x in U)R(x)</m> is true. 
                On the other hand, if we let <m>W</m> be the collection of all real numbers, then the statement <m>(∀x in W )R(x)</m> is false.
              </p>
            </example>

            <example>
              <p>
                For the sake of completeness, we need to allow the case where the collection <m>U</m> has nothing in it. 
                In that case, the statement <m>(∀x in U)P(x)</m> is always true, no matter what <m>P(x)</m> is, for the following reason. 
                The statement “<m>(∀x in U)P(x)</m>” is equivalent to the statement “if <m>x</m> is in <m>U</m>, then <m>P(x)</m> is true.” 
                When the collection <m>U</m> has nothing in it, then the statement “<m>x</m> is in <m>U</m>” is false, and hence the conditional statement “if <m>x</m> is in <m>U</m>, then <m>P(x)</m> is true” is true.
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-existential-quantifiers"><title>Existential Quantifiers</title>
            
            <definition xml:id="def-existential-quantifier">
              <statement>
                <p>
                  Let <m>P(x)</m> be a statement with variable <m>x</m>, and let <m>U</m> denote a collection of possible values of <m>x</m>.
                  An existential quantifier applied to <m>P(x)</m> is the statement, denoted <m>(∃x \text{ in }U)P(x)</m>, which is true if <m>P(x)</m> is true for at least one value of <m>x</m> in <m>U</m>.
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                If the collection <m>U</m> is understood from the context, then we will write <m>(∃x)P(x)</m>.
              </p>
            </convention>

            <remark>
              <p>
                Observe that if the collection <m>U</m> has nothing in it, then the statement <m>(∃x)P(x)</m> is false.
              </p>
            </remark>

            <p>
              It is important to note that the phrase “at least one value of <m>x</m> in <m>U</m>” means one or more, possibly many, or even all <m>x</m> in <m>U</m>. 
              In particular, if <m>(∀x in U)P(x)</m> is true, then <m>(∃x in U)P(x)</m> is true, except in the special case that <m>U</m> has nothing in it. 
              However, the statement <m>(∃x in U)P(x)</m> does not imply that <m>(∀x in U)P(x)</m> is true, except in the case that <m>U</m> has either one thing or nothing in it.
            </p>

            <convention>
              <p>
                There are a variety of ways to write <m>(∃x in U)P(x)</m> in English, for example:
                <ul>
                  <li>
                    <p>
                      There exists some <m>x</m> in <m>U</m> such that <m>P(x)</m> holds;
                    </p>
                  </li>

                  <li>
                    <p>
                      There is <m>x</m> in <m>U</m> such that <m>P(x)</m> holds;
                    </p>
                  </li>

                  <li>
                    <p>
                      There exists at least one <m>x</m> in <m>U</m> such that <m>P(x)</m> holds;
                    </p>
                  </li>

                  <li>
                    <p>
                      For some value of <m>x</m> in <m>U</m>, the condition <m>P(x)</m> holds;
                    </p>
                  </li>

                  <li>
                    <p>
                      It is the case that <m>P(x)</m> is true for some <m>x</m> in <m>U</m>.
                    </p>
                  </li>
                </ul>
              </p>
            </convention>

            <example>
              <p>
                Let <m>Q(r) = </m>“person r has brown hair,” and let <m>W</m> be the collection of all people in the world. 
                Then the statement <m>(∃r in W )Q(r)</m> would mean that “there is someone with brown hair,” or equivalently “some people have brown hair” (which is a true statement).
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-multiple-quantifiers"><title>Multiple Quantifiers</title>
              
            <p>
              We can form statements with more than one quantifier, as long as different quantifiers involve different variables. 
            </p>

            <example><title>The Order of the Quantifiers Matters.</title>
            
              <p>
                Suppose that <m>P(x, y) = “x + y^2 = 3,”</m> where <m>x</m> and <m>y</m> are real numbers. 
                The statement <m>(∀y)(∃x)P(x, y)</m> can then be written in English as “for all <m>y</m> there exists some <m>x</m> such that<m> x + y^2 = 3</m>,” or equivalently “for each <m>y</m> there is some <m>x</m> such that <m>x + y^2 = 3</m>.” 
                This statement is true, because for any real number <m>y</m> we can always solve for <m>x</m> in terms of <m>y</m>, yielding <m>x = 3 − y^2</m> .
              </p>

              <p>
                If we reverse the order of the quantifiers, we obtain the statement <m>(∃x)(∀y)P(x, y)</m>, which can be written in English as “there exists some <m>x</m> such that for all <m>y</m>, the equation <m>x+y^2 = 3</m> holds.” 
                This statement is false, because for any given <m>x</m>, there can be at most two values of <m>y</m> such that <m>x + y^2 = 3</m>. 
              </p>
            </example>

            <remark>
              <p>
                When attempting to prove a theorem, the statement of which involves multiple quantifiers, it is sometimes useful to translate the statement of the theorem into symbols, to help keep track of the meaning of the quantifiers. 
              </p>
            </remark>

            <example>
              <p>
                Suppose that we are given the statement “if <m>x</m> is a non-negative real number, then <m>x</m> is a perfect square.” 
                This statement can be interpreted as a doubly quantified statement by rephrasing it as “for each non-negative real number <m>x</m>, there is some real number <m>y</m> such that <m>x = y^2</m>.”
                Written symbolically, the statement is
                (<m>∀x</m> in the non-negative real numbers)(<m>∃y</m> in the real numbers)(<m>x = y^2</m>).
              </p>
            </example>

            <warning>
              <p>
                A lack of attention to the order of quantifiers can easily lead to mistakes in proving theorems that have statements with multiple quantifiers.
              </p>
            </warning>

            <p>
              There are eight possible generic ways of writing two quantifiers in a statement that has variables. Most of the eight possibilities have different meanings from one another.
            </p>

            <example>
              <p>
                <ul>
                  <li>
                    <p>
                      <m>(\forall x)(\forall y)L(x, y)</m>. 
                      This statement can be written in English as “for each person <m>x</m>, for each type of fruit <m>y</m>, person <m>x</m> likes to eat <m>y</m>,” and more simply as “every person likes every type of fruit.” 
                      To verify whether this statement is true, we would have to ask each person in the world if she likes every type of fruit; if even one person does not like one type of fruit, then the statement would be false.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(\forall y)(\forall x)L(x, y)</m>. 
                      This statement can be written as “for each type of fruit <m>y</m>, for each person <m>x</m>, we know <m>x</m> likes to eat <m>y</m>,” and more simply as “every type of fruit is liked by every person.” 
                      This statement is equivalent to Statement 1.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(\forall x)(∃y)L(x, y)</m>. 
                      This statement can be written as “for each person <m>x</m>, there is a type of fruit y such that <m>x</m> likes to eat <m>y</m>,” and more simply as “every person likes at least one type of fruit.” 
                      To verify whether this statement is true, we would have to ask each person in the world if she likes some type of fruit; if at least one person does not like any type of fruit, then the statement would be false.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(∃x)(\forall y)L(x, y)</m>. 
                      This statement can be written as “there is a person <m>x</m> such that for all types of fruit <m>y</m>, person <m>x</m> likes to eat <m>y</m>,” and more simply as “there is a person who likes every type of fruit.” 
                      To verify whether this statement is true, we would start asking one person at a time if she likes every type of fruit; as soon as we found one person who answers yes, we would know that the statement is true, and we could stop asking more people. 
                      If no such person is found, then the statement would be false.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(\forall y)(∃x)L(x, y)</m>. 
                      This statement can be written as “for each type of fruit <m>y</m>, there is a person <m>x</m> such that <m>x</m> likes to eat <m>y</m>,” and more simply as “every type of fruit is liked by at least one person.” 
                      To verify whether this statement is true, we would have to list all the types of fruit, and then for each type of fruit, ask one person at a time whether she likes the fruit; once we found someone who liked that fruit, we could move onto the next fruit, and again ask one person at a time about it. 
                      For the statement to be true, we would have to find at least one person per fruit, though the same person could be selected for more than one fruit.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(∃y)(\forall x)L(x, y)</m>. 
                      This statement can be written as “there is a type of fruit <m>y</m> such that for all persons <m>x</m>, we know that <m>x</m> likes to eat <m>y</m>,” and more simply as “there is a type of fruit that all people like.” 
                      To verify whether this statement is true, we would have to list all the types of fruit, and then for one type of fruit at a time, ask each person in the world if she likes that type of fruit; as soon as we found one type of fruit that everyone likes, we would know that the statement is true, and we could stop asking about more types of fruit.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(∃x)(∃y)L(x, y)</m>. 
                      This statement can be written as “there is a person <m>x</m> such that there is a type of fruit <m>y</m> such that <m>x</m> likes to eat <m>y</m>,” and more simply as “there is a person who likes at least one type of fruit.” 
                      To verify whether this statement is true, we would have to start asking one person at a time if she likes some type of fruit; as soon as we found one person who answers yes, we would know that the statement is true, and we could stop asking more people.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(∃y)(∃x)L(x, y)</m>. 
                      This statement can be written as “there is a type of fruit <m>y</m> such that there is a person <m>x</m> such that <m>x</m> likes to eat <m>y</m>,” and more simply as “there is a type of fruit that is liked by at least one person.” 
                      This statement is equivalent to Statement 7.
                    </p>
                  </li>
                </ul>
              </p>
            </example>

            <p>
              In the above example we had eight cases, because there were two variables. 
              When there are more variables, then the number of cases will be even larger. 
              Also, we observe that whereas most of the cases in the above example are different from one another, there exist some examples of statements where some of the distinct cases above happen to coincide.
            </p>

          </subsection>

          <subsection xml:id="subsec-negating-quantifiers"><title>Negating Quantifiers</title>
            
            <p>
              We now look at the negation of statements with quantifiers.
            </p>

            <fact xml:id="fact-quantifier-negation">
              <statement>
                <p>
                  Let <m>P(x)</m> be a statement with variable <m>x</m>, which takes values in some collection <m>U</m>.
                  <ol>
                    <li>
                      <p>
                        <m>¬[(∀x in U)P(x)] ⇔ (∃x in U)(¬P(x))</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>¬[(∃x in U)P(x)] ⇔ (∀x in U)(¬P(x))</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
            </fact>

            <remark>
              <p>
                Unlike the equivalences discussed in Section 1.3, we cannot use truth tables to verify the equivalences in <xref ref="fact-quantifier-negation"/>, though they are true nonetheless, based on the meanings of the quantifiers.
              </p>
            </remark>

            <p>
              We can use the above equivalences to negate statements with more than one quantifier. 
            </p>

            <example>
              <p>
                Suppose that <m>f</m> is a function that takes real numbers to real numbers (for example <m>f (x) = x^2</m> for all real numbers <m>x</m>). 
                Let <m>Q =</m> “for each real number <m>w</m>, there is some real number <m>y</m> such that <m>f (y) = w</m>.” 
                We would like to find <m>¬Q</m>. 
                We start by writing <m>Q</m> symbolically. 
                Let <m>P(w, y) = “ f (y) = w.”</m> 
                Then <m>Q = (∀w)(∃y)P(w, y)</m>.
                Using our equivalences we have

                ¬Q ⇔ ¬[(∀w)(∃y)P(w, y)] ⇔ (∃w)¬[(∃y)P(w, y)]
                   ⇔ (∃w)(∀y)(¬P(w, y)).

                Rephrasing this last expression in English yields <m>¬Q = </m>“there exists a real number <m>w</m> such that for all real numbers <m>y</m>, the relation <m>f (y) \neq w</m> holds.
              </p>
            </example>

            <p>
              It is often easier to negate statements with multiple quantifiers by first translating them into symbolic form, negating them symbolically and then translating back into English. 
              With a bit of practice it is possible to negate such statements directly in English as well, as long as the statements are not too complicated.
            </p>

          </subsection>

        </section>

      </chapter>

      <chapter xml:id="ch-proof"><title>Proofs</title>

        <introduction><title>Why do We Need Proofs?</title>
          <p>
            The main reason, of course, is to be sure that something is true. Contrary to popular misconception, mathematics is not a formal game in which we derive theorems from arbitrarily chosen axioms. 
            Rather, we discuss various types of mathematical objects, some geometric (for example, circles), some algebraic (for example,polynomials), some analytic (for example, derivatives) and the like. 
            To understand these objects fully, we need to use both intuition and rigor. 
            Our intuition tells us what is important, what we think might be true, what to try next and so forth. 
            Unfortunately, mathematical objects are often so complicated or abstract that our intuition at times fails, even for the most experienced mathematicians. 
            We use rigorous proofs to verify that a given statement that appears intuitively true is indeed true.
          </p>

          <p>
            Another use of mathematical proofs is to explain why things are true, though not every proof does that. 
            Some proofs tell us that certain statements are true, but shed no intuitive light on their subjects. 
            Other proofs might help explain the ideas that underpin the result being proved; such proofs are preferable, though any proof, even if non-intuitive, is better than no proof at all.
          </p>

          <p>
            A third reason for having proofs in mathematics is pedagogical. 
            A student (or experienced mathematician for that matter) might feel that she understands a new concept, but it is often only when attempting to construct a proof using the concept that a more thorough understanding emerges.
          </p>

          <p>
            Finally, a mathematical proof is a way of communicating to another person an idea that one person believes intuitively, but the other does not.
          </p>

          <p>
            One final comment on writing proofs: neither thinking up proofs nor writing them properly is easy, especially as the material under consideration becomes more and more abstract. 
            Mathematics is not a speed activity, and you should not expect to construct proofs rapidly. 
            You will often need to do scratch work first, before writing up the actual proof. 
            As part of the scratch work, it is very important to figure out the overall strategy for the problem being solved, prior to looking at the details.
            What type of proof is to be used? 
            What definitions are involved? 
            Not every choice of strategy ultimately works, of course, and so any approach needs to be understood as only one possible way to attempt to prove the theorem. 
            If one approach fails, try another. 
            Every mathematician has, in some situations, had to try many approaches to proving a theorem before finding one that works; the same is true for students of mathematics.
          </p>
        </introduction>

        <section xml:id="direct-proof"><title>Direct Proof</title>

          <subsection xml:id="subsec-direct-proofs"><title>Direct Proofs</title>

            <p>
              Theorems are not proved in a vacuum. 
              To prove one theorem, we usually need to use various relevant definitions, and theorems that have already been proved. 
              If we do not want to keep going backwards infinitely, we need to start with some objects that we use without definition, as well as some facts about these objects that are assumed without proof. 
              Such facts are called axioms, and a body of knowledge that can be derived from a set of axioms is called an axiomatic system.
            </p>

            <p>
              In modern abstract mathematics, we take set theory as our basis for all arguments.
            </p>

            <p>
              As a basis for our work in the present chapter, we will make use of standard definitions and properties of the familiar number systems such as the integers, rational numbers and real numbers.
            </p>

            <p>
              The statement of virtually every theorem, when viewed appropriately, is of the form P → Q, or some combination of such statements.
              To prove theorems, we therefore need to know how to prove statements of the form P → Q.
            </p>

            <definition xml:id="def-direct-proof">
              <statement>
                <p>
                  The most intuitive form of proof, which we treat in this section, is called a <term>direct proof</term>: assume that <m>P</m> is true, and produce a series of steps, each one following from the previous ones, which eventually lead to <m>Q</m>.
                </p>
              </statement>
            </definition>

            <p>
              That this sort of proof deserves a name is because there are other approaches that can be taken, as we will soon see.
            </p>

            <p>
              Direct proofs, when completed, typically have the following form.
            </p>

            <insight>
              <p>
                Suppose that <m>P</m> is true.
                ...
                (argumentation)
                ...
                Then <m>Q</m> is true. 
              </p>
            </insight>

            <p>
              When constructing a proof, the first thing to do is specify what you are assuming, and what it is you are trying to prove. 
              Then you pick a strategy for the proof; one such strategy is direct proof. 
              The next stage is actually figuring out a proof, making use of your chosen strategy. 
              If you cannot devise a proof using your chosen strategy, perhaps another strategy should be attempted. 
              There is no fixed way of finding a proof; it requires experimentation, playing around and trying different things.
            </p>
            
            <p>
              You are probably familiar with the statement “the sum of even numbers is even.” 
              This statement can be viewed in the form P → Q if we look at it properly, because it actually says “if n and m are even numbers, then n + m is an even number.
              To construct a rigorous proof of our statement (as well as the corresponding result for odd numbers), we first need precise definitions of the terms involved.
            </p>

            <p>
              Our theorem is concerned with the integers, that is, the numbers
              . . . , −3, −2, −1, 0, 1, 2, 3, . . . ,
              and so we need to assume that we know what the integers are, that we have the operations addition, subtraction, multiplication and division, and that these operations satisfy standard properties, for example the Distributive Law. 
              Using only those standard facts about the integers, we can make the following definition, which is the basis for our theorem and its proof.
            </p>

            <definition xml:id="def-even-odd">
              <statement>
                <p>
                  Let <m>n</m> be an integer. 
                  The number <m>n</m> is <term>even</term> if there is some integer <m>k</m> such that <m>n = 2k</m>. 
                  The number <m>n</m> is <term>odd</term> if there is some integer <m>j</m> such that <m>n =2 j + 1</m>. 
                </p>
              </statement>
            </definition>

            <p>
              We are now ready to state and prove our theorem.
            </p>

            <theorem xml:id="thm-even-odd">
              <statement>
                <p>
                  Let <m>n</m> and <m>m</m> be integers.
                  <ol>
                    <li>
                      <p>
                        If <m>n</m> and <m>m</m> are both even, then <m>n + m</m> is even.
                      </p>
                    </li>

                    <li>
                      <p>
                        If <m>n</m> and m are both odd, then <m>n + m</m> is even.
                      </p>
                    </li>

                    <li>
                      <p>
                        If <m>n</m> is even and <m>m</m> is odd, then <m>n + m</m> is odd.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  <ol>
                    <li>
                      <p>
                        Suppose that <m>n</m> and <m>m</m> are both even. 
                        Then there exist integers <m>k</m> and <m>j</m> such that <m>n = 2k</m> and <m>m = 2 j</m>. 
                        Then
                        <me>n + m = 2k + 2 j = 2(k + j).</me>
                        Because <m>k</m> and <m>j</m> are integers, so is <m>k + j</m>. Hence <m>m + n</m> is even.
                      </p>
                    </li>

                    <li>
                      <p>
                        Combing soon!
                      </p>
                    </li>

                    <li>
                      <p>
                        Combing soon!
                      </p>
                    </li>
                  </ol>
                </p>
              </proof>
            </theorem>

            <remark>
              <p>
                There is a fourth possible case we did not state in <xref ref="thm-even-odd"/>, namely, the case when <m>n</m> is odd and <m>m</m> is even, because that case is really no different from Part (3) of the theorem, and hence it would not tell us anything new; it makes no difference whether we call the even number <m>n</m> and the odd number <m>m</m>, or vice versa.
              </p>
            </remark>

            <p>
              The proof of Part (1) of Theorem 2.1.3 is quite simple, but there are a few features worth mentioning, because they are typical of what is found in virtually all our subsequent proofs (and in the proofs you will need to write). 
              First, the proof relies completely on the definition of what it means to be an even or an odd integer. 
              In a large number of proofs, going back to the formal definitions involved is the key step; forgetting to do so is a major source of error by students who are first learning about proofs.
            </p>

            <p>
              Second, observe that the proof is written in grammatically correct English. 
              Complete sentences are used, with proper punctuation. 
              Each sentence begins with a capital letter, and ends with a period, even if the end of the sentence is in a displayed equation. 
              Mathematical formulas and symbols are parts of sentences, and are treated no differently from other words. 
            </p>


            <definition xml:id="def-divides">
              <statement>
                <p>
                  Let <m>a</m> and <m>b</m> be integers. 
                  The number <m>a</m> <term>divides</term> the number <m>b</m> if and only if there is some integer <m>q</m> such that <m>aq = b</m>. 
                  If <m>a</m> divides <m>b</m>, we write <m>a|b</m>, and we say that <m>a</m> is a factor of <m>b</m>, and that <m>b</m> is <term>divisible</term> by <m>a</m>. 
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                It is customary in definitions to write “if” rather than “if and only if,” because it is taken as assumed that if the condition does not hold, then the term being defined cannot be applied.
              </p>
            </convention>

            <theorem>
              <statement>
                <p>
                  Let <m>a</m>, <m>b</m> and <m>c</m> be integers. 
                  If <m>a|b</m> and <m>b|c</m>, then <m>a|c</m>.
                </p>
              </statement>

              <proof>
                <p>
                  Suppose that <m>a|b</m> and <m>b|c</m>. 
                  Hence there are integers <m>q</m> and <m>r</m> such that <m>aq = b</m> and <m>br = c</m>. 
                  Define the integer <m>k</m> by <m>k = qr</m>. 
                  Then <m>ak = a(qr) = (aq)r = br = c</m>. 
                  Because <m>ak = c</m>, it follows that <m>a|c</m>. 
                </p>
              </proof>
            </theorem>

            <theorem>
              <statement>
                <p>
                  Any integer divides zero.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>n</m> be an integer. Observe that <m>n · 0 = 0</m>. Hence <m>n|0</m>. 
                </p>
              </proof>
            </theorem>

            <exercise>
              <statement>
                <p>
                  Let <m>n</m> be an integer. 
                  Prove that if <m>n</m> is even then <m>n^2</m> is even, and if <m>n</m> is odd then <m>n^2</m> is odd.
                </p>
              </statement>
            </exercise>

          </subsection>
          
        </section>

        <section xml:id="sec-contrapositive-contradiction"><title>Contrapositive, Contradiction</title>

          <introduction>
            <p>
              In this section we discuss two strategies for proving statements of the form <m>P → Q</m>. 
              Both these strategies are a bit more convoluted than direct proof, but in some situations they are nonetheless easier to work with. 
              A less than perfect analogy might be when the straightest road between two cities leads up and down a mountain and through difficult terrain, whereas a curved road might at first seem to be going in the wrong direction, but in fact it bypasses the mountain and is ultimately easier and quicker than the straight road.
            </p>
          </introduction>

          <subsection xml:id="subsec-contrapositive"><title>Contrapositive</title>
            
          <p>
            Recall <xref ref="def-contrapositive"/>.
          </p>

          <definition xml:id="def-contrapositive-proof">
            <statement>
              <p>
                In order to prove <m>P \to  Q</m>, we could just as well prove <m>¬Q \to  ¬P</m>, which we would do by the method of direct proof. 
                We construct such a proof by assuming that <m>Q</m> is false, and then, in the final write-up, presenting a step-by-step argument going from <m>¬Q </m> to <m>¬P</m>.
                A proof of this sort is called proof by <term>contrapositive</term>.
              </p>
            </statement>
          </definition>

          <insight>
              <p>
                Suppose that <m>Q</m> is false.
                ...
                (argumentation)
                ...
                Then <m>P</m> is false. 
              </p>
            </insight>

          <theorem>
            <statement>
              <p>
                Let <m>n</m> be an integer. If <m>n^2</m> is odd, then <m>n</m> is odd.
              </p>
            </statement>

            <proof>
              <p>
                Suppose that <m>n</m> is even. Then there is some integer <m>k</m> such that <m>n = 2k</m>. 
                Hence <m>n^2 = (2k)^2 = 4k^2 = 2(2k^2)</m>. Because <m>2k^2</m> is an integer, it follows that <m>n^2</m> is even. 
                By contrapositive, we see that if <m>n^2</m> is odd then n is odd. 
              </p>
            </proof>
          </theorem>

          <convention>
            <p>
              In the above proof we mentioned that we used proof by contrapositive. 
              In general, it is often helpful to the reader to have the method of proof stated explicitly.
            </p>
          </convention>

          </subsection>

          <subsection xml:id="subsec-contradiction"><title>Contradiction</title>

            <p>
               Another method of proof for theorems with statements of the form <m>P \to  Q</m>, which looks similar to proof by contrapositive but is actually distinct from it, is proof by contradiction.
            </p>

            <definition xml:id="def-contradiction-proof">
              <statement>
                <p>
                  The method of proof by <term>contradiction</term> is to show that <m>P → Q</m> is true by assuming that <m>P ∧ ¬Q</m> is true, and then deriving a logical contradiction, by which we mean a statement that cannot be true under any circumstances.
                </p>
              </statement>
            </definition>

            <p>
              Logicians use the term “proof by contradiction” to mean the proof of a statement <m>A</m> by assuming <m>¬A</m>, then reaching a contradiction, and then deducing that <m>A</m> must be true. 
              For our purposes, we are interested in proof by contradiction for the special case where the statement <m>A</m> has the form <m>P \to  Q</m>, because that is how mathematical theorems are formulated.
            </p>

            <insight>
              <p>
                We prove the result by contradiction. 
                Suppose that <m>P</m> is true and that <m>Q</m> is false.
                ...
                (argumentation)
                ...
                We have therefore reached a contradiction. Therefore <m>P</m> implies <m>Q</m>. 
              </p>
            </insight>

            <theorem>
              <statement>
                <p>
                  The only consecutive non-negative integers <m>a</m>, <m>b</m> and <m>c</m> that satisfy <m>a^2 + b^2 = c^2</m> are <m>3</m>, <m>4</m> and <m>5</m>.
                </p>
              </statement>

              <proof>
                <p>
                  We prove the result by contradiction. 
                  Suppose that <m>a</m>, <m>b</m> and <m>c</m> are non-negative consecutive integers other than <m>3</m>, <m>4</m> and <m>5</m>, and that <m>a^2 + b^2 = c^2</m>. 
                  Because a, b and c are not 3, 4 and 5, we know that a \neq  3, and because the three numbers are consecutive, we know that b = a + 1 and c = a + 2. 
                  From <m>a^2 + b^2 = c^2</m> we deduce that <m>a^2 + (a + 1)^2 = (a + 2)^2</m>. 
                  After expanding and rearranging we obtain <m>a^2 - 2a - 3 = 0</m>. 
                  This equation factors as <m>(a - 3)(a + 1) = 0</m>. 
                  Hence <m>a = 3 or a = -1</m>. We have already remarked that <m>a \neq  3</m>, and we know a is non-negative. 
                  Therefore we have a contradiction, and the theorem is proved. 
                </p>
              </proof>
            </theorem>

            <p>
              Our next two theorems are both famous results that have well-known proofs by contradiction. 
              These clever proofs are much more difficult than what we have seen so far, and are more than would be expected of a student to figure out on her own at this point.
            </p>

            <definition xml:id="def-rational-number">
              <statement>
                <p>
                  Let <m>x</m> be a real number. 
                  The number <m>x</m> is a <term>rational</term> number if there exist integers <m>n</m> and <m>m</m> such that <m>m \neq  0</m> and <m>x = \frac{n}{m}</m> .
                  If <m>x</m> is not a rational number, it is an <term>irrational</term> number.
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                Observe that if x is a rational number, then there are many different fractions of the form n m such that x = n m. 
                Given any fraction n m such that n 6 = 0, we can always reduce it to “lowest terms,” by which we mean that the numerator and denominator have no common factors other than 1 and −1.
              </p>
            </remark>

            <definition xml:id="def-square-root">
              <statement>
                <p>
                  Let <m>p</m> be a positive real number. 
                  The <term>square root</term> of <m>p</m>, denoted <m>\sqrt{p}</m>, is a positive real number <m>x</m> such that <m>x^2 = p</m>. 
                </p>
              </statement>
            </definition>

            <theorem xml:id="thm-sqrt-2-irrational">
              <statement>
                <p>
                  There is no rational number <m>x</m> such that <m>x^2 = 2</m>.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>x</m> be a real number. 
                  Suppose that <m>x^2 = 2</m>, and that <m>x</m> is rational. 
                  We will derive a contradiction. 
                  Because <m>x</m> is rational, there are integers <m>n</m> and <m>m</m> such that <m>x = \frac nm </m>. 
                  Observe that <m>n \neq  0</m>. 
                  If <m>\frac nm</m> is not in lowest terms, then we could cancel any common factors, bringing it to lowest terms. 
                  There is no problem assuming that this has been done already, and so we may assume that n and m have no common factors other than <m>1</m> and <m>-1</m>.
                </p>

                <p>
                  Because <m>x^2 = 2</m>, then <m>(\frac nm)^2 = 2</m>. 
                  It follows that <m>\frac{n^2}{m^2} = 2</m>, and hence <m>n2 = 2m2</m>. 
                  We now ask whether <m>n</m> is even or odd. 
                  If <m>n</m> were odd, then using Exercise 2.2.4 we would see that <m>n^2</m> would be odd. 
                  This last statement is not possible, because <m>n^2 = 2m^2</m>, and <m>2m^2</m> must be even, because it is divisible by <m>2</m>. 
                  It follows that <m>n</m> cannot be odd; hence <m>n</m> must be even. 
                  Therefore there is some integer <m>k</m> such that <m>n = 2k</m>. 
                  Then <m>(2k)^2 = 2m^2</m>, so that <m>4k^2 = 2m^2</m>, and therefore <m>2k^2 = m^2</m> . 
                  By an argument similar to the one used above, we see that <m>m</m> is even. 
                  We therefore conclude that both <m>n</m> and <m>m</m> are even. 
                  We have therefore reached a contradiction, because any two even numbers have <m>2</m> as a common factor, and yet we assumed that <m>n</m> and <m>m</m> have no common factors other than <m>1</m> and <m>-1</m>. 
                  Hence <m>x</m> is not rational. 
                </p>
              </proof>
            </theorem>

            <definition xml:id="def-prime-number">
              <statement>
                <p>
                  Let <m>p</m> be an integer greater than <m>1</m>. 
                  The number <m>p</m> is a <term>prime</term> number iff the only positive integers that divide <m>p</m> are <m>1</m> and <m>p</m>. 
                  The number <m>p</m> is a <term>composite</term> number iff it is not a prime number. 
                </p>
              </statement>
            </definition>

            <exercise>
              <statement>
                <p>
                  Prove that the product of a non-zero rational number and an irrational number is irrational.
                </p>
              </statement>
            </exercise>
            
          </subsection>
          
        </section>

        <section xml:id="other-structures"><title>Other Proof Structures</title>

          <introduction>
            <p>
              The notion of equivalence of statements has already been seen to be useful in proving theorems, for example in proof by contrapositive.
              In this section we will make use of some other equivalences of statements to prove certain types of theorems.
            </p>
          </introduction>

          <subsection xml:id="subsec-cases"><title>Cases</title>

            <convention>
              <p>
                One commonly used method for proving a statement of the form P → Q is by breaking up the proof into a number of <term>cases</term> (and possibly subcases, subsubcases and so on).
              </p>
            </convention>

            <p>
              Formally, we use proof by cases when the premise P can be written in the form A ∨ B. 
              We then use Exercise 1.3.2 (6) to see that (A ∨ B) → Q is equivalent to (A → Q) ∧ (B → Q). 
              Hence, in order to prove that a statement of the form (A ∨ B) → Q is true, it is sufficient to prove that each of the statements A → Q and B → Q is true.
            </p>

            <remark>
              <p>
                The use of this strategy often occurs when proving a statement involving a quantifier of the form “for all x in U,” and where no single proof can be found for all such x, but where U can be divided up into two or more parts, and where a proof can be found for each part.
              </p>
            </remark>

            <theorem xml:id="thm-even-square-plus-n">
              <statement>
                <p>
                  Let n be an integer. Then n^2 + n is even.
                </p>
              </statement>
            </theorem>

            <remark>
              <p>
                In the proof of Theorem 2.4.1 we had two cases, which together covered all possibilities, and which were exclusive of each other. 
                It is certainly possible to have more than two cases, and it is also possible to have non-exclusive cases; all that is needed is that all the cases combined cover all possibilities. 
                The proof of Theorem 2.4.4 below has two non-exclusive cases.
              </p>
            </remark>

            <p>
              We now turn to theorems that have statements of the form P → (A ∨ B). 
              Such theorems are less common than the previously discussed type, but do occur, and it is worth being familiar with the standard proof strategies for such theorems. 
            </p>

            <convention>
              <p>
                There are two commonly used strategies, each one being advantageous in certain situations.
                One approach would be to use the contrapositive together with De Morgan’s Law (Fact 1.3.2 (13)), which together imply that P → (A∨B) is equivalent to (¬A∧¬B) → ¬P. 
                The other would be to use Exercise 1.3.2 (5), which says that P → (A ∨ B) is equivalent to (P ∧ ¬A) → B. 
                The roles of A and B could also be interchanged in this last statement.
              </p>
            </convention>

            <theorem xml:id="thm-irrational-product">
              <statement>
                <p>
                  Let x and y be real numbers. 
                  If xy is irrational, then x or y is irrational.
                </p>
              </statement>

              <proof>
                <p>
                  Suppose that xy is irrational and that x is rational. Hence x = a
b for some
integers a and b such that b 6 = 0. We will show that y is irrational, by using proof by
contradiction. Suppose that y is rational. It follows that y = m
n for some integers m
and n such that n 6 = 0. Hence xy = am
bn , and bn 6 = 0, contradicting the fact that xy is
irrational. Hence y is irrational. 
                </p>
              </proof>
            </theorem>
            
            
            
          </subsection>

          <subsection xml:id="subsec-iff"><title>If and Only If</title>
            
            <p>
              Whereas the most common logical form of the statement of a theorem is P → Q, as we have discussed so far, another common form is P ↔ Q. 
              We refer to such theorems as “if and only if” theorems (often abbreviated “iff” theorems). 
              To prove such a theorem, we make use of the fact that P ↔ Q is equivalent to (P → Q) ∧ (Q → P), as was shown in Fact 1.3.2 (11).
              Hence, to prove a single statement of the form P ↔ Q, it is sufficient to prove the two statements P → Q and Q → P, each of which can be proved using any of the methods we have seen so far.
            </p>

            <theorem xml:id="thm-mutual-divide">
              <statement>
                <p>
                  Let a and b be non-zero integers. Then a|b and b|a if and only if a = b or a = −b.
                </p>
              </statement>

              <proof>
                <p>
                  ⇒. Suppose that a|b and b|a. 
                  Because a|b, there is some integer m such that am = b, and because b|a, there is some integer k such that bk = a. 
                  Substituting this last equation into the previous one, we obtain (bk)m = b, and hence b(km) = b.
                  Because b 6 = 0, it follows that km = 1. 
                  Because k and m are integers, then either k = 1 and m = 1, or k = −1 and m = −1. 
                  (We will not provide a proof of this last fact; it is stated as Theorem A.4 in the Appendix.) 
                  In the former case a = b, and in the latter case a = −b.
                </p>

                <p>
                  ⇐. Suppose that a = b or a = −b. 
                  First, suppose that a = b. 
                  Then a · 1 = b, so a|b, and b · 1 = a, so b|a. 
                  Similarly, suppose that a = −b. 
                  Then a · (−1) = b, so a|b, and b · (−1) = a, so b|a. 
                </p>
              </proof>
            </theorem>

            <theorem xml:id="thm-odd-product">
              <statement>
                <p>
                  Let m and n be integers. 
                  Then mn is odd if and only if both m and n are odd.
                </p>
              </statement>

              <proof>
                <p>
                  ⇐. 
                  Suppose that m and n are both odd. 
                  Hence there is an integer j such that m = 2 j + 1, and there is an integer k such that n = 2k + 1. 
                  Therefore
                  mn = (2 j + 1)(2k + 1) = 4 jk + 2 j + 2k + 1 = 2(2 jk + j + k) + 1.
                  Because k and j are integers, so is 2 jk + j + k. 
                  Therefore mn is odd.
                </p>

                <p>
                  ⇒. 
                  Suppose that m and n are not both odd. 
                  We will deduce that mn is not odd, and the desired result will follow by contrapositive. 
                  If m and n are not both odd, then at least one of them is even. 
                  Suppose first that m is even. 
                  Then there is an integer p such that m = 2p. 
                  Hence mn = (2p)n = 2(pn). 
                  Because p and n are integers, so is pn. 
                  Therefore mn is even. 
                  Next assume that n is even. 
                  The proof in this case is similar to the previous case, and we omit the details. 
                </p>
              </proof>
            </theorem>

          </subsection>

          <subsection xml:id="subsec-tfare"><title>The Following are Equivalent</title>

            <p>
              A slightly more built-up version of an if and only if theorem is a theorem that states that three or more statements are all mutually equivalent. 
              Such theorems often include the phrase “the following are equivalent,” sometimes abbreviated “TFAE.”
            </p>
            
          </subsection>


        </section>

      </chapter>

      <chapter xml:id="ch-sets"><title>Sets</title>

        <section xml:id="sec-set-basics"><title>Set Basics</title>
          
          <example>
            <p>
              <ul>
                <li><title>Natural Numbers</title>
                  <p>
                    the set of <term>natural numbers</term>
                    <me>\{1, 2, 3, \dots\}</me>,
                    denoted <m>\N</m>;
                  </p>
                </li>

                <li><title>Integers</title>
                  <p>
                    the set of <term>integers</term>
                    <me>\{\dots, -2, -1, 0, 1, 2, \dots\}</me>,
                    denoted <m>\Z</m>;
                  </p>
                </li>

                <li><title>Rational Numbers</title>
                  <p>
                    the set of <term>rational numbers</term>, denoted <m>\Q</m>, which is the set of fractions;
                  </p>
                </li>

                <li><title>Real Numbers</title>
                  <p>
                    the set of <term>real numbers</term>, denoted <m>\R</m>, which is the set of all the numbers that are informally thought of as forming the number line.
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <example>
            <p>
              An extremely valuable set we will regularly encounter is the empty set (also called the null set) which is the set that does not have any elements in it. 
              That is, the empty set is the set <m>\{ \}</m>. 
              This set is denoted <m>\emptyset</m>.
            </p>
          </example>

          <p>
            It may seem strange to consider a set that doesn't have anything in it, but the role of the empty set in set theory is somewhat analogous to the role of zero in arithmetic.
          </p>

          <convention><title>Set Builder Notation</title>
            <p></p>
          </convention>

          <definition xml:id="def-subset">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The set <m>A</m> is a <term>subset</term> of the set <m>B</m>, denoted <m>A \subseteq B</m>, if <m>x\in  A</m> implies <m>x\in B</m>. 
                If <m>A</m> is not a subset of <m>B</m>, we write <m>A not\subseteq  B</m>.
              </p>
            </statement>
          </definition>

          <insight><title>Subset Proof</title>
            <p>
              There is a standard strategy for proving a statement of the form “<m>A \subseteq B</m>,” which is to take an arbitrary element <m>a\in  A</m>, and then to use the definitions of <m>A</m> and <m>B</m> to deduce that <m>a\in B</m>. 
              Such a proof typically has the following form.
            </p>

            <p>
              Proof. 
              Let <m>a\in  A</m>.
              ...
              (argumentation)
              ...
              Then <m>a\in B</m>. 
              Hence <m>A \subseteq B</m>. 
            </p>
          </insight>

          <remark>
            <p>
              It is important to distinguish between the notion of an object being an element of a set, and the notion of a set being a subset of another set. 
              For example, let <m>A =\{a, b, c\}</m>. Then <m>a\in  A</m> and <m>\{a\} \subseteq  A</m> are true, whereas the statements “<m>a \subseteq  A</m>” and “<m>\{a\}\in  A</m>” are false. 
              Also, observe that a set can be an element of another set. 
              Let <m>B = \{\{a\}, b, c\}</m>. 
              Observe that <m>B</m> is not the same as the set <m>A</m>. 
              Then <m>\{a\}\in B</m> and <m>\{\{a\}\} \subseteq B</m> are true, but “<m>a\in B</m>” and “<m>\{a\} \subseteq B</m>” are false.
            </p>
          </remark>

          <theorem xml:id="thm-properties-of-subsets">
            <statement>
              <p>
                <ol>
                  <li>
                    <p>
                      <m>A \subseteq  A.</m>
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>0 \subseteq  A.</m>
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A \subseteq B</m> and <m>B \subseteq  C</m>, then <m>A \subseteq  C</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ol>
                  <li>
                    <p>
                      To show that <m>A \subseteq  A</m>, we start by choosing an arbitrary element <m>a\in  A</m>, where we think of this “<m>A</m>” as the one on the left-hand side of the expression “<m>A \subseteq  A</m>.” 
                      It then follows that <m>a\in  A</m>, where we now think of this “<m>A</m>” as the one on the right-hand side of the expression “<m>A \subseteq  A</m>.” 
                      Hence <m>A \subseteq  A</m>, using the definition of subsets.
                    </p>
                  </li>

                  <li>
                    <p>
                      We give two proofs, because both are instructive. 
                      First, we have a direct proof. 
                      To show that <m>\emptyset \subseteq  A</m>, we need to show that if <m>a\in\emptyset</m>, then <m>a\in  A</m>. 
                      Because <m>a\in\emptyset</m> is always false, then the logical implication “if <m>a\in\emptyset</m>, then <m>a\in  A</m>” is always true, using the precise definition of the conditional given in Section 1.2.
                    </p>

                    <p>
                      Next, we have a proof by contradiction. 
                      Suppose that <m>\emptyset not\subseteq   A</m>. 
                      Then there exists some <m>x\in\emptyset</m> such that <m>x /\in  A</m>. 
                      This statement cannot be true, however, because there is no <m>x</m> such that <m>x\in\emptyset</m>. 
                      We have therefore reached a contradiction, and hence the desired result is true.
                    </p>

                    <p>
                      This proof by contradiction might not appear to fit the standard outline for such proofs as described in Section 2.3, because it does not appear as if we are viewing the statement being proved as having the form <m>P \to  Q</m>. 
                      In fact, there are two ways of viewing the statement being proved as having this form. 
                      For the direct proof given above, we viewed the statement being proved as <m>(\forall A)([a\in\emptyset] \to  [a\in  A])</m>. 
                      We then chose an arbitrary set <m>A</m>, and proved the statement <m>[a\in\emptyset] \to  [a\in  A]</m>. 
                      For the proof by contradiction, we viewed the statement being proved as “if <m>A</m> is a set, then <m>\emptyset \subseteq  A</m>,” and then indeed used our standard method of doing proof by contradiction.
                    </p>
                  </li>

                  <li>
                    <p>
                      This proof, having no logical tricks, is extremely typical. 
                      Let <m>a\in  A</m>. 
                      Because <m>A \subseteq B</m>, it follows that <m>a\in B</m>. 
                      Because <m>B \subseteq  C</m>, it follows that <m>a\in  C</m>. 
                      Therefore we see that <m>a\in  A</m> implies <m>a\in  C</m>, and hence <m>A \subseteq  C</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-set-equality">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The set <m>A</m> <term>equals</term> the set <m>B</m>, denoted <m>A = B</m>, if <m>A \subseteq B</m> and <m>B \subseteq  A</m>. 
                The set <m>A</m> is a <term>proper subset</term> of the set <m>B</m>, denoted <m>A \subset B</m>, if <m>A \subseteq B</m> and <m>A \neq B</m>. 
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              There is a bit of variation in the mathematical literature for the notation used for proper subsets. 
              Some texts use <m>A \subset B</m> to mean <m>A</m> is a proper subset of <m>B</m>, whereas others use the notation <m>A \subset B</m> to mean what we write as <m>A \subseteq B</m>.
            </p>
          </convention>

          <insight>
            <p>
              Proof. Let <m>a\in  A</m>.
              ...
              (argumentation)
              ...
              Then <m>a\in B</m>. Therefore <m>A \subseteq B</m>.
              Next, Let <m>b\in B</m>.
              ...
              (argumentation)
              ...
              Then <m>b\in  A</m>. Hence <m>B \subseteq  A</m>.
              We conclude that <m>A = B</m>.
              
            </p>
          </insight>

          <lemma>
            <statement>
              <p>
                Let <m>A, B</m> and <m>C</m> be sets.
                <ol>
                  <li>
                    <p>
                      <m>A = A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A = B</m> then <m>B = A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A = B</m> and <m>B = C</m>, then <m>A = C</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                All three parts of this lemma follow straightforwardly from the definition of equality of sets together with Lemma 3.2.4. 
                Details are left to the reader.
              </p>
            </proof>
          </lemma>

          <p>
            In some situations we will find it useful to look at not just one subset of a given set, but at all subsets of the set. 
            In particular, we can form a new set, the elements of which are the subsets of the given set.
          </p>

          <definition xml:id="def-power-set">
            <statement>
              <p>
                Let <m>A</m> be a set. The <term>power set</term> of <m>A</m>, denoted <m>\cP(A)</m>, is the set defined by
                  <me>\cP(A) = \{X | X \subseteq  A\}</me>. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    Because <m>\emptyset \subseteq\emptyset</m>, then <m>P ( \emptyset) = \{ \emptyset\}</m>. 
                    In particular, we see that <m>P ( \emptyset) \neq\emptyset</m>.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>A = \{a, b, c\}</m>. 
                    Then the subsets of <m>A</m> are <m>\emptyset, \{a\}, \{b\}, \{c\}, \{a, b\}, \{a, c\}, \{b, c\} and \{a, b, c\}</m>. 
                    The last of these subsets is not proper, but we need all subsets, not only the proper ones. 
                    Therefore
                      <me>
                        \cP(A) = \{ \emptyset, \{a\}, \{b\}, \{c\}, \{a, b\}, \{a, c\}, \{b, c\}, \{a, b, c\}\}.
                      </me>
                    It can be seen intuitively that if <m>A</m> is a finite set with n elements, then <m>\cP(A)</m> is a finite set with <m>2^n</m> elements; by Part (1) of this exercise we see that this formula holds even when <m>n = 0</m>. 
                    This formula is proved in Theorem 7.7.10 (1). 
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Prove that it is not possible that <m>A \subset B</m> and <m>B \subseteq  A</m> are both true.
              </p>
            </statement>
          </exercise>
          
        </section>

        <section xml:id="sec-set-operations"><title>Set Operations</title>
          
          <definition xml:id="def-union-intersection">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The <term>union</term> of <m>A</m> and <m>B</m>, denoted <m>A \cup B</m>, is the set defined by 
                  <me>A \cup B = \{x | x\in  A \text{ or } x\in B\}</me>.
                The <term>intersection</term> of <m>A</m> and <m>B</m>, denoted <m>A \cap B</m>, is the set defined by
                  <me>A \cap B = \{x | x\in  A \text{ and }x\in B\}</me>. 
              </p>
            </statement>
          </definition>

          <theorem xml:id="thm-properties-union-intersection">
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets.
                <ol>
                  <li>
                    <p>
                      <m>A \cap B \subseteq  A</m> and <m>A \cap B \subseteq B</m>. 
                      If <m>X</m> is a set such that <m>X \subseteq  A</m> and <m>X \subseteq B</m>, then <m>X \subseteq  A \cap B</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>A \subseteq  A \cup B</m> and <m>B \subseteq  A \cup B</m>. 
                      If <m>Y</m> is a set such that <m>A \subseteq  Y</m> and <m>B \subseteq  Y</m>, then <m>A \cup B \subseteq  Y</m> .
                    </p>
                  </li>

                  <li><title>Commutative Laws</title>
                    <p>
                      <m>A \cup B = B \cup  A</m> and <m>A \cap B = B \cap  A</m>.
                    </p>
                  </li>

                  <li><title>Associative Laws</title>
                    <p>
                      <m>(A\cup B)\cup C = A\cup (B\cup C)</m> and <m>(A\cap B)\cap C = A\cap (B\cap C)</m>.
                    </p>
                  </li>

                  <li><title>Distributive Laws</title>
                    <p>
                      <m>A \cap  (B \cup C) = (A \cap B) \cup  (A \cap C)</m> and <m>A \cup  (B \cap C) = (A \cup B) \cap  (A \cup C)</m>.
                    </p>
                  </li>

                  <li><title>Identity Laws</title>
                    <p>
                      <m>A \cup\emptyset = A</m> and <m>A \cap\emptyset = \emptyset</m>.
                    </p>
                  </li>

                  <li><title>Idempotent Laws</title>
                    <p>
                      <m>A \cup  A = A</m> and <m>A \cap  A = A</m>.
                    </p>
                  </li>

                  <li><title>Absorbtion Laws</title>
                    <p>
                      <m>A \cup  (A \cap B) = A</m> and <m>A \cap  (A \cup B) = A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A \subseteq B</m>, then <m>A \cup C \subseteq B \cup C</m> and <m>A \cap C \subseteq B \cap C</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <definition xml:id="def-disjoint">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The sets <m>A</m> and <m>B</m> are <term>disjoint</term> if <m>A \cap B = \emptyset</m>. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              Let <m>\E</m> be the set of even integers, let <m>\O</m> be the set of odd integers and let <m>\P</m> be the set of prime numbers. 
              Then <m>\E</m> and <m>\O</m> are disjoint, whereas <m>\E</m> and <m>\P</m> are not disjoint (because <m>\E \cap\P = \{2\}</m>).
            </p>
          </example>

          <definition xml:id="def-set-difference">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The <term>set difference</term> (also called the <term>difference</term>) of <m>A</m> and <m>B</m>, denoted <m>A \sm B</m>, is the set defined by <m>A \sm B = \{x | x\in  A \text{ and }x \not\in B\}</m>. 
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              Some books use the notation <m>A - B</m> instead of <m>A \sm B</m>.
              Though the notation <m>A - B</m> may seem intuitive, there are situations where it can become misleading or confusing.
            </p>
          </convention>

          <theorem xml:id="thm-properties-of-set-difference">
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets.

                <ol>
                  <li>
                    <p>
                      <m>A \sm B \subseteq  A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(A \sm B) \cap B = \emptyset</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>A \sm B = \emptyset</m> if and only if <m>A \subseteq B</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>B \sm (B \sm A) = A</m> if and only if <m>A \subseteq B</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A \subseteq B</m>, then <m>A \sm C = A \cap  (B \sm C)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A \subseteq B</m>, then <m>C \sm A ⊇ C \sm B</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>C \sm (A \cup B) = (C \sm A) \cap  (C \sm B)</m> and <m>C \sm (A \cap B) = (C \sm A) \cup  (C \sm B)</m> (DeMorgan's Laws).
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <definition xml:id="def-cartesian-product">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The <term>product</term> (also called the <term>Cartesian product</term>) of <m>A</m> and <m>B</m>, denoted <m>A \times B</m>, is the set 
                <me>
                  A \times B = \{(a, b) | a\in  A and b\in B\}
                </me>,
                where <m>(a, b)</m> denotes an ordered pair. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              We can think of <m>\R^2</m>, which is defined in terms of ordered pairs of real numbers, as <m>\R^2 = \R \times\R</m>. 
              Similarly, we think of <m>\R^n</m> as 
              <me>\R^n = \underbrace{\R \times \cdots \times \R}_{n \text{ times}}.</me>
            </p>
          </example>

          <theorem xml:id="thm-properties-of-products">
            <statement>
              <p>
                Let <m>A</m>, <m>B</m>, <m>C</m> and <m>D</m> be sets.
                <ol>
                  <li>
                    <p>
                      If <m>A \subseteq B</m> and <m>C \subseteq  D</m>, then <m>A \times C \subseteq B \times  D</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>A \times  (B \cup C) = (A \times B) \cup  (A \times C)</m> and <m>(B \cup C) \times  A = (B \times  A) \cup  (C \times  A)</m> (Distributive Laws).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>A \times  (B \cap C) = (A \times B) \cap  (A \times C)</m> and <m>(B \cap C) \times  A = (B \times  A) \cap  (C \times  A)</m> (Distributive Laws).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>A \times\emptyset = \emptyset</m> and <m>\emptyset \times  A = \emptyset</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(A \cap B) \times  (C \cap  D) = (A \times C) \cap  (B \times  D)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <remark>
            <p>
              Observe that <m>A \times B</m> is not the same as <m>B \times  A</m>, unless <m>A</m> and <m>B</m> happen to be equal.
            </p>
          </remark>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Prove that <m>(A\cup B)-A = B - (A \cap B)</m>
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets. 
                Suppose that <m>C \subset  A \cup B</m>, and that <m>C \cap  A = \emptyset</m>. 
                Prove that <m>C \subseteq B</m>.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                For real numbers <m>a</m>, <m>b</m> and <m>c</m>, we know that <m>a - (b - c) = (a - b) + c</m>. 
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets.
                <ol>
                  <li>
                    <p>
                      Suppose that <m>C \subseteq  A</m>. Prove that <m>A - (B -C) = (A - B) \cup C</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Does <m>A \sm (B \sm C) = (A \sm B) \cup  C</m> hold for all sets <m>A</m>, <m>B</m> and <m>C</m>? 
                      Prove or give a counterexample for this formula. 
                      If the formula is false, find and prove a modification of this formula that holds for all sets.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>

        </section>

        <section xml:id="sec-families-of-sets"><title>Families of Sets</title>
          
          <definition xml:id="def-family-of-sets">
            <statement>
              <p>
                Let <m>A</m> be a set. 
                The set <m>A</m> is called a <term>family of sets</term> if all the elements of A are sets. 
                The family of sets <m>A</m> is <term>indexed</term> by <m>I</m>, denoted <m>A = \{A_i\}_{i\in I}</m>, if there is a non-empty set <m>I</m> such that there is an element <m>A_i\in  A</m> for each <m>i\in  I</m>, and that every element of <m>A</m> equals <m>A_i</m> for exactly one <m>i\in  I</m>. 
              </p>
            </statement>
          </definition>

          <remark>
            <p>
              Convention for <m>I</m> vs. <m>\alpha</m> for indexing sets.
            </p>
          </remark>

          <definition xml:id="def-union-intersection-2">
            <statement>
              <p>
                Let <m>A</m> be a family of sets. 
                The <term>union</term> of the sets in <m>A</m>, denoted <m>\bigcup_{X\in A} X</m>, is defined as follows. 
                If <m>A \neq \emptyset</m>, then 
                <me>\bigcup {X\in A} X = \{x | x\in  A \text{ for some }A\in  A\};</me>
                if <m>A = \emptyset</m>, then <m>\bigcup{X\in A} X = \emptyset</m>. 
                The <term>intersection</term> of the sets in <m>A</m>, denoted <m>\bigcap{X\in A} X</m>, is defined as follows. 
                If <m>A \neq\emptyset</m>, then
                <me>\bigcap {X\in A} X = \{x | x\in  A \text{ for all } A\in  A\};</me>
                if <m>A = \emptyset</m>, then <m>\bigcap{X\in A} X</m> is not defined.
                If <m>A = \{A_i\}i\in I</m> is indexed by a set <m>I</m>, then we write
                <me>\bigcup {i\in I}A_i = \{x | x\in  A_i \text{ for some }i\in  I\} \text{ and } \bigcap{i\in I}A_i = \{x | x\in  A_i \text{ for all } i\in  I\}</me> 
                to denote the union and intersection of the sets in <m>A</m>, respectively. 
              </p>
            </statement>
          </definition>

          <p>
            Intuitively, the set <m>\bigcup i\in I A_i</m> is the set that contains everything that is in at least one of the sets <m>A_i</m>; the set <m>\bigcap  i\in I A_i</m> is the set containing everything that is in all of the sets <m>A_i</m>. 
            The same holds for the non-indexed notation.
          </p>

          <theorem xml:id="thm-properties-of-families">
            <statement>
              <p>
                Let <m>I</m> be a non-empty set, let <m>\{A_i\}i\in I</m> be a family of sets indexed by <m>I</m> and let <m>B</m> be a set.
                <ol>
                  <li>
                    <p>
                      <m>\bigcap i\in I A_i \subseteq  A k</m> for all <m>k\in  I</m>. 
                      If <m>B \subseteq  A k</m> for all <m>k\in  I</m>, then <m>B \subseteq\bigcap i\in I A_i</m> .
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>Ak \subseteq\bigcup  i\in I A_i</m> for all <m>k\in  I</m>. 
                      If <m>A k \subseteq B</m> for all <m>k\in  I</m>, then <m>\bigcup  i\in I A_i \subseteq B</m>.
                    </p>
                  </li>

                  <li><title>Distributive Law</title>
                    <p>
                      <m>B \cap  (\bigcup  i\in I A_i) = \bigcup i\in I (B \cap  A_i)</m>.
                    </p>
                  </li>

                  <li><title>Distributive Law</title>
                    <p>
                      <m>B \cup  (\bigcap i\in I A_i) = \bigcap i\in I (B \cup  A_i)</m>.
                    </p>
                  </li>

                  <li><title>De Morgan's Law</title>
                    <p>
                      <m>B - (\bigcup i\in I A_i) = \bigcap i\in I (B - A_i)</m>.
                    </p>
                  </li>

                  <li><title>De Morgan's Law</title>
                    <p>
                      <m>B - (\bigcap i\in I A_i) = \bigcup i\in I (B - A_i)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>
          
        </section>

      </chapter>

      <chapter xml:id="ch-functions"><title>Functions</title>

        <section xml:id="sec-function-basics"><title>Function Basics</title>
          
          <definition xml:id="def-function">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                A <term>function</term> (also called a <term>map</term>) <m>f</m> from <m>A</m> to <m>B</m>, denoted <m>f : A \to B</m>, is a subset <m>F \subseteq  A \times B</m> such that for each <m>a\in  A</m>, there is one and only one pair in <m>F</m> of the form <m>(a, b)</m>. 
                The set <m>A</m> is called the <term>domain</term> of <m>f</m> and the set <m>B</m> is called the <term>codomain</term> of <m>f</m>. 
              </p>
            </statement>
          </definition>
          
          <example>
            <p>
              <ul>
                <li>
                  <p>
                    A <term>constant map</term> <m>f : A \to B</m> is any function of the form <m>f (x) = b</m> for all <m>x\in  A</m>, where <m>b\in B</m> is some fixed element.
                  </p>
                </li>

                <li>
                  <p>
                    The <term>identity map</term> on <m>A</m> is the function <m>1_A : A \to  A</m> defined by <m>1_A(x) = x</m> for all <m>x\in  A</m>.
                  </p>
                </li>

                <li>
                  <p>
                    The <term>inclusion map</term> from <m>S</m> to <m>A</m> is the function <m>j : S \to  A</m> defined by <m>j(x) = x</m> for all <m>x\in  S</m>
                  </p>
                </li>

                <li>
                  <p>
                    If <m>f : A \to B</m> is a function, the <term>restriction</term> of <m>f</m> to <m>S</m>, denoted <m>f|_S</m>, is the function <m>f|_S : S \to B</m> defined by <m>f|_S(x) = f (x)</m> for all <m>x\in  S</m>.
                  </p>
                </li>

                <li>
                  <p>
                    If <m>g : S \to B</m> is a function, an <term>extension</term> of <m>g</m> to <m>A</m> is any function <m>G : A \to B</m> such that <m>G|S = g</m>.
                  </p>
                </li>

                <li>
                  <p>
                    The <term>projection maps</term> from <m>A \times B</m> are the functions <m>π_1 : A \times B \to  A</m> and <m>π_2 : A \times B \to B</m> defined by <m>π_1((a, b)) = a</m> and <m>π_2((a, b)) = b</m> for all <m>(a, b)\in A \times B</m>. 
                    For any finite collection of sets <m>A1, \dots, A p</m>, projection maps
                    <me>π_i : A1 \times\cdots \times  A p \to  A_i</me>
                    for all <m>i\in  {1, \dots, p}</m> can be defined similarly.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>X</m> be a non-empty set, and let <m>S \subseteq  X</m> be a subset. 
                    The <term>characteristic map</term> for <m>S</m> in <m>X</m>, denoted <m>χS</m>, is the function <m>χS : X \to  {0, 1}</m> defined by
                    <me>
                      χS(y) =
                      \begin{cases}
                        1, &amp; if y\in  S//
                        0, &amp; if y\in  X - S.
                      \end{cases}
                    </me>
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <exercise>
            <statement>
              <p>
                Let <m>A</m>, <m>B \subseteq  X</m> be subsets. 
                Prove that <m>χA = χB</m> if and only if <m>A = B</m>. 
                
              </p>
            </statement>

            <hint>
              <p>
                Observe that “<m>χA = χB</m>” is a statement of equality of functions, whereas “<m>A = B</m>” is a statement of equality of sets.
              </p>
            </hint>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                A partial function from <m>A</m> to <m>B</m> is a function of the form <m>f J : J \to B</m>, where <m>J \subseteq  A</m>. 
                We can think of partial functions from <m>A</m> to <m>B</m> as subsets of <m>A \times B</m> that satisfy a certain condition.
                Let <m>f J</m> and <m>gK</m> be partial functions from <m>A</m> to <m>B</m>. Prove that <m>f J \subseteq  g K</m> if and only if <m>J \subseteq  K</m> and <m>gK |J = f J</m>.
              </p>
            </statement>
          </exercise>

        </section>

        <section xml:id="sec-image-and-pre-image"><title>Image and Preimage</title>
          
          <definition xml:id="def-image">
            <statement>
              <p>
                Let <m>P \subseteq  A</m>. 
                The <term>image</term> of <m>P</m> under <m>f</m>, denoted <m>f(P)</m>, is the set defined by
                <me>f (P) = {b\in B | b = f (p) for some p\in  P}.</me>
                The <term>range</term> of <m>f</m> (also called the image of <m>f</m> ) is the set <m>f(a)</m>.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-preimage">
            <statement>
              <p>
                Let <m>Q \subseteq B</m>. 
                The <term>inverse image</term> of <m>Q</m> under <m>f</m>, denoted <m>f\inv (Q)</m>, is the set defined by 
                <me>f\inv(Q) = {a\in  A | f(a)\in  Q}.</me> 
              </p>
            </statement>
          </definition>

          <theorem xml:id="thm-properties-of-image-preimage">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, let <m>C, D \subseteq  A</m> and <m>S,\sqcap \subseteq B</m> be subsets, and let <m>f : A \to B</m> be a function. 
                Let <m>I</m> and <m>K</m> be non-empty sets, let <m>{Ui}i\in I</m> be a family of subsets of <m>A</m> indexed by <m>I</m>, and let <m>{Vk}k\in K</m> be a family of subsets of <m>B</m> indexed by <m>K</m>.

                <ol>
                  <li>
                    <p>
                      <m>f ( \es ) = \es </m> and <m>f\inv ( \es ) = \es </m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f\inv (B) = A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f (C) \subseteq  S</m> if and only if <m>C \subseteq  f\inv (S)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>C \subseteq  D</m>, then <m>f (C) \subseteq  f (D)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>S \subseteq  T</m>, then <m>f\inv (S) \subseteq  f\inv (T )</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f (\bigcup i\in I Ui) = \bigcup i\in I f (Ui)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f (⋂i\in I Ui) \subseteq  ⋂i\in I f (Ui)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f\inv  (\bigcup k\in K Vk) = \bigcup k\in K f\inv (Vk)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f\inv  (⋂k\in K Vk) = ⋂k\in K f\inv (Vk)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, let <m>P, Q \subseteq  A</m> be subsets and let <m>f : A \to B</m> be a function.
                <ol>
                  <li>
                    <p>
                      Prove that <m>f (P) - f (Q) \subseteq  f (P - Q)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Is it necessarily the case that <m>f (P - Q) \subseteq  f (P) - f (Q)</m>?
                      Give a proof or a counterexample.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>

        </section>

        <section xml:id="sec-composition-and-inverse-functions"><title>Composition and Inverse Functions</title>
          
          <definition xml:id="def-composition">
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets, and let <m>f : A \to B</m> and <m>g : B \to  C</m> be functions.
                The composition of <m>f</m> and <m>g</m> is the function <m>g \circ  f : A \to  C</m> defined by
                <me>(g \circ  f )(x) = g( f (x))</me>
                for all <m>x\in  A</m>. 
              </p>
            </statement>
          </definition>

          <theorem xml:id="thm-properties-of-composition">
            <statement>
              <p>
                Let <m>A, B, C</m> and <m>D</m> be sets, and let <m>f : A \to B</m> and <m>g : B \to  C</m> and <m>h : C \to  D</m> be functions.
                <ol>
                  <li>
                    <p>
                      <m>(h \circ  g) \circ  f = h \circ  (g \circ  f )</m> (Associative Law).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>f \circ  1A = f and 1B \circ  f = f</m> (Identity Law).
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <definition xml:id="def-left-right-inverse">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, and let <m>f : A \to B</m> and g : <m>B \to  A</m> be functions.
                <ul>
                  <li>
                    <p>
                      The function <m>g</m> is a right inverse for <m>f</m> if <m>f \circ  g = 1B</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>g</m> is a left inverse for <m>f</m> if <m>g \circ  f = 1A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>g</m> is an inverse for <m>f</m> if it is both a right inverse and a left inverse. 
                    </p>
                  </li>
                </ul>
              </p>
            </statement>
          </definition>

          <theorem xml:id="thm-inverse-properties">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, and let <m>f : A \to B</m> be a function.
                <ol>
                  <li>
                    <p>
                      If <m>f</m> has an inverse, then the inverse is unique.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>f</m> has a right inverse <m>g</m> and a left inverse <m>h</m>, then <m>g = h</m>, and hence <m>f</m> has an inverse.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>g</m> is an inverse of <m>f</m>, then <m>f</m> is an inverse of <m>g</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <convention>
            <p>
              Let <m>A</m> and <m>B</m> be sets, and let <m>f : A \to B</m> be a function. 
              If <m>f</m> has an inverse, the inverse is denoted <m>f\inv  : B \to  A</m>. 
            </p>
          </convention>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, let <m>U \subseteq  A</m> and <m>V \subseteq  C</m> be subsets, and let <m>f : A \to B</m> and <m>g : B \to  C</m> be functions. 
                Prove that
                <me>(g \circ  f )(U) = g( f (U)) and (g \circ  f )-1(V ) = f\inv (g-1(V ))</me>.
              </p>
            </statement>
          </exercise>
          
        </section>

        <section xml:id="sec-inject-surject-biject"><title>Injectivity, Surjectivity, Bijectivty</title>
          
          <definition xml:id="def-jectivity">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, and let <m>f : A \to B</m> be a function.
                <ul>
                  <li>
                    <p>
                      The function <m>f</m> is injective (also called one-to-one or monic) if <m>x \neq  y</m> implies <m>f (x) \neq  f (y)</m> for all <m>x, y\in  A</m>; equivalently, if <m>f (x) = f (y)</m> implies <m>x = y</m> for all <m>x, y\in  A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>f</m> is surjective (also called onto or epic) if for every <m>b\in B</m>, there exists some <m>a\in  A</m> such that <m>f(a) = b</m>; equivalently, if <m>f(a) = B</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>f</m> is bijective if it is both injective and surjective.
                    </p>
                  </li>
                </ul>
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    Let <m>k : [0, ∞) \to  [0, ∞)</m> be defined by <m>k(x) = x2</m> for all <m>x\in  [0, ∞)</m>. 
                    This function is surjective and injective, and hence bijective. 
                    First, we show that <m>k</m> is injective. Let <m>x, y\in  [0, ∞)</m>. 
                    Suppose that <m>k(x) = k(y)</m>. 
                    Then <m>x2 = y2</m>. 
                    It follows that <m>√x2 = √y2</m>, and because <m>x ≥ 0</m> and <m>y ≥ 0</m>, we deduce that <m>x = √x2 = √y2 = y</m>. 
                    Hence <m>k</m> is injective. Second, we show that <m>k</m> is surjective. 
                    Let <m>b\in  [0, ∞)</m>. 
                    Then <m>√b\in  [0, ∞)</m>, and so <m>k(√b) = (√b)2 = b</m>. 
                    Hence k is surjective.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>g : [0, ∞) \to  R</m> be defined by <m>g(x) = x2</m> for all <m>x\in  [0, ∞)</m>. 
                    This function is injective but not surjective. 
                    The proof of the injectivity of <m>g</m> is the same as the proof of the injectivity of the function <m>k</m> in Part (1) of this example. 
                    The reason that <m>g</m> is not surjective is that <m>g(a) \neq  -2</m> for any <m>a\in  [0, ∞)</m>, though <m>-2</m> is in the codomain of <m>g</m>.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>h : R \to  [0, ∞)</m> be defined by <m>h(x) = x2</m> for all <m>x\in  R</m>. 
                    This function is surjective but not injective. 
                    The proof of the surjectivity of <m>h</m> is the same as the proof of the surjectivity of the function <m>k</m> in Part (1) of this example. 
                    The reason <m>h</m> is not injective is because <m>h(-3) = 9 = h(3)</m> even though <m>-3 \neq  3</m>. 
                    (Observe that instead of <m>±3</m> we could have used <m>±a</m> for any positive number <m>a</m>, but a single instance where the definition of injectivity fails is sufficient.)
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>f : R \to  R</m> be defined by <m>f (x) = x2</m> for all <m>x\in  R</m>. 
                    This function is neither injective nor surjective, which is seen using the same arguments as the corresponding arguments for <m>g</m> and <m>h</m> in Parts (2) and (3) of this example.
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <lemma>
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets, and let <m>f : A \to B</m> and <m>g : B \to  C</m> be functions.
                <ol>
                  <li>
                    <p>
                      If <m>f</m> and <m>g</m> are injective, then <m>g \circ  f</m> is injective.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>f</m> and <m>g</m> are surjective, then <m>g \circ  f</m> is surjective.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>f</m> and <m>g</m> are bijective, then <m>g \circ  f</m> is bijective.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </lemma>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be non-empty sets, and let <m>f : A \to B</m> be a function.
                <ol>
                  <li>
                    <p>
                      The function <m>f</m> has a right inverse if and only if <m>f</m> is surjective.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>f</m> has a left inverse if and only if <m>f</m> is injective.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>f</m> has an inverse if and only if <m>f</m> is bijective.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be non-empty sets, and let <m>f : A \to B</m> be a function.
                <ol>
                  <li>
                    <p>
                      The function <m>f</m> is injective if and only if <m>f \circ  g = f \circ  h</m> implies <m>g = h</m> for all functions g<m>, h : Y \to  A</m> for all sets <m>Y</m> .
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>f</m> is surjective if and only if <m>g \circ  f = h \circ  f</m> implies <m>g = h</m> for all functions <m>g, h : B \to  X</m> for all sets <m>X</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, and let <m>S \subseteq  A</m> be a subset
                <ol>
                  <li>
                    <p>
                      Prove that the identity map <m>1A : A \to  A</m> is bijective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Prove that inclusion map <m>j : S \to  A</m> is injective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>f : A \to B</m> be a function. 
                      Suppose that <m>f</m> is injective. 
                      Is the restriction <m>f |S</m> necessarily injective? 
                      Give a proof or a counterexample.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>g : A \to B</m> be a function. 
                      Suppose that <m>g</m> is surjective. 
                      Is the restriction <m>g|S</m> necessarily surjective? 
                      Give a proof or a counterexample.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>h : S \to B</m> be a function, and let <m>H : A \to B</m> be an extension of <m>h</m>. 
                      Suppose that <m>h</m> is injective. 
                      Is <m>H</m> necessarily injective?
                      Give a proof or a counterexample.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>k : S \to B</m> be a function, and let <m>K : A \to B</m> be an extension of <m>k</m>. 
                      Suppose that <m>k</m> is surjective. 
                      Is <m>K</m> necessarily surjective? Give a proof or a counterexample.
                    </p>
                  </li>

                  <li>
                    <p>
                      Prove that the projection maps <m>π1 : A \times B \to  A</m> and <m>π2 : A \times B \to B</m> are surjective. 
                      Are the projection maps injective?
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets. 
                Prove that there is a bijective function <m>g : (A \times B) \times C \to  A \times  (B \times C)</m>.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, let <m>P, Q \subseteq  A</m> be subsets and let <m>f : A \to B</m> be a function. 
                Suppose that <m>f</m> is injective.
                Prove that <m>f (P - Q) = f (P) - f (Q)</m>. 
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, and let <m>f : A \to B</m> and <m>g : B \to  A</m> be functions.
                <ol>
                  <li>
                    <p>
                      Suppose that <m>f</m> is injective, and that <m>g</m> is a left inverse of <m>f</m>. 
                      Prove that <m>g</m> is surjective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Suppose that <m>f</m> is surjective, and that <m>g</m> is a right inverse of <m>f</m>. 
                      Prove that <m>g</m> is injective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Suppose that <m>f</m> is bijective, and that <m>g</m> is the inverse of <m>f</m>.
                      Prove that <m>g</m> is bijective.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets, and let <m>f : A \to B</m> and <m>g : B \to  C</m> be functions.
                <ol>
                  <li>
                    <p>
                      Prove that if <m>g \circ  f</m> is injective, then <m>f</m> is injective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Prove that if <m>g \circ  f</m> is surjective, then <m>g</m> is surjective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Prove that if <m>g \circ  f</m> is bijective, then <m>f</m> is injective, and <m>g</m> is surjective.
                    </p>
                  </li>

                  <li>
                    <p>
                      Find an example of functions <m>f : A \to B</m> and <m>g : B \to  C</m> such that <m>g \circ  f</m> is bijective, but <m>f</m> is not surjective, and <m>g</m> is not injective. 
                      Hence Parts (1)-(3) of this exercise are the best possible results.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>
          
        </section>

      </chapter>

      <chapter xml:id="ch-relations"><title>Relations</title>

        <section xml:id="sec-relation-basics"><title>Relation Basics</title>
          
          <definition xml:id="def-relation">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                A relation <m>R</m> from <m>A</m> to <m>B</m> is a subset <m>R \subseteq  A \times B</m>.
                If <m>a\in  A</m> and <m>b\in B</m>, we write <m>a R b</m> if <m>(a, b)\in  R</m>, and <m>a \notR b</m> if <m>(a, b) \not\in  R</m>. 
                A relation on <m>A</m> is a relation from <m>A</m> to <m>A</m>. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    Let <m>P</m> be the set of all people. 
                    Define a relation on <m>P</m> by having person <m>x</m> related to person <m>y</m> if and only if <m>x</m> and <m>y</m> have at least one parent in common.
                  </p>
                </li>

                <li>
                  <p>
                    The symbols &lt; and <m>\leq </m> both represent relations on <m>\R</m>.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>A</m> be a set. 
                    The symbol “<m>\subseteq </m>” represents a relation on <m>\cP (A)</m>, where <m>P</m>, <m>Q\in\cP (A)</m> are related if and only if <m>P \subseteq  Q</m>.
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <proposition xml:id="prop-functions-are-relations">
            <statement>
              <p>
                Let <m>f : A \to B</m> be a function. 
                Then <m>f</m> is defined by a subset of <m>A \times B</m> satisfying a certain condition. 
                Hence <m>f</m> is also a relation from <m>A</m> to <m>B</m>. 
              </p>
            </statement>
          </proposition>

          <p>
            The concept of a relation is therefore seen to be more general than the concept of a function.
          </p>

          <remark>
            <p>
              In principle, it would have been logical to have the chapter on relations before the chapter on functions, and to view functions as a special case of relations. 
              In practice, however, most mathematicians do not think of functions as special types of relations when they use functions on a daily basis, and therefore functions deserve their own treatment independent of the study of relations. 
            </p>
          </remark>

          <definition xml:id="def-relation-class">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be non-empty sets, let <m>R</m> be a relation from <m>A</m> to <m>B</m>, and let <m>x\in  A</m>. The relation class of <m>x</m> with respect to <m>R</m>, denoted <m>R [x]</m>, is the set defined by
                <me>R [x] = \{y\in B | x R y\}</me>.
                If the relation <m>R</m> is understood from the context, we will often write <m>[x]</m> instead of <m>R [x]</m>.
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    There are a number of distinct cases here, and we will examine a few of them.
                    If <m>x</m> is the only child of each of her parents, then <m>[x] = \{x\}</m>, where we observe that <m>x</m> has the same parents as herself. If <m>y</m> and <m>z</m> are the only two children of each of their parents, then <m>[y] = \{y, z\} = [z]</m>. 
                    If <m>a</m> has one half-sibling <m>b</m> by her father, and another half-sibling <m>c</m> by her mother, and each of <m>b</m> and <m>c</m> has no other siblings or half-siblings, then <m>[a] = \{a, b, c\}</m>, and <m>[b] = \{a, b\}</m>, and <m>[c] = \{a, c\}</m>.
                  </p>
                </li>

                <li>
                  <p>
                    For the relation &lt;, we see that <m>[x] = (x, ∞)</m> for all <m>x\in\R</m>, and for the relation <m>\leq </m>, we see that <m>[x] = [x, ∞)</m> for all <m>x\in\R</m>.
                  </p>
                </li>
              </ul>
            </p>
          </example>

        </section>

        <section xml:id="sec-congruence"><title>Congruence</title>
        
          <definition xml:id="def-congruent">
            <statement>
              <p>
                Let <m>n\in\N</m>, and let <m>a, b\in\Z</m>. The number <m>a</m> is congruent to the number <m>b</m> modulo <m>n</m>, denoted <m>a \equiv  b (mod n)</m>, if <m>a - b = kn</m> for some <m>k\in\Z</m>.
              </p>
            </statement>
          </definition>

          <example>
            <p>
              We see that <m>19 \equiv  -5 (mod 4)</m>, because <m>19 - (-5) = 24 = 6 · 4</m>; and <m>7 \equiv  7 (mod 3)</m>, because <m>7 - 7 = 0 = 0 · 3</m>; and <m>13 \not\equiv  2 (mod 9)</m>, because <m>13 - 2 = 11</m> and <m>11</m> is not a multiple of <m>9</m>.
            </p>
          </example>

          <lemma xml:id="lem-modular-equivalence">
            <statement>
              <p>
                Let <m>\n\in  N</m>, and let <m>a, b, c\in\Z</m>.
                <ol>
                  <li>
                    <p>
                      <m>a \equiv  a (mod n)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>a \equiv b (mod n)</m> then <m>b \equiv  a (mod n)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>a \equiv b (mod n)</m> and <m>b \equiv  c (mod n)</m>, then <m>a \equiv  c (mod n)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ol>
                  <li>
                    <p>
                      Observe that<m> a - a = 0 · n</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Suppose that <m>a \equiv b (mod n)</m>. Then <m>a-b = kn</m> for some <m>k\in\Z</m>. 
                      Hence <m>b-a = (-k)n</m>. 
                      Because <m>-k\in\Z</m>, it follows that <m>b \equiv  a (mod n)</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Suppose that <m>a \equiv b (mod n)</m> and <m>b \equiv  c (mod n)</m>. 
                      Then <m>a-b = kn</m> and <m>b-c = jn</m> for some <m>k, j\in\Z</m>. 
                      Adding these two equations we obtain <m>a-c = (k + j)n</m>. 
                      Because <m>k + j\in\Z</m>, it follows that <m>a \equiv  c (mod n)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </proof>
          </lemma>

          <theorem>
            <statement>
              <p>
                Let <m>n\in\N</m>, and let <m>a\in\Z</m>. 
                Then there is a unique <m>r\in\{0, \dots, n - 1\}</m> such that <m>a \equiv  r (mod n)</m>.
              </p>
            </statement>

            <proof>
              <p>
                To prove uniqueness, suppose that there are <m>x, y\in\{0, \dots, n - 1\}</m> such that <m>a \equiv  x (mod n)</m> and <m>a \equiv  y (mod n)</m>. 
                It follows from Lemma 5.2.3 (2) that <m>x \equiv  a (mod n)</m>, and from Lemma 5.2.3 (3) that <m>x \equiv  y (mod n)</m>. 
                That is, we have <m>x - y = pn</m> for some <m>p\in\Z</m>. 
                On the other hand, because <m>x, y\in\{0, \dots, n - 1\}</m>, it follows that <m>-(n - 1) \leq  x - y \leq  n - 1</m>. 
                We deduce that <m>p = 0</m>, and hence that <m>x = y</m>.
                To prove existence, we use the Division Algorithm (Theorem A.5) to deduce that there are <m>q, r\in\Z</m> such that <m>a = nq + r</m> and <m>0 \leq  r &lt; n</m>. 
                Hence <m>a - r = qn</m>, and therefore <m>a \equiv  r (mod n)</m>. 
              </p>
            </proof>
          </theorem>

          <corollary>
            <statement>
              <p>
                Let <m>n\in\N</m>, and let <m>a\in\Z</m>. 
                Then precisely one of the following holds:
                either <m>a = nk</m> for some <m>k\in\Z</m>, or <m>a = nk + 1</m> for some <m>k\in\Z</m>, or <m>a = nk + 2</m> for some <m>k\in\Z</m>, \dots, or <m>a = nk + (n - 1)</m> for some <m>k\in\Z</m>.
              </p>
            </statement>
          </corollary>

          <corollary>
            <statement>
              <p>
                Let <m>a\in\Z</m>. 
                Then <m>a</m> is even or odd, but not both.
              </p>
            </statement>
          </corollary>
          
          <theorem xml:id="thm-modular-partition">
            <statement>
              <p>
                Let <m>n\in\N</m>.
                <ol>
                  <li>
                    <p>
                      Let <m>a, b\in\Z</m>. If <m>a \equiv b (mod n)</m>, then <m>[a] = [b]</m>. If <m>a \not\equiv b (mod n)</m>, then [<m>a] ∩ [b] = \es</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>[0] \cup  [1] \cup\dots\cup  [n - 1] = \Z</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ol>
                  <li>
                    <p>
                      Suppose that <m>a \equiv b (mod n)</m>. 
                      Let <m>x\in  [a]</m>. 
                      Then by the definition of relation classes we know that <m>a \equiv  x (mod n)</m>. 
                      By Lemma 5.2.3 (2) it follows that <m>b \equiv  a (mod n)</m>, and hence by Lemma 5.2.3 (3) we deduce that <m>b \equiv  x (mod n)</m>. 
                      Therefore <m>x\in  [b]</m>, and hence <m>[a] \subseteq  [b]</m>. 
                      A similar argument shows that <m>[b] \subseteq  [a]</m>. 
                      We conclude that <m>[a] = [b]</m>.
                    </p>

                    <p>
                      Now assume that <m>a \not\equiv b (mod n)</m>. 
                      We use proof by contradiction. 
                      Suppose that <m>[a] ∩ [b] \neq \es</m>.
                      Hence there is some <m>y\in  [a] ∩ [b]</m>. 
                      Then <m>y\in  [a]</m> and <m>y\in  [b]</m>, so that <m>a \equiv  y (mod n)</m> and <m>b \equiv  y (mod n)</m>. 
                      By Lemma 5.2.3 (2) we see that <m>y \equiv b (mod n)</m>, and by Lemma 5.2.3 (3) it follows that <m>a \equiv b (mod n)</m>, which is a contradiction. 
                      We conclude that <m>[a] ∩ [b] = \es</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      By definition <m>[a] \subseteq  Z</m> for all <m>a\in\Z</m>, and therefore [<m>0] \cup\dots\cup  [n - 1] \subseteq\Z</m>. 
                      Let <m>x\in\Z</m>. 
                      By Theorem 5.2.4 there is a unique <m>r\in\{0, \dots, n-1\}</m> such that <m>x \equiv  r (mod n)</m>.
                      It follows from Lemma 5.2.3 (2) that <m>r \equiv  x (mod n)</m>. 
                      Hence <m>x\in  [r]</m>. 
                      Because <m>r\in\{0, \dots, n - 1\}</m>, it follows that <m>x\in  [0] \cup\dots\cup  [n - 1]</m>. 
                      Therefore <m>\Z \subseteq  [0] \cup\dots\cup  [n - 1]</m>.
                      We conclude that <m>[0] \cup\dots\cup  [n - 1] = \Z</m>. 
                    </p>
                  </li>
                </ol>
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-integers-modulo">
            <statement>
              <p>
                Let <m>n\in\N</m>. 
                The set of integers modulo <m>n</m>, denoted <m>\Z/n</m>, is the set defined by <m>\Z/n = \{[0], [1], \dots, [n - 1]\}</m>, where the relation classes are for congruence modulo <m>n</m>. 
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              The set <m>\Z/n</m> is also denoted <m>\Z/n\Z</m> in some texts, for reasons that will become apparent if the reader learns about group theory.
            </p>
          </convention>

          <example><title>Like Clockwork</title>
            <p>
              The integers modulo <m>12</m> is the set <m>\Z/12 = \{[0], [1], \dots, [11]\}</m>. 
              This set has <m>12</m> elements, each of which is itself a set (namely, a relation class), but which is viewed here as a single element in the set <m>\Z/12</m>.
              The relation classes in <m>\Z/12</m> could each be described differently. 
              For example, we see that <m>[0] = [12]</m>, and so <m>\Z/12 = \{[12], [1], \dots, [11]\}</m>, which is what we see on the face of a clock. 
              For mathematical purposes it is more convenient to write <m>[0]</m> rather than <m>[12]</m>, and so we will continue to write <m>\Z/12</m> as we did originally; it would also be nice to have the <m>12</m> on clocks replaced with <m>0</m>, but historical practice holds sway over mathematics in this situation. 
              There are, of course, many other ways to rewrite the elements of <m>\Z/12</m>, for example <m>\Z/12 = \{[-36], [25], [-10], \dots, [131]\}</m>, and so it would in principle be possible to replace the number on a clock with <m>-36, 25, -10, \dots, 131</m>, though presumably only mathematicians would find that amusing. 
            </p>
          </example>

          <definition xml:id="def-modular-arithmetic">
            <statement>
              <p>
                Let <m>n\in\N</m>. Let <m>+</m> and <m>·</m> be the binary operations on <m>\Z\n</m> defined by <m>[a] + [b] = [a + b]</m> and <m>[a] · [b] = [ab]</m> for all <m>[a], [b]\in\Z/n</m>. 
              </p>
            </statement>
          </definition>

          <lemma>
            <statement>
              <p>
                Let <m>n\in\N</m>, and let <m>a, b, c, d\in\Z</m>. 
                Suppose that <m>a \equiv  c (mod n)</m> and <m>b \equiv  d (mod n)</m>. 
                Then <m>a + b \equiv  c + d (mod n)</m> and <m>ab \equiv  cd (mod n)</m>.
              </p>
            </statement>

            <proof>
              <p>
                There exist <m>k, j\in\Z</m> such that <m>a - c = kn and b - d = jn</m>. 
                Then <m>a = c + kn</m> and<m> b = d + jn</m>, and therefore
  a + b = (c + kn) + (d + jn) = c + d + (k + j)n,
  ab = (c + kn)(d + jn) = cd + (c j + dk + k jn)n.
                The desired result now follows. 
              </p>
            </proof>
          </lemma>

          <theorem>
            <statement>
              <p>
                Let <m>n\in\N</m>, and let <m>[a], [b], [c], [d]\in\Z/n</m> . 
                Suppose that <m>[a] = [c]</m> and <m>[b] = [d]</m>. 
                Then <m>[a + b] = [c + d]</m> and <m>[ab] = [cd]</m>.
              </p>
            </statement>
          </theorem>

          <definition xml:id="def-canonical-congruence-map">
            <statement>
              <p>
                Let <m>n\in\N</m>. 
                The canonical map for congruence modulo <m>n</m> is the function <m>\gamma  : \Z \to\Z/n</m> defined by <m>\gamma (a) = [a]</m> for all <m>a\in  Z</m>.
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              Observe that there is a distinct function <m>\gamma </m> for each <m>n\in\N</m>, but to avoid unnecessarily cumbersome notation (such as <m>\gamma _n</m>), we will assume that the number <m>n</m> is always known from the context.
            </p>
          </convention>

          <remark>
            <p>
              The canonical map <m>\gamma  : \Z \to\Z/n</m> is a special case of a more general type of canonical map that will be seen in Definition 5.3.8.
            </p>
          </remark> 

          <exercise>
            <statement>
              <p>
                Let <m>n\in\N</m>, and let <m>a, b\in\Z</m>. Then <m>\gamma (a+b) = \gamma (a)+\gamma (b)</m> and <m>\gamma (ab) =\gamma (a) · \gamma (b)</m>.
              </p>
            </statement>
          </exercise>
          
        </section>

        <section xml:id="sec-equivalence-relations"><title>Equivalence Relations</title>
        
          <definition xml:id="def-r-s-t">
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>R</m> be a relation on <m>A</m>.
                <ol>
                  <li>
                    <p>
                      The relation <m>R</m> is reflexive if <m>x R x</m>, for all <m>x\in  A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The relation <m>R</m> is symmetric if <m>x R y</m> implies <m>y R x</m>, for all <m>x, y\in  A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The relation <m>R</m> is transitive if <m>x R y</m> and <m>y R z</m> imply <m>x R z</m>, for all <m>x, y, z\in  A</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ol>
                <li>
                  <p>
                    The relation <m>\leq </m> on <m>R</m> is reflexive and transitive, but not symmetric.
                  </p>
                </li>

                <li>
                  <p>
                    The relation of one person being the cousin of another is symmetric, but neither reflexive nor transitive.
                  </p>
                </li>

                <li>
                  <p>
                    The relation of one person being the daughter of another person is neither reflexive, symmetric nor transitive.
                  </p>
                </li>
              </ol>
            </p>
          </example>

          <definition xml:id="def-equivalence-relation">
            <statement>
              <p>
                Let <m>A</m> be a set, and let <m>\sim </m> be a relation on <m>A</m>. 
                The relation <m>\sim </m> is an equivalence relation if it is reflexive, symmetric and transitive.
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              We use <m>\sim</m> for equivalence relations. 
            </p>
          </convention>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    Equality
                  </p>
                </li>

                <li>
                  <p>
                    Being the same age
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <corollary xml:id="cor-congruence-equivalence-relation">
            <statement>
              <p>
                Congruence module <m>n</m> for any <m>n\in\N</m> is an equivalene relation on <m>\Z</m>.
              </p>
            </statement>
          </corollary>

          <definition xml:id="def-equivalence-class">
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\sim</m> be an equivalence relation on <m>A</m>. 
                The relation classes of <m>A</m> with respect to <m>\sim</m> are called equivalence classes.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-quotient-set">
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\sim</m> be an equivalence relation on <m>A</m>. 
                The quotient set of <m>A</m> with respect to <m>\sim</m>, denoted <m>A/\sim</m>, is the set defined by <m>A/\sim  = \{[x] | x\in  A\}</m>.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-canonical-map">
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\sim</m> be an equivalence relation on <m>A</m>. 
                The canonical map for <m>A</m> and <m>\sim</m>  is the function <m>\gamma  : A \to  A/\sim</m>  defined by <m>\gamma (x) = [x]</m> for all <m>x\in  A</m>. 
              </p>
            </statement>
          </definition>

          <definition xml:id="def-partition">
            <statement>
              <p>
                Let <m>A</m> be a non-empty set. 
                A partition of <m>A</m> is a family <m>\cD</m> of non-empty subsets of <m>A</m> such that
                <ol>
                  <li>
                    <p>
                      if <m>P, Q\in\cD</m> and <m>P \neq  Q</m>, then <m>P ∩ Q = \es</m>;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\bigcup _{P\in \cD} P = A</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    Let <m>\E</m> denote the set of even integers, and let <m>\O</m> denote the set of odd integers.
                    Then <m>\cD = {\E, \O}</m> is a partition of <m>\Z</m>.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>\cC = \{[n, n + 1)\}_{n\in \Z}</m>. 
                    Then <m>C</m> is a partition of <m>\R</m>.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>\cG = \{(n - 1, n + 1)\}_{n\in \Z}</m>. 
                    Then <m>G</m> is not a partition of <m>\R</m>, because it is not pairwise disjoint. 
                    For example, we observe that <m>(1 - 1, 1 + 1) ∩ (2 - 1, 2 + 1) = (1, 2)</m>. 
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <theorem xml:id="thm-equivalence-partitions">
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\sim</m> be an equivalence relation on <m>A</m>. 
                Then <m>A/\sim</m> is a partition of <m>A</m>.
              </p>
            </statement>
          </theorem>

          <corollary>
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, let <m>\sim</m> be an equivalence relation on <m>A</m> and let <m>x, y\in  A</m>. 
                Then <m>[x] = [y]</m> if and only if <m>x \sim  y</m>.
              </p>
            </statement>
          </corollary>

          <p>psi and phi stuff to come</p>
          
        </section>


      </chapter>

      <chapter xml:id="ch-induction-recursion"><title>Induction and Recursion</title>

        <section xml:id="sec-properties-of-n"><title>Properties of the Natural Numbers</title>
          <p></p>
        </section>

        <section xml:id="sec-induction"><title>Mathematical Induction</title>
          
          <theorem xml:id="thm-induction">
            <statement>
              <p>
                Let G \subseteq  N. Suppose that
                <ol>
                  <li>
                    <p>
                      1\in  G;
                    </p>
                  </li>

                  <li>
                    <p>
                      if n\in  G, then n + 1\in  G.
                    </p>
                  </li>
                </ol>
                Then G = N.
              </p>
            </statement>
          </theorem>

          <proposition>
            <statement>
              <p>
                If n\in  N, then 8n - 3n is divisible by 5.
              </p>
            </statement>

            <proof>
              <p>
                Let G = {n\in  N | 8n - 3n is divisible by 5}.
                We will use PMI to show that G = N, and it will then follow that 8n - 3n is divisible by 5 for all n\in  N, which is what we need to prove. 
                First, we observe that G \subseteq  N by definition, and hence PMI is applicable. 
                To use PMI, we need to show two things, which are that 1\in  G, and that if n\in  G then n + 1\in  G. 
                We start with the first of these.
                Observe that 8^1 - 3^1 = 5, and therefore 8^1 - 3^1 is indeed divisible by 5. 
                Hence 1\in  G, which is Part (a) of the statement of PMI.
              </p>

              <p>
                To show Part (b) of the statement of PMI, let n\in  G. 
                We then need to deduce that n + 1\in  G. 
                Because n\in  G, we know that 8n - 3n is divisible by 5, which means that there is some k\in  Z such that 8n - 3n = 5k (recall the definition of divisibility in Section 2.2). 
                To show that n+1\in  G will require showing that 8n+1 -3n+1 is divisible by 5; we can make use of our hypothesis that 8n - 3n is divisible by 5 in this proof.
                We compute
  8n+1 - 3n+1 = 8 · 8n - 3 · 3n = (5 · 8n + 3 · 8n) - 3 · 3n
  = 5 · 8n + 3 · (8n - 3n) = 5 · 8n + 3(5k) = 5(8n + 3k).
                Because n and k are integers, then 8n + 3k is an integer, and hence 8n+1 - 3n+1 is divisible by 5. 
                It follows that n + 1\in  G. 
                We have therefore proved that Part (b) of the statement of PMI holds. 
                PMI now implies that G = N, and the result is proved. 
              </p>
            </proof>
          </proposition>

          <proposition>
            <statement>
              <p>
                If n\in  N, then
  1 + 2 + \cdots + n = n(n + 1)
  2 . 
              </p>
            </statement>
          </proposition>

          <warning><title>Horse Induction</title>
            <p>
              We will prove that all horses have the same color. 
              More precisely, we will show that the statement “for any set of n horses, all the horses in the set have the same color,” is true for all n\in  N. 
              Because there are only finitely many horses in the world, it will then follow that all existing horses have the same color. 
              First, suppose that n = 1. 
              It is certainly true that for any set of one horse, all the horses in the set have the same color. 
              Next, suppose that the result is true for n, so that for any set of n horses, all the horses in the set have the same color. 
              We need to show that the result is true for n + 1. 
              Let {H1, \dots, Hn+1} be a set of n + 1 horses. 
              The set {H1, \dots, Hn} has n horses, so by the inductive hypothesis all the horses in this set have the same color. 
              On the other hand, the set {H2, \dots, Hn+1} also has n horses, so all horses in this set have the same color. 
              In particular, it then follows that Hn and Hn+1 have the same color. 
              Combining this fact with the previous observation that horses H1, \dots, Hn all have the same color, it follows that H1, \dots, Hn+1 all have the same color. 
              We have therefore proved the inductive step. 
              Hence all horses have the same color.
            </p>
          </warning>

          <exercise><title>Pigeonhole Principle</title>
            <statement>
              <p>
                Let k, m\in  N, and let f : {1, \dots, m} \to  {1, \dots, k} be a function. 
                Prove that if m &gt; k, then f is not injective. 
                A combinatorial interpretation of this fact is known as the Pigeonhole Principle, which says that if m objects are placed in k boxes, where m &gt; k, then there will be a box with more than one object in it.
                Though this principle may seem innocuous, it is very important in combinatorics.
              </p>
            </statement>
          </exercise>
          

        </section>

        <section xml:id="sec-recursion"><title>Recursion</title>
          <p></p>
        </section>


      </chapter>

      <chapter xml:id="ch-cardinality"><title>Cardinality</title>

        <section xml:id="sec-cardinality-of-sets"><title>Cardinality of Sets</title>
          
          <definition xml:id="def-equinumerous">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                The sets <m>A</m> and <m>B</m> are equinumerous, denoted <m>A \# B</m> (more commonly <m>|A|=|B|</m>), if there is a bijective function <m>f : A \to B</m>. 
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              Don't like the <m>\sim</m> notation.
            </p>
          </convention>

          <theorem>
            <statement>
              <p>
                
              </p>
            </statement>
          </theorem>

          <warning><title>Almost Equivalent</title>
            <p>
              Lemma 6.5.2 might lead the reader to think of <m>\#</m> as an equivalence relation, but we need to proceed with caution here. 
              If <m>\#</m> were a relation, on what set would it be a relation? 
              We might want to think of <m>\#</m> as a relation on the set of all sets, because for any two sets <m>A</m> and <m>B</m>, it must be the case that either <m>A \# B</m> or <m>A \not \# B</m>. 
              However, because of foundational problems such as Russell's Paradox, which was discussed in Section 3.5, we avoid things such as the set of all sets. 
              Hence, although <m>\#</m> satisfies the three properties of an equivalence relation, it is not technically a relation on a set at all. 
              If, however, all sets of interest are subsets of a given set <m>X</m>, then it is correct to say that <m>\#</m> is an equivalence relation on <m>\cP(X)</m>.
            </p>
          </warning>

          <definition xml:id="def-set-sizes">
            <statement>
              <p>
                Let <m>A</m> be a set.
                <ul>
                  <li>
                    <p>
                      The set <m>A</m> is said to be finite if it is either the empty set or <m>A \# \{1, \dots, n\}</m> for some <m>n\in\N</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The set <m>A</m> is said to be infinite if it is not finite.
                    </p>
                  </li>

                  <li>
                    <p>
                      The set <m>A</m> is said to be countably infinite if <m>A \# \N</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The set <m>A</m> is said to be countable (also called denumerable) if it is finite or countably infinite.
                    </p>
                  </li>

                  <li>
                    <p>
                      The set <m>A</m> is said to be uncountable if it is not countable.
                    </p>
                  </li>
                </ul>
              </p>
            </statement>
          </definition>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Suppose that <m>A \# B</m>. 
                If <m>A</m> is finite, infinite, countably infinite, countable or uncountable, then so is <m>B</m>.
              </p>
            </statement>
          </theorem>

          <theorem>
            <statement>
              <p>
                <ol>
                  <li>
                    <p>
                      The set <m>\N</m> is infinite.
                    </p>
                  </li>

                  <li>
                    <p>
                      A countably infinite set is infinite.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ol>
                  <li>
                    <p>
                      Suppose that <m>\N</m> is finite. 
                      Because <m>\N \neq \es</m>, then there is some <m>n\in\N</m> such that <m>\N \# \{1, \dots, n\}</m>. Let <m>f : \{1, \dots, n\} \to\N</m> be a bijective function. 
                      It then follows from Theorem 6.3.11 (1) that there is some <m>k\in\{1, \dots, n\}</m> such that <m>f (k) ≥ f (i)</m> for any <m>i\in\{1, \dots, n\}</m>. 
                      Therefore <m>f (k) + 1 &gt; f (i)</m> for all <m>i\in\{1, \dots, n\}</m>. 
                      Hence <m>f (k) + 1 \not\in  f (\{1, \dots, n\})</m>. 
                      Because <m>f (k) + 1\in\N,</m> we deduce that <m>f</m> is not surjective, which is a contradiction. 
                      Hence <m>N</m> is not finite, and so it is infinite.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>B</m> be a set. 
                      Suppose that <m>B</m> is countably infinite. 
                      Then <m>B \# N</m>. 
                      Suppose further that <m>B</m> is finite. 
                      It would then follow from Exercise 6.5.5 that <m>N</m> is finite, which is a contradiction to Part (1) of this lemma. 
                      Hence <m>B</m> is infinite. 
                    </p>
                  </li>
                </ol>
              </p>
            </proof>
          </theorem>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Then <m>A \not\# \cP (A)</m>.
              </p>
            </statement>

            <proof>
              <p>
                There are two cases. 
                First, suppose that <m>A = \es</m>. 
                Observe that <m>\cP (A) = \{ \es \}</m>, and therefore there cannot be a bijective function <m>\cP (A) \to  A</m>, because there cannot be a function from a non-empty set to the empty set. 
                Hence <m>\cP (A) \not\sim  A</m>.
              </p>

              <p>
                Next, suppose that <m>A \neq\es</m>. 
                Suppose further that <m>A \sim\cP (A)</m>. 
                Then there is a bijective function <m>f : A \to\cP (A)</m>. 
                Let <m>D = \{a\in  A | a /\in  f(a)\}</m>. 
                Observe that <m>D \subseteq  A</m>, and so <m>D\in\cP (A)</m>. 
                Because <m>f</m> is surjective, there is some <m>d\in  A</m> such that <m>f (d) = D</m>. 
                Is <m>d\in  D</m>? 
                Suppose that <m>d\in  D</m>. 
                Then by the definition of <m>D</m> we see that <m>d \not\in  f (d) = D</m>.
                Suppose that <m>d \not\in  D</m>. 
                Then <m>d\in  f (d) = D</m>. 
                We therefore have a contradiction, and so <m>A \not\sim\cP (A)</m>. 
              </p>
            </proof>
          </theorem>

          <corollary xml:id="cor-pn-uncountable">
            <statement>
              <p>
                The set <m>\cP (\N)</m> is uncountable.
              </p>
            </statement>

            <proof>
              <p>
                By Theorem 6.5.7 we know that <m>\cP (\N) \not\sim  N</m>, and so <m>\cP (\N)</m> is not countably infinite. 
                If we could show that <m>\cP (\N)</m> were not finite, then it would follow that it is not countable. 
                Suppose that <m>\cP (\N)</m> is finite. 
                Let <m>T = \{{n} | n\in  N\} \subseteq\cP (\N)</m>. 
                It follows from Theorem 6.6.5 (1) that <m>T</m> is finite. 
                However, it is evident that <m>T \sim\N</m>, and this would imply that <m>\N</m> is finite, which is a contradiction to Lemma 6.5.5 (1). 
                We conclude that <m>\cP (\N)</m> is uncountable. 
              </p>
            </proof>
          </corollary>

          <definition>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                We say that <m>A\into B </m>if there is an injective function <m>f : A \to B</m>.
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              Notation I like better
            </p>
          </convention>

          <theorem>
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets. Then the following hold:
                <ol>
                  <li>
                    <p>
                      <m>\es\into A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>A\into A</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A\into B</m> and <m>B\into C</m>, then <m>A\into C</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>
          
          <lemma xml:id="lem-schroder-lemma">
            <statement>
              <p>
                Let <m>A</m>, <m>B</m> and <m>C</m> be sets. 
                Suppose that <m>C \subseteq B \subseteq  A</m>, and that <m>A\into C</m>.
                Then <m>A \# B</m>.
              </p>
            </statement>
          </lemma>

          <theorem xml:id="thm-schroder-bernstein">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Suppose that <m>A\into B</m> and <m>B\into A</m>. 
                Then <m>A \# B</m>.
              </p>
            </statement>

            <proof>
              <p>
                By definition there are injective functions <m>p : A \to B</m> and <m>q : B \to  A</m>. 
                Then <m>p(A) \subseteq B</m>, and <m>q(p(A)) \subseteq  q(B) \subseteq  A</m>.
                By Exercise 6.5.4 we know that <m>q(p(A)) \#  A</m> and <m>q(B) \# B</m>. 
                From the former it follows that <m>A\into q(p(A))</m>, and we then use Lemma 6.5.11 to deduce that <m>A \#  q(B)</m>.
                Hence <m>A \# B</m>. 
              </p>
            </proof>
          </theorem>

          <example>
            <p>
              Let <m>a, b\in\R</m>. 
              Suppose that <m>a &lt; b</m>. 
              We will use the Schroeder-Bernstein Theorem (Theorem 6.5.10) to prove that <m>[a, b] \#  (a, b)</m>. 
              By Example 6.5.3 (3) we know that <m>[a, b] \#  [-1, 1]</m> and <m>(a, b) \#  (-1, 1)</m>. 
              Hence, it will suffice to prove that <m>(-1, 1) \#  [-1, 1]</m>. 
              Let <m>f : (-1, 1) \to  [-1, 1]</m> be defined by <m>f (x) = x</m> for all <m>x\in  (-1, 1)</m>, and let <m>g : [-1, 1] \to  (-1, 1)</m> be defined by <m>g(x) = x^2</m> for all <m>x\in  [-1, 1]</m>.
              Then both <m>f</m> and <m>g</m> are injective, and hence <m>(-1, 1)\into [-1, 1]</m> and <m>[-1, 1]\into (-1, 1)</m>.
              The Schroeder-Bernstein Theorem now implies that <m>[-1, 1] \#  (-1, 1)</m>, and therefore <m>[a, b] \#  (a, b)</m>.
            </p>
          </example>

          <theorem xml:id="thm-set-trichotomy">
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Then <m>A\into B</m> or <m>B\into A</m>.
              </p>
            </statement>

            <proof>
              <p>
                We need to show that there is an injective function <m>f : A \to B</m> or an injective function <m>g : B \to  A</m>. 
                If <m>A</m> or <m>B</m> is empty these functions exist trivially, so we will assume that <m>A</m> and <m>B</m> are both non-empty.
              </p>

              <p>
                A partial function from <m>A</m> to <m>B</m> is a function of the form <m>f : J \to B</m>, where <m>J \subseteq  A</m>.
                We can think of a partial function from <m>A</m> to <m>B</m> as a subset <m>F \subseteq  A \times B</m> such that for each <m>a\in  A</m>, there is at most one pair in <m>F</m> of the form <m>(a, b)</m>.
                Hence, we can apply the concepts of subset and union to partial functions from <m>A</m> to <m>B</m>.
              </p>

              <p>
                Let <m>P</m> be the set of all injective partial functions from <m>A</m> to <m>B</m>. 
                Observe that <m>P \neq\es</m>, because <m>\es \in  P</m> . 
                Let <m>C</m> be a chain in <m>P</m> . 
                We claim that <m>\bigcup _{F\in C} F\in  P</m> . 
                Suppose that <m>(a, b)</m>, <m>(a, c)\in  \bigcup F\in C C</m>, for some <m>a\in  A</m> and <m>b, c\in B</m>. 
                Then <m>(a, b)\in  G</m> and <m>(a, c)\in  H</m> for some partial functions <m>G, H\in  C</m> . 
                Because <m>CC</m> is a chain, we know that <m>G \subseteq  H</m> or <m>G ⊇ H</m>. 
                Without loss of generality assume that <m>G \subseteq  H</m>. 
                Then <m>(a, b)</m> and <m>(a, c)</m> are both in <m>H</m>, and because <m>H</m> is a partial function, then it must be the case that <m>b = c</m>. 
                We conclude that <m>\bigcup  F\in C F</m> is a partial function from <m>A</m> to <m>B</m>. 
                Next, suppose that <m>(c, e), (d, e)\in  \bigcup  F\in C C</m>, for some <m>c, d\in  A</m> and <m>e\in B</m>. 
                A similar argument shows that <m>(c, e) and (d, e)</m> must both be in some <m>K\in  C</m>, and because <m>K</m> is an injective partial function, then it must be the case that <m>c = d</m>. 
                We conclude that \bigcup <m>F\in C F</m> is an injective partial function from <m>A</m> to <m>B</m>, and hence that <m>\bigcup  F\in C F\in  P</m> .
              </p>

              <p>
                By Zorn's Lemma (Theorem 3.5.6) the family of sets <m>P</m> has a maximal element. Let <m>M\in  P</m> be such a maximal element. 
                Then <m>M</m> is an injective partial function from <m>A</m> to <m>B</m>. 
                There are now three cases. 
                First, suppose that for each <m>a\in  A</m>, there is a pair of the form <m>(a, b) in M</m>. 
                Then <m>M</m> is an injective function <m>A \to B</m>. 
                Second, suppose that for each <m>d\in B</m>, there is a pair of the form <m>(c, d)\in  M</m>. 
                Then <m>M</m> is a bijective partial function from <m>A to B</m>, and using Exercise 4.4.13 (3) we see that the inverse function of <m>M</m> can be viewed as an injective function <m>B \to  A</m>. 
                Third, suppose that neither of the previous two cases holds. 
                Then there is some <m>x\in  A</m> such that there is no pair of the form <m>(x, b)</m> in <m>M</m>, and there is some <m>y\in B</m> such that there is no pair of the form <m>(a, y)\in  M</m>. 
                Let <m>N = M \cup\{(x, y)\}</m>. 
                It is left to the reader to verify that <m>N</m> is an injective partial function from <m>A</m> to <m>B</m>, and hence that <m>N\in  P</m> . 
                Because <m>M $ N</m>, we have a contradiction to the fact that <m>M</m> is a maximal element of <m>P</m>, and so this third case cannot happen. 
              </p>
            </proof>
          </theorem>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, let <m>X \subseteq  A</m> be a subset and let <m>f : A \to B</m> be a function. 
                Suppose that <m>f</m> is injective. 
                Prove that <m>X \#  f (X)</m>.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                <ol>
                  <li>
                    <p>
                      Give an example of sets <m>A</m>, <m>B</m> and <m>C</m> such that <m>A \# B</m> and <m>A \cup C \not\# B \cup C</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>A</m>, <m>B</m> and <m>C</m> be sets. 
                      Suppose that <m>A \# B</m> and that <m>A ∩C = \es</m>  and <m>B ∩C = \es</m> .
                      Prove that <m>A \cup C \# B \cup C</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>A</m>, <m>B</m> and <m>C</m> be sets. 
                      Suppose that <m>A \cup C \# B \cup C</m> and that <m>A ∩C = \es</m>  and <m>B ∩ C = \es</m> . 
                      Is it necessarily the case that <m>A \# B</m>? 
                      Give a proof or a counterexample.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>
        
        </section>

        <section xml:id="sec-finite-countable-sets"><title>Finite and Countable Sets</title>

          <definition xml:id="def-cardinality">
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Suppose that <m>A</m> is finite. 
                The cardinality of <m>A</m>, denoted <m>|A|</m>, is defined as follows. 
                If <m>A = \es</m>, let <m>|A| = 0</m>. 
                If <m>A \neq\es</m>, let <m>|A| = n</m>, where <m>A \#\{1, \dots, n\}</m>. 
              </p>
            </statement>
          </definition>

          <corollary>
            <statement>
              <p>
                Let <m>n, m\in\N</m>. 
                Then <m>\{1, \dots, n\} \#\{1, \dots, m\}</m> if and only if <m>n = m</m>.
              </p>
            </statement>
          </corollary>

          <corollary>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Suppose that <m>A</m> and <m>B</m> are finite. 
                Then <m>A \# B</m>if and only if <m>|A| = |B|</m>.
              </p>
            </statement>
          </corollary>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Suppose that <m>A</m> is finite.
                <ol>
                  <li>
                    <p>
                      If <m>X \subseteq  A</m>, then <m>X</m> is finite.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>X \subseteq  A</m>, then <m>|A| = |X| + |A - X|</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>X $ A</m>, then <m>|X| &lt; |A|</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>X $ A</m>, then <m>X \not\#  A</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </theorem>

          <corollary xml:id="cor-infinite-subset">
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Then <m>A</m> is infinite if and only if it contains an infinite subset.
              </p>
            </statement>
          </corollary>

          <theorem xml:id="thm-countable-subsets">
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Suppose that <m>A</m> is countable. 
                If <m>X \subseteq  A</m>, then <m>X</m> is countable.
              </p>
            </statement>

            <proof>
              <p>
                Let <m>X \subseteq  A</m>.
              </p>

              <p>
                If <m>A</m> is finite, then by Theorem 6.6.5 (1) we know that <m>X</m> is finite, and hence it is countable. 
                Now assume that <m>A</m> is countably infinite. 
                We will prove the theorem for the special case that <m>A = \N</m>. 
                For the general case, we observe that if <m>A</m> is countably infinite, then there is a bijective function <m>f : A \to\N</m>, and the desired result follows from the fact that <m>X \#  f (X)</m>, which holds by Exercise 6.5.4, and that <m>f (X)</m> is a subset of <m>\N</m>.
              </p>

              <p>
                Suppose that <m>A = \N</m>. 
                If <m>X</m> is finite, then it is countable by definition, and there is nothing to prove. 
                Now suppose that <m>X</m> is infinite.
              </p>

              <p>
                By the Well-Ordering Principle (Theorem 6.2.5), there is a unique element <m>b\in  X</m> such that <m>b \leq  x</m> for all <m>x\in  X</m>. 
                Let <m>k : G(X) \to  X</m> be defined as follows. 
                Let <m>g\in  G(X)</m>. 
                Then <m>g\in  F (\{1, \dots, n\}, X)</m> for some <m>n\in\N</m>, which means that <m>g</m> is a function <m>\{1, \dots, n\} \to  X</m>. 
                It follows from Exercise 6.6.3 that <m>g</m> cannot be surjective, and hence <m>X \sm g(\{1, \dots, n\}) \neq\es</m> . 
                Using the Well-Ordering Principle again we see that there is a unique element <m>z_g\in  X \sm g(\{1, \dots, n\})</m> such that <m>z_g \leq  x</m> for all <m>x\in  X \sm g(\{1, \dots, n\})</m>.
                We then let <m>k(g) = z_g</m>.
              </p>

              <p>
                We can apply Theorem 6.4.8 to <m>b</m> and <m>k</m> as above, and we deduce that there is a unique function <m>f : \N \to  A</m> such that <m>f (1) = b</m>, and that <m>f (n + 1) = k( f_|\{1,...,n\})</m> for all <m>n\in\N</m>. 
                Hence <m>f (1) \leq  x</m> for all <m>x\in  X</m>, and if <m>n\in\N</m>, then <m>f (n + 1)\in  X \sm [ f |_{1,...,n}](\{1, \dots, n\}) = X \sm f (\{1, \dots, n\})</m>, and so <m>f (n + 1) \leq  y</m> for all <m>y\in  X \sm f (\{1, \dots, n\})</m>.
              </p>

              <p>
                Let <m>r\in\N</m>. 
                Then <m>f (r) \leq  y</m> for all <m>y\in  X \sm f (\{1, \dots, r - 1\})</m>, where we think of <m>\{1, \dots, 0\}</m> as the empty set when <m>r = 1</m>. 
                Because <m>f (r + 1)\in  X \sm f (\{1, \dots, \}) \subseteq  X - f (\{1, \dots, r - 1\})</m>, it follows that <m>f (r) &lt; f (r + 1)</m>. 
                By Exercise 6.3.4 we see that <m>f (n) ≥ n</m> for all <m>n\in\N</m>.
              </p>

              <p>
                We now show that <m>f</m> is bijective. 
                Let <m>i, j\in\N</m>. 
                Suppose that <m>i \neq  j</m>. 
                Without loss of generality assume that <m>i &lt; j</m>. 
                Then <m>i \leq  j - 1</m>, and also <m>j &gt; 1</m>, so that <m>j - 1\in\N</m>.
                It follows that <m>f (i)\in  f (\{1, \dots, j - 1\})</m>, and as observed above we know that <m>f ( j)\in  X \sm f (\{1, \dots, j - 1\})</m>. 
                Therefore <m>f (i) \neq  f ( j)</m>, and we deduce that f is injective.
              </p>

              <p>
                Let <m>m\in  X</m>. 
                Suppose that <m>m \neq  f (p)</m> for any <m>p\in\N</m>. 
                Using a previous observation we know that <m>m \leq  f(m)</m>, and hence <m>m &lt; f(m)</m>. 
                On the other hand, we saw above that <m>f(m) \leq  y</m> for all<m> y\in  X \sm f (\{1, \dots, m - 1\})</m>. 
                By hypothesis on <m>m</m> we know that <m>m \not\in  f (\{1, \dots, m - 1\})</m>, and it follows that <m>f(m) \leq  m</m>, which is a contradiction. 
                Therefore <m>f</m> is surjective.
              </p>

              <p>
                We conclude that <m>f</m> is bijective, which implies that <m>X \#\N</m>. Hence <m>X</m> is countably infinite, and therefore countable. 
              </p>
            </proof>
          </theorem>
          
          <theorem>
            <statement>
              <p>
                Let <m>A</m> be a non-empty set. The following are equivalent.
                <ol>
                  <li>
                    <p>
                      The set <m>A</m> is countable.
                    </p>
                  </li>

                  <li>
                    <p>
                      There is an injective function <m>f : A \to  N</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      There is a surjective function <m>g : N \to  A</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ul>
                  <li>
                    <p>
                      <m>(a) ⇒ (b)</m>. Suppose that <m>A</m> is countable. 
                      There are two cases, depending upon whether <m>A</m> is finite or countably infinite. 
                      If <m>A</m> is finite, there is a bijective function <m>k : A \to\{1, \dots, n\}</m> for some <m>n\in\N</m>, and hence there is an injective function <m>ˆk : A \to  N</m>, because <m>\{1, \dots, n\} \subseteq\N</m>. 
                      If <m>A</m> is countably infinite, there is a bijective function <m>h : X \to  N</m>, which is injective.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(b) ⇒ (a)</m>. 
                      Suppose that there is an injective function <m>f : A \to\N</m>. 
                      Because <m>f</m> is injective, it follows from Exercise 6.5.4 that <m>A \#  f(a)</m>. 
                      By Theorem 6.6.7 we know that <m>f(a)</m> is countable, and therefore <m>A</m> is countable.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>(b) ⇔ (c)</m>. 
                      Suppose that there is an injective function <m>f : A \to  N</m>. 
                      By Theorem 4.4.5 (2) the function <m>f</m> has a left inverse, say <m>g : N \to  A</m>. 
                      By Exercise 4.4.13 (1) we see that <m>g</m> is surjective. 
                      The other implication is proved similarly, and we omit the details.
                    </p>
                  </li>
                </ul>
              </p>
            </proof>
          </theorem>

          <theorem xml:id="thm-countable-unions-intersections">
            <statement>
              <p>
                Let <m>I</m> be a non-empty set, and let <m>\{A_i\}_{i\in I}</m> be a family of sets indexed by <m>I</m>. 
                Suppose that <m>A_i</m> is countable for each <m>i\in  I</m>.
                <ol>
                  <li>
                    <p>
                      <m>⋂_{i\in I} A_i</m> is countable.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>I</m> is countable, then <m>\bigcup _{i\in I} A_i</m> is countable.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ol>
                  <li>
                    <p>
                      Choose some <m>k\in  I</m>. Then <m>⋂i\in I Ai \subseteq  Ak</m>, and hence <m>⋂i\in I Ai</m> is countable by Theorem 6.6.7.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>A_i = \es</m>  for all <m>i\in  I</m>, then <m>\bigcup_{i\in I} A_i = \es</m>, which implies that <m>\bigcup_{i\in I} A_i</m> is finite, and hence countable. 
                      Now assume that <m>Ak \neq\es</m>  for some <m>k\in  I</m>. 
                      Because the empty set contributes nothing to a union of sets, the set <m>\bigcup  i\in I Ai</m> will not be changed if we delete from <m>I</m> those elements <m>s\in  I</m> such that <m>A_s = \es</m> . 
                      Let us assume that that has been done, and therefore that <m>A_i \neq\es</m>  for all <m>i\in  I</m>.
                    </p>

                    <p>
                      There are two cases, depending upon whether <m>I</m> is countably infinite or is finite.
                      We prove the former case, leaving the other case to the reader in Exercise 6.6.12.
                      Because we are assuming that <m>I</m> is countably infinite, without loss of generality we may assume that <m>I = \N</m>.
                    </p>

                    <p>
                      Because <m>A_i</m> is countable for all <m>i\in  I</m>, then by Theorem 6.6.8 there is a surjective function <m>f_i : N \to  A_i</m> for each <m>i\in  I</m>. 
                      Let <m>g : \N \to  \bigcup_{i\in I} A_i</m> be defined as follows. 
                      Let <m>r\in  \N</m>. 
                      We can apply Exercise 6.3.14 to the function <m>f : \N \to  \N</m> defined by <m>f (n) = (n-1)n^2</m> for all <m>n\in \ N</m>, and we deduce that there are unique <m>n, p\in  \N</m> such that 
                      <m>(n-1)n^2 &lt; r \leq n(n+1)^2</m> and <m>r = (n-1)n^2 + p</m>. 
                      Let <m>g(r) = f n-p+1(p)</m>.
                    </p>

                    <p>
                      Let <m>x\in \bigcup_{i\in I} A_i</m>. 
                      Then <m>x\in  A_k</m> for some <m>k\in I</m>. 
                      Because <m>f_k</m> is surjective, there is some <m>w\in  \N</m> such that <m>x = f_k(w)</m>. 
                      Let <m>t = k + w - 1</m>. 
                      The reader can then verify that <m>g( (t-1)t 2 + w) = f t-w+1(w) = f k(w) = x</m>. 
                      Therefore <m>g</m> is surjective, and it follows from Theorem 6.6.8 that <m>\bigcup_{i\in I} A_i</m> is countable. 
                    </p>
                  </li>
                </ol>
              </p>
            </proof>
          </theorem>

          <remark>
            <p>
              Observe that in the proof of Theorem 6.6.9 (2), we simultaneously had to choose a surjective function <m>f_i : \N \to  A_i</m> for each <m>i\in  I</m>; there really is a choice to be made, because there is more than one such function for each <m>i\in  I</m> (except when <m>A_i</m> has only one element in it). 
              Hence, we are making use of the Axiom of Choice (Theorem 4.1.5). 
              To use that axiom formally in this proof, we would let <m>S_i</m> denote the set of all surjective functions <m>N \to  A_i</m> for each <m>i\in  I</m>, and we would apply the Axiom of Choice to the family of sets <m>\{Si\}_{i\in I}</m>; we omit the details. 
              It is pointed out in [Vau95, p. 56] that any proof of Theorem 6.6.9 (2) requires the Axiom of Choice.
            </p>
          </remark>

          <theorem xml:id="thm-countable-products">
            <statement>
              <p>
                Let <m>A_1, \dots, A_n</m> be sets for some <m>n\in  \N</m>. 
                Suppose that <m>A_1, \dots, A_n</m> are countable. Then <m>A_1 \times \cdots \times  A_n</m> is countable.
              </p>
            </statement>
          </theorem>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> be a set.
                If <m>A</m> is infinite, then <m>A</m> has a countably infinite subset.
              </p>
            </statement>

            <proof>
              <p>
                Suppose that <m>A</m> is infinite. 
                By the Trichotomy Law for Sets (Theorem 6.5.13) we know that <m>\N\into A or A\into \N</m>.
              </p>

              <p>
                First, suppose that <m>\N\into A</m>. 
                Then there is an injective function <m>f : \N \to  A</m>. 
                By Exercise 6.5.4 we know that <m>\N \#  f (N)</m>. 
                Hence <m>f (\N)</m> is a countably infinite subset of <m>A</m>.
              </p>

              <p>
                Second, suppose that <m>A\into \N</m>. 
                Then there is an injective function <m>g : A \to  \N</m>. 
                By Exercise 6.5.4 again we know that <m>A \#  g(A)</m>. 
                Because <m>g(A) \subseteq  \N</m>, it follows from Theorem 6.6.7 that <m>g(A)</m> is countable. 
                Hence <m>A</m> is countable. 
                Because <m>A</m> is infinite, then it must be countably infinite, and hence A has a countably infinite subset, namely, itself.
              </p>
            </proof>
          </theorem>

          <theorem xml:id="thm-finite-characterization">
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Then <m>A</m> is finite if and only if <m>A</m> has no proper subset with the same cardinality as <m>A</m>.
              </p>
            </statement>
          </theorem>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Suppose that <m>A</m> and <m>B</m> are finite. 
                Prove that <m>A \cup B</m> is finite.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A \subseteq  \N</m> be a subset. 
                Suppose that there is some <m>M\in  N</m> such that <m>a \leq  M</m> for all <m>a\in  A</m>. 
                Prove that <m>A</m> is finite.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Prove that <m>A</m> is finite if and only if there is an injective function <m>f : A \to  \{1, \dots, n\}</m> for some <m>n\in  \N</m> if and only if there is a surjective function <m>f : \{1, \dots, n\} \to  A</m> for some <m>n\in  \N</m>.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets, and let <m>f : A \to B</m> be a function. 
                Suppose that <m>A</m> and <m>B</m> are finite sets, and that <m>|A| = |B|</m>. Prove that <m>f</m> is bijective if and only if <m>f</m> is injective if and only if <m>f</m> is surjective.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>F \subseteq  \N</m> be a set. 
                Suppose that <m>F</m> is finite and non-empty. 
                Use Theorem 6.3.11 (1) to prove that there is some <m>k\in  F</m> such that <m>p \leq  k</m> for all <m>p\in  F</m>.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>X</m> be a set. 
                Suppose that <m>X</m> is countably infinite. 
                Prove that there is a function <m>f : X \to  X</m> that is injective but not surjective.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> be a set. 
                Prove that <m>A</m> is uncountable if and only if it contains an uncountable subset.
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                Let <m>A</m> and <m>B</m> be sets. 
                Suppose that <m>A</m> and <m>B</m> are countable. 
                Prove that <m>A \times B</m> is countable.
              </p>
            </statement>
          </exercise>

        </section>

        <section xml:id="sec-cardinality-of-number-systems"><title>Cardinality of the Number Systems</title>
          
          <theorem xml:id="thm-q-countable">
            <statement>
              <p>
                The set <m>\Q</m> is countably infinite.
              </p>
            </statement>

            <proof>
              <p>
                We have just remarked that the set <m>\Z</m> is countably infinite, and hence it is countable. 
                Let <m>Z_* = \Z \sm \{0\}</m>. 
                It follows from Exercise 6.5.8 (1) that <m>\Z_*</m> is also countable. 
                By Theorem 6.6.10 we know that <m>Z \times  \Z_*</m> is countable, and it follows from Theorem 6.6.8 that there is a surjective function <m>g : \N \to  \Z \times  \Z_*</m>. Let <m>f : \Z \times  \Z_* \to  \Q</m> be defined by <m>f ((m, n)) = mn</m> for all <m>(m, n)\in  Z \times  \Z_*</m>. 
                Given that <m>\Q</m> consists of all fractions, it is evident that <m>f</m> is surjective. 
                By Lemma 4.4.4 (2) we see that <m>f \circ  g</m> is a surjective function <m>\N \to  \Q</m>. 
                Hence <m>\Q</m> is countable by Theorem 6.6.8. Because <m>\Q</m> is infinite, as previously remarked, it is therefore countably infinite. 
              </p>
            </proof>
          </theorem>

          <theorem xml:id="thm-r-uncountable">
            <statement>
              <p>
                The set <m>\R</m> is uncountable.
              </p>
            </statement>

            <proof>
              <p>
                Suppose to the contrary that <m>\R</m> is countable. 
                Because <m>\R</m> is infinite, as already observed, it must be countably infinite. 
                From Example 6.5.3 (4) we know that <m>(0, 1) \#  \R</m>, and hence <m>(0, 1)</m> must be countably infinite. 
                Let <m>f : \N \to  (0, 1)</m> be a bijective function. 
                For each <m>n\in  \N</m>, we can write <m>f (n)</m> as an infinite decimal
                f (n) = 0.a1
                n a2
                n a3
                n \dots, where the numbers a1
                n, a2
                n, a3
                n, \dots  are integers in {0, 1, \dots, 9},
                and where the expansion does not eventually become the number 9 repeating.
              </p>

              <p>
                For each k\in  N, let
                bk =
                {
                1, if a k
                k \neq  1
                2, if ak
                k = 1.
                Observe that bk \neq  ak k for all k\in  N. 
                Let b be the number represented by the decimal expansion b = 0.b1 b2 b3 \dots . 
                Because b k \neq  9 for all k\in  N, then this decimal expansion corresponds to a unique number in (0, 1). 
                We claim that b \neq  f (n) for all n\in  N.
                The decimal expansion of any real number is unique if it does not become the number 9 repeating, and therefore if two numbers have different such decimal expansions (even if the difference is by only one digit) then the two numbers are not equal. 
                For each n\in  N, the n-th digit in the decimal expansion of f (n) is a n n, whereas the n-th digit in the decimal expansion of b is b n. 
                Hence b \neq  f (n) for all n\in  N. 
                We have therefore reached a contradiction to the surjectivity of f, and we deduce that R is not countable. 
              </p>
            </proof>
          </theorem>

          <theorem xml:id="thm-irrationals-uncountable">
            <statement>
              <p>
                The set of irrational numbers has the same cardinality as <m>\R</m>.
              </p>
            </statement>
          </theorem>

          <theorem xml:id="thm-rn-cardinality">
            <statement>
              <p>
                Let <m>n\in  \N</m>. Then <m>R^n \#  R</m>.
              </p>
            </statement>
          </theorem>

          <exercise>
            <statement>
              <p>
                <ol>
                  <li>
                    <p>
                      Prove that <m>(0, 1) \times  (0, 1) \#  (0, 1)</m>. 
                      Use the fact that every real number can be expressed uniquely as an infinite decimal, if decimal expansions that eventually become the number <m>9</m> repeating are not allowed.
                    </p>
                  </li>

                  <li>
                    <p>
                      Let <m>A</m> and <m>B</m> be sets. 
                      Suppose that <m>A \#  \R</m> and <m>B \#  \R</m>. 
                      Prove that <m>A \times B \#  \R</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </exercise>

          <exercise>
            <statement>
              <p>
                This exercise is for the reader who is familiar with the complex numbers. 
                Prove that the set of complex numbers <m>\C</m> has the same cardinality as <m>\R</m>.
              </p>
            </statement>
          </exercise>

        </section>

      </chapter>

      <chapter xml:id="ch-extras"><title>Extras</title>

        <section xml:id="sec-binary-operations"><title>Binary Operations</title>

          <subsection xml:id="subsec-internal-binary-operations"><title>Internal Binary Operations</title>
          
            <definition xml:id="def-binop"><title>Binary Operation</title> 
              <statement>
                <p>
                  A <em>internal binary operation</em><idx><h>binary operation</h></idx><idx><h>operation</h></idx> on a set <m>S</m> is a <xref text="title" provisional="def-function"/>
                  <me>
                    -\cdot-:S\times S\to S,\text{given by } (x,y)\mapsto x\cdot y.
                  </me>
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                Let <m>S</m> be a set, and let <m>* : S \times S \to S</m> be a binary operation. 
                If <m>a, b\in S</m>, then it would be proper to denote the result of doing the operation <m>*</m> to the pair <m>(a, b)</m> by writing <m>*((a, b))</m>. 
                Such notation is quite cumbersome, however, and would not look like familiar binary operations such as addition of numbers. 
                Hence, we will write <m>a * b</m> instead of <m>*((a, b))</m>.
              </p>
            </convention>

            <remark>
              <p>
                Internal binary operations are usually reffered to as <q>binary operations</q> as they are the most common form of binary operation.
                <fn>The <q>internal</q> piece subtly implies the existence of some nebulous <em>external</em> binary operation, which we'll get to later.</fn>
              </p>
            </remark>

            <definition xml:id="def-closure">
              <statement>
                <p>
                  A binary operation is <term>closed</term> 
                </p>
              </statement>
            </definition>

            <example>
              <p>
                <ul>
                  <li><title>Addition</title>
                    <p>
                      The function <m>+:S\to S</m> defined by <m>+(a,b)=a+b</m> is a binary operation for <m>S\in\{\N,\Z,\Q,\R,\C\}</m>.
                    </p>
                  </li>

                  <li><title>Multiplication</title>
                    <p>
                      The function <m>\cdot:S\to S</m> defined by <m>+(a,b)=a\cdot b</m> (often shortened to <m>ab</m>) is a binary operation for <m>S\in\{\N,\Z,\Q,\R,\C\}</m>.
                    </p>
                  </li>

                  <li><title>Composition</title>
                    <p>
                      Let <m>F</m> denote the set of all functions from a set <m>S</m> to itself. The function <m>\circ:F\to F</m> defined by <m>\circ(f,g)=g\circ f</m> is a binary operation.
                    </p>
                  </li>
                </ul>
              </p>
            </example>

            <definition xml:id="def-commutative">
              <statement>
                <p>
                  A binary operation on a set <m>S</m> is <term>commutative</term> if <m>a*b=b*a</m> for all <m>a,b\in S</m>.
                </p>
              </statement>
            </definition>

            <definition xml:id="def-associative">
              <statement>
                <p>
                  A binary operation on a set <m>S</m> is <term>associative</term> if <m>(a*b)*c=a*(b*c)</m> for all <m>a,b,c\in S</m>.
                </p>
              </statement>
            </definition>

            <definition xml:id="def-idempotent">
              <statement>
                <p>
                  A binary operation on a set <m>S</m> is <term>idempotent</term> if <m>a * a=a</m> for all <m>a\in S</m>.
                </p>
              </statement>
            </definition>
            
            <definition xml:id="def-identity">
              <statement>
                <p>
                  Let <m>*</m> be a binary operation on a set <m>S</m>.
                  <ul>
                    <li>
                      <p>
                        An element <m>\ell</m> is called a <term>left identity</term> if <m>\ell * a=a</m> for all <m>a\in S</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        An element <m>r</m> is called a <term>right identity</term> if <m>r * a=a</m> for all <m>a\in S</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        An element <m>e</m> is called an <term> identity</term> if it is both a left and a right identity.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <theorem xml:id="thm-unique-identity">
              <statement>
                <p>
                  Any binary operation has at most one identity.
                </p>
              </statement>
            </theorem>

            <corollary xml:id="cor-left-right-identity">
              <statement>
                <p>
                  If an operation has both a left identity and a right identity, then these two elements are equal.
                </p>
              </statement>
            </corollary>

            <definition xml:id="def-inverse">
              <statement>
                <p>
                  Let <m>*</m> be a binary operation on a set <m>S</m> with identity <m>e</m>, and let <m>a\in S</m>.
                  <ul>
                      <li>
                        <p>
                          An element <m>b</m> is called a <term>left inverse</term> of <m>a</m> if <m>b * a=e</m>.
                        </p>
                      </li>

                      <li>
                        <p>
                          An element <m>c</m> is called a <term>right inverse</term> if <m>a * b=e</m>.
                        </p>
                      </li>

                      <li>
                        <p>
                          An element that is both a left inverse and right inverse of <m>a</m> is called an <term>inverse</term> of <m>a</m>.
                        </p>
                      </li>
                    </ul>
                </p>
              </statement>
            </definition>

            <proposition xml:id="prop-unique-associative-inverses">
              <statement>
                <p>
                  Let <m>*</m> be an associative binary operation on a set <m>S</m>.
                  <ol>
                    <li>
                      <p>
                        Any element in <m>S</m> has at most one inverse.
                      </p>
                    </li>
                    
                    <li>
                      <p>
                        If <m>a\in S</m> has a left inverse <m>b</m> and a right inverse <m>c</m>, then these <m>b=c</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
            </proposition>

          </subsection>

          <subsection xml:id="subsec-partial-binary-operations"><title>Partial Binary Operations</title>
            <definition xml:id="def-partial-function">
              <statement>
                <p>
                  A <term>partial function</term> from a set <m>X</m> to a set <m>Y</m> is a function from a subset <m>A</m> of <m>X</m> to <m>Y</m>. This is denoted <m>f:X\rightharpoonup Y</m>.
                </p>
              </statement>
            </definition>

            <definition xml:id="def-partial-binary-operation">
              <statement>
                <p>
                  A <em>partial binary operation</em><idx><h>partial binary operation</h></idx><idx><h>operation</h></idx> on a set <m>S</m> is a partial function
                  <me>
                    -*-:S\times S\to S,\text{given by } (x,y)\mapsto x * y.
                  </me>
                </p>
              </statement>
            </definition>

            <example><title>Division</title>
              <p>
                
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-external-binary-operations"><title>External Binary Operations</title>

            <definition xml:id="def-external-binary-operation">
              <statement>
                <p>
                  
                </p>
              </statement>
            </definition>
            
          </subsection>

        </section>

        <section xml:id="sec-algebraic-structures"><title>Algebraic Structures</title>

          <subsection xml:id="subsec-grouplike"><title>Grouplike Structures</title>
          
            <definition xml:id="def-magma">
              <statement>
                <p>
                  Let <m>*</m> be a binary operation on a set <m>S</m>. We define the following:
                  <ul>
                    <li>
                      <p>
                        The pair <m>(S,*)</m> is called a <term>magma</term>.
                      </p>
                    </li>

                    <li>
                      <p>
                        A <term>semigroup</term> is an associative magma.
                      </p>
                    </li>

                    <li>
                      <p>
                        A <term>monoid</term> is a semigroup with an identity element.
                      </p>
                    </li>

                    <li>
                      <p>
                        A <term>group</term> is a monoid with inverses.
                      </p>
                    </li>

                    <li>
                      <p>
                        An <term>abelian group</term> is a commutative group.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <definition xml:id="def-partial-structures">
              <statement>
                <p>
                  Let <m>*</m> be a partial binary operation on a set <m>S</m>. We define the following:
                  <ul>
                    <li>
                      <p>
                        The pair <m>(S,*)</m> is called a <term>partial magma</term>.
                      </p>
                    </li>

                    <li>
                      <p>
                        A <term>semigroupoid</term> is an associative partial magma.
                      </p>
                    </li>

                    <li>
                      <p>
                        A <term>small category</term> is a semigroupoid with an identity element.
                      </p>
                    </li>

                    <li>
                      <p>
                        A <term>groupoid</term> is a small category with inverses.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>
          </subsection>

          <subsection xml:id="subsec-ringlike"><title>Ringlike Structures</title>

            <definition xml:id="def-distributive-law">
              <statement>
                <p>
                  
                </p>
              </statement>
            </definition>
            
          </subsection>

          <subsection xml:id="subsec-latticelike"><title>Latticelike Structures</title>

            <definition xml:id="def-absorbtion-law">
              <statement>
                <p>
                  
                </p>
              </statement>
            </definition>
            
          </subsection>

        </section>

        <section xml:id="sec-posets"><title>Partially Ordered Sets</title>
          
          <definition xml:id="def-antisymmetric"><title>Antisymmetric</title>
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\preccurlyeq</m> be a relation on <m>A</m>. 
                The relation <m>\preccurlyeq</m> is <term>antisymmetric</term> if <m>x \preccurlyeq y</m> and <m>y \preccurlyeq x</m> imply that <m>x = y</m>, for all <m>x, y\in  A</m>
              </p>
            </statement>
          </definition>

          <definition xml:id="def-poset"><title>Poset</title>
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\preccurlyeq</m> be a relation on <m>A</m>.
                The relation <m>\preccurlyeq</m> is a <term>partial ordering</term> (also called a <term>partial order</term>) if it is reflexive, transitive and antisymmetric. 
                If <m>\preccurlyeq</m> is a partial ordering, the pair <m>(A, \preccurlyeq)</m> is a partially ordered set, often abbreviated as <term>poset</term>.
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    Let <m>A</m> be a set. 
                    Then <m>(P(A), \subseteq )</m> is a poset but not a totally ordered set, as mentioned previously.
                  </p>
                </li>

                <li>
                  <p>
                    Divisibility in <m>\N</m> is a poset.
                  </p>
                </li>
              </ul>
              
            </p>
          </example>

          <definition xml:id="def-toset"><title>Toset</title>
            <statement>
              <p>
                Let <m>A</m> be a non-empty set, and let <m>\preccurlyeq</m> be a relation on <m>A</m>.
                The relation <m>\preccurlyeq</m> is a <term>total ordering</term> (also called a <term>total order</term> or linear ordering) if it is a partial ordering, and if for every <m>a, b\in  A</m>, at least one of a <m>\preccurlyeq b</m> or <m>b \preccurlyeq a</m> holds. 
                If <m>\preccurlyeq</m> is a total ordering, the pair <m>(A, \preccurlyeq)</m> is a <term>totally ordered set</term>. 
              </p>
            </statement>
          </definition>

          <remark>
            <p>
              Formally, a poset is a pair <m>(A, \preccurlyeq)</m>. 
              However, when the relation <m>\preccurlyeq</m> is understood from the context, or it is not important to designate the symbol for the relation, we will simply say “let <m>A</m> be a poset.” 
              Similarly for totally ordered sets.
            </p>
          </remark>

          <example>
            <p>Each of the sets <m>\N, \Z, \Q</m> and <m>\R</m> with the relation <m>\leq </m> is a totally ordered set.</p>
          </example>

          <definition xml:id="def-covers"><title>Cover</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset, and let <m>a, b\in  A</m>. 
                The element <m>b</m> <term>covers</term> the element <m>a</m> if <m>a \preccurlyeq b</m>, and <m>a \neq b</m>, and there is no <m>x\in  A</m> such that <m>a \preccurlyeq x \preccurlyeq b</m> and <m>a \neq  x \neq b</m>.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-greatest-least-element"><title>Greatest, Least Element</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset, and let <m>a\in  A</m>. 
                The element <m>a</m> is a <term>greatest element</term> of <m>A</m> if <m>x \preccurlyeq a</m> for all <m>x\in  A</m>. 
                The element <m>a</m> is a <term>least element</term> of <m>A</m> if <m>a \preccurlyeq x</m> for all <m>x\in  A</m>. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              The poset <m>(\Z, \leq )</m> has no greatest element or least element. 
              Even finite posets need not have greatest elements or least elements. 
              For example, the poset in Example 7.4.4 (1) does not have a greatest element; observe that <m>12</m> is not a greatest element with respect to the relation <m>a|b</m>, because <m>10</m> does not divide <m>12</m>.
              The poset <em>does</em> have a least element, the number <m>2</m>, because <m>2</m> divides all the other numbers in the set. 
            </p>
          </example>

          <definition xml:id="def-maximal-minimal-element"><title>Maximal, Minimal Element</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset, and let <m>a\in  A</m>. 
                The element a is a <term>maximal element</term> of <m>A</m> if there is no <m>x\in  A</m> such that <m>a \preccurlyeq x</m> and <m>a \neq  x</m>. 
                The element <m>a</m> is a <term>minimal element</term> of <m>A</m> if there is no <m>x\in  A</m> such that <m>x \preccurlyeq a</m> and <m>a \neq  x</m>.
              </p>
            </statement>
          </definition>

          <example>
            <p>
              The poset <m>(\Z, \leq )</m> has no maximal element or minimal element. 
              Let <m>(A, \preccurlyeq)</m> be the poset in Example 7.4.4 (1). 
              The elements <m>8</m>, <m>10</m> and <m>12</m> are all maximal elements, which shows that maximal elements need not be unique, and also that maximal elements need not be greatest elements. 
              The element <m>2</m> is a minimal element, which also happens to be a least element. 
            </p>
          </example>

          <theorem xml:id="thm-finite-maximal-minimal">
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset. 
                Suppose that <m>A</m> is finite. Then <m>A</m> has a maximal element and a minimal element.
              </p>
            </statement>

            <proof>
              <p>
                We will prove the existence of maximal elements; the existence of minimal elements is similar, and we omit the details. 
                Let <m>n = |A|</m>. We proceed by induction on <m>n</m>. 
                If <m>n = 1</m>, then the single element of <m>A</m> is clearly a maximal element. 
                Now assume that <m>n \geq   2</m>. 
                Suppose that the result is true for <m>n - 1</m>. 
                Let <m>w\in  A</m>, and let <m>B = A - \{w\}</m>.
                By Exercise 7.4.8 we know that <m>(B, \preccurlyeq)</m> is a poset. 
                Because |<m>B| = n - 1</m>, it follows from the inductive hypothesis that there is a maximal element <m>p</m> of <m>B</m>. 
                We now define <m>r\in  A</m> as follows. 
                If <m>p \preccurlyeq w</m>, let <m>r = w</m>; if it is not the case that <m>p \preccurlyeq w</m>, then let <m>r = p</m>.
                We claim that <m>r</m> is a maximal element of <m>A</m>. 
                There are two cases. 
                First, suppose that <m>p \preccurlyeq w</m>. 
                Then <m>r = w</m>. 
                Suppose that there is some <m>y\in  A</m> such that <m>w \preccurlyeq y</m> and <m>w \neq  y</m>. 
                By transitivity it follows that <m>p \preccurlyeq y</m>, and by antisymmetry it follows that <m>p \neq y</m>. 
                Because <m>y \neq  w</m>, then <m>y\in B</m>, and we then have a contradiction to the fact that <m>p</m> is a maximal element of <m>B</m>. 
                It follows that <m>w</m> is a maximal element of <m>A</m>. 
                Second, suppose that it is not the case that <m>p \preccurlyeq w</m>. 
                Then <m>r = p</m>. 
                Because <m>p</m> is a maximal element of <m>B</m>, then there is no <m>x\in B</m> such that <m>p \preccurlyeq x</m> and <m>p \neq  x</m>. 
                It follows that there is no <m>x\in  A = B \cup\{w\}</m> such that <m>p \preccurlyeq x</m> and <m>p \neq  x</m>, and hence <m>p</m> is a maximal element of <m>A</m>. 
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-poset-bounds"><title>Poset Bounds</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset, let <m>X \subseteq  A</m> be a subset and let <m>a\in  A</m>. 
                The element <m>a</m> is an <term>upper bound</term> of <m>X</m> if <m>x \preccurlyeq a</m> for all <m>x\in  X</m>. 
                The element <m>a</m> is a <term>least upper bound</term> of <m>X</m> if it is an upper bound of <m>X</m>, and <m>a \preccurlyeq z</m> for any other upper bound <m>z of X</m>. 
                The element <m>a</m> is a <term>lower bound</term> of <m>X</m> if <m>a \preccurlyeq x</m> for all <m>x\in  X</m>. 
                The element <m>a</m> is a <term>greatest lower bound</term> for <m>X</m> if it is a lower bound of <m>X</m>, and <m>w \preccurlyeq a</m> for any other lower bound <m>w of X</m>. 
              </p>
            </statement>
          </definition>

          <lemma xml:id="lem-unique-bounds"><title>Uniqueness of Poset Bounds</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset, and let <m>X \subseteq  A</m> be a subset. 
                If <m>X</m> has a least upper bound, then it is unique, and if <m>X</m> has a greatest lower bound, then it is unique.
              </p>
            </statement>

            <proof>
              <p>
                Let <m>p, q\in  A</m>, and suppose that both are least upper bounds of <m>X</m>. 
                By definition both <m>p</m> and <m>q</m> are upper bounds for <m>X</m>. 
                Because <m>p</m> is a least upper bound of <m>X</m>, and <m>q</m> is an upper bound of <m>X</m>, then <m>p \preccurlyeq q</m> by the definition of least upper bounds. 
                Similarly, we see that <m>q \preccurlyeq p</m>. 
                By antisymmetry, it follows that <m>p = q</m>. 
                A similar argument works for greatest lower bounds; we omit the details. 
              </p>
            </proof>
          </lemma>

          <theorem xml:id="thm-poset-to-toset"><title>Poset Extension Theorem</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset. 
                Suppose that <m>A</m> is finite. 
                Then there is a total ordering <m>\preccurlyeq'</m> on A such that if <m>x \preccurlyeq y</m> then <m>x \preccurlyeq' y</m>, for all <m>x, y\in  A</m>.
              </p>
            </statement>

            <proof>
              <p>
                Let <m>n = |A|</m>. 
                We proceed by induction on <m>n</m>. 
                If <m>n = 1</m> the result is trivial.
                Now assume that <m>n \geq 2</m>. 
                Suppose that the result is true for <m>n - 1</m>. 
                By Theorem 7.4.9 the poset <m>A</m> has a maximal element, say <m>r\in  A</m>. 
                Let <m>B = A \sm \{r\}</m>. 
                By Exercise 7.4.8 we know that <m>(B, \preccurlyeq)</m> is a poset. 
                Because <m>|B| = n - 1</m>, it follows from the inductive hypothesis that there is a total ordering <m>\preccurlyeq''</m> on <m>B</m> such that if <m>x \preccurlyeq y</m> then <m>x \preccurlyeq'' y</m>, for all <m>x, y\in B</m>. 
                Now define a relation <m>\preccurlyeq'</m> on <m>A</m> as follows. 
                If <m>x, y\in B</m>, let <m>x \preccurlyeq' y</m> if and only if <m>x \preccurlyeq'' y</m>. 
                If <m>x\in  A</m>, let <m>x \preccurlyeq' r</m>. 
                It is left to the reader in Exercise 7.4.9 to show that <m>\preccurlyeq'</m> is a total order on <m>A</m>, and that if <m>x \preccurlyeq y</m> then <m>x \preccurlyeq' y</m>, for all <m>x, y\in  A</m>. 
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-order-homomorphism"><title>Order Homomorphism</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> and <m>(B, \preccurlyeq')</m> be posets, and let <m>f : A \to B</m> be a function. 
                The function <m>f</m> is an <term>order homomorphism</term> (also called an <term>order preserving function</term>) if <m>x \preccurlyeq y</m> implies <m>f (x) \preccurlyeq' f (y)</m>, for all <m>x, y\in  A</m>.
                The function <m>f</m> is an <term>order isomorphism</term> if it is bijective, and if both <m>f</m> and <m>f\inv</m> are order homomorphisms.

              </p>
            </statement>
          </definition>

          <theorem xml:id="thm-finite-toset-classification"><title>Finite Toset Classification Theorem</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a totally ordered set. 
                Suppose that <m>A</m> is finite. 
                Let <m>n = |A|</m>. 
                Then there is an order isomorphism from <m>(A, \preccurlyeq)</m> to <m>(\{1, 2,\dots, n\}, \leq )</m>.
              </p>
            </statement>

            <proof>
              <p>
                We follow [KR83a]. 
                We prove the result by induction on <m>n</m>. 
                When <m>n = 1</m> the result is trivial. 
                Now assume that <m>n \geq 2</m>. 
                Suppose that the result holds for <m>n - 1</m>.
                By Theorem 7.4.9 the poset <m>A</m> has a maximal element, say <m>r\in  A</m>. Let <m>x\in  A</m>.
                Because <m>\preccurlyeq</m> is a total ordering, we know that <m>x \preccurlyeq r</m> or <m>r \preccurlyeq x</m>. 
                If it were the case that <m>r \preccurlyeq x</m>, then by hypothesis on <m>r</m> we would know that <m>r = x</m>. 
                Hence <m>x \preccurlyeq r</m>.
                Let <m>B = A \sm \{r\}</m>. 
                By Exercise 7.4.8 we know that <m>(B, \preccurlyeq)</m> is a poset. 
                Because <m>|B| = n - 1</m>, it follows from the inductive hypothesis that there is an order isomorphism from <m>(B, \preccurlyeq)</m> to <m>(\{1, 2,\dots, n - 1\}, \leq )</m>, say <m>f : B \to\{1, 2,\dots, n - 1\}</m>. 
                Let <m>F : A \to\{1, 2,\dots, n\}</m> be defined by <m>F(x) = f (x)</m> for all <m>x\in B</m>, and <m>F(r) = n</m>.
                Because <m>f</m> is bijective, it is straightforward to see that <m>F</m> is bijective as well; we omit the details. 
                To see that <m>F</m> is an order isomorphism, it suffices by Lemma 7.4.16 to show that <m>x \preccurlyeq y</m> if and only if <m>F(x) \leq  F(y)</m>, for all <m>x, y\in  A</m>. 
                First, let <m>x, y\in B</m>. 
                Then <m>x \preccurlyeq y</m> if and only if <m>f (x) \leq  f (y)</m> because <m>f</m> is an order isomorphism. 
                Because <m>F(x) = f (x)</m> and <m>F(y) = f (y)</m>, then <m>x \preccurlyeq y</m> if and only if <m>F(x) \leq  F(y)</m>. 
                Now let <m>z\in B</m>. 
                We know that <m>z \preccurlyeq r</m>, and we also know that <m>F(z) \leq  n = F(r)</m>, because <m>F(z)\in\{1, 2,\dots, n - 1\}</m>.
                Hence <m>z \preccurlyeq r</m> if and only if <m>F(z) \leq  F(r)</m>, because both these statements are true. 
                It follows that <m>F</m> is an order isomorphism. 
              </p>
            </proof>
          </theorem>
      
        </section>   

        <section xml:id="sec-lattices"><title>Lattices</title>

          <definition xml:id="def-meet-join"><title>Meet, Join</title>
            <statement>
              <p>
                Let <m>(A, \preccurlyeq)</m> be a poset. 
                Let <m>a, b\in  A</m>. 
                The <term>join</term> of <m>a</m> and <m>b</m>, denoted <m>a \wedge b</m>, is the least upper bound of <m>\{a, b\}</m>, if the least upper bound exists; the join is not defined if the least upper bound does not exist. 
                The <term>meet</term> of <m>a</m> and <m>b</m>, denoted <m>a \wedge  b</m>, is the greatest lower bound of <m>\{a, b\}</m>, if the greatest lower bound exists; the meet is not defined if the greatest lower bound does not exist.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-lattice"><title>Lattice</title>
            <statement>
              <p>
                A poset <m>(A, \preccurlyeq)</m> is a <term>lattice</term> if <m>a \wedge b</m> and <m>a \wedge b</m> exist for all <m>a, b\in  A</m>. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ul>
                <li>
                  <p>
                    The sets <m>\N, \Z, \Q</m> and <m>\R</m> with the relation <m>\leq </m> are all lattices. 
                    We know from Example 7.4.2 (3) that these sets with the relation <m>\leq </m> are all posets. 
                    Let <m>x</m> and <m>y</m> be two numbers in any one of these sets. 
                    If <m>x = y</m> then <m>x \wedge   y = x = y</m> and <m>x \wedge  y = x = y</m>; if <m>x \neq  y</m>, then <m>x \wedge   y</m> is the smaller of the two numbers, and <m>x \wedge  y</m> is the larger. 
                    More generally, any totally ordered set is a lattice, by the same argument.
                  </p>
                </li>

                <li>
                  <p>
                    Let <m>A</m> be a set. 
                    The poset <m>(\cP(A), \subseteq )</m> is a lattice. 
                    If <m>X,Y\in\cP(A)</m>, then <m>X \wedge  Y = X \cap Y</m> and <m>X \wedge Y = X \cup Y</m>.
                  </p>
                </li>

                <li>
                  <p>
                    As shown in Example 7.4.2 (5), the set <m>\N</m> with the relation “<m>a|b</m>” is a poset.
                    This poset is a lattice. 
                    If <m>a, b\in\N</m>, then <m>a \wedge b</m> is the greatest common divisor of <m>a</m> and <m>b</m>, and <m>a \wedge b</m> is the least common multiple.
                  </p>
                </li>
              </ul>
            </p>
          </example>

          <theorem>
            <statement>
              <p>
                Let <m>(L, \preccurlyeq)</m> be a lattice, and let <m>x, y, z\in  L</m>.
                <ol>
                  <li>
                    <p>
                      <m>x \wedge   x = x</m> and <m>x \vee  x = x</m> (Idempotent Laws).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>x \wedge   y = y \wedge   x</m> and <m>x \vee  y = y \vee  x</m> (Commutative Laws).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>x \wedge   (y \wedge   z) = (x \wedge y) \wedge z</m> and <m>x \vee  (y \vee  z) = (x \vee  y) \vee  z</m> (Associative Laws).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>x \wedge   (x \vee  y) = x</m> and <m>x \vee  (x \wedge   y) = x</m> (Absorption Laws).
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>x\preccurlyeq y</m> if and only if <m>x \wedge   y = x</m> if and only if <m>x \vee  y = y</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>x\preccurlyeq y</m>, then <m>x \wedge   z\preccurlyeq y \wedge   z</m> and <m>x \vee  z\preccurlyeq y \vee  z</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                Coming soon!
              </p>
            </proof>
          </theorem>

          <theorem>
            <statement>
              <p>
                Let <m>A</m> be a set, and let <m>u : A \times  A \to  A</m> and <m>t : A \times  A \to  A</m> be binary operations on <m>A</m>. 
                Suppose that <m>\sqcup</m> and <m>\sqcap</m> satisfy the following properties. Let <m>x, y, z\in A</m>.
                <ol>
                  <li>
                    <p>
                      <m>x\sqcup y = y\sqcup x</m> and <m>x\sqcap y = y\sqcap x</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>x\sqcup (y\sqcup z) = (x\sqcup y)\sqcup z</m> and <m>x\sqcap (y\sqcap z) = (x\sqcap y)\sqcap z</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>x\sqcup (x\sqcap y) = x</m> and <m>x\sqcap (x\sqcup y) = x</m>.
                    </p>
                  </li>
                </ol>
                Let <m>\preccurlyeq</m> be the relation on <m>A</m> defined by <m>x\preccurlyeq y</m> if and only <m>if x\sqcup y = x</m>, for all <m>x, y\in  A</m>. 
                Then <m>(A, \preccurlyeq)</m> is a lattice, with <m>\sqcup</m> and <m>\sqcap</m> the meet and join of the lattice, respectively.
              </p>
            </statement>

            <proof>
              <p>
                We follow [Bir48] and [LP98] in part. 
                As a preliminary, we prove the following two facts: 
                (1) <m>x\sqcup x = x</m> for all <m>x\in  A</m>; and 
                (2) <m>x\sqcup y = x</m> if and only if <m>x\sqcap y = y</m>, for all <m>x, y\in  A</m>. 
                Let <m>x, y, z\in  A</m>. 
                Using both parts of Property (c), we see that <m>x\sqcup x = x\sqcup (x\sqcap (x\sqcup x)) = x</m>, which proves Fact (1). 
                Suppose that <m>x\sqcup y = x</m>. 
                Then by Properties (a) and (c) we see that <m>x\sqcap y = (x\sqcup y)\sqcap y = y\sqcap (y\sqcup x) = y</m>, which proves one of the implications in Fact (2); a similar argument proves the other implication, and we omit the details.
              </p>

              <p>
                We now show that <m>(A, \preccurlyeq)</m> is a poset. 
                Because <m>x\sqcup x = x</m> by Fact (1), it follows from the definition of <m>\preccurlyeq</m> that <m>x\preccurlyeq x</m>. 
                Hence <m>\preccurlyeq</m> is reflexive. 
                Now suppose that <m>x\preccurlyeq y</m> and <m>y\preccurlyeq z</m>. 
                Then <m>x\sqcup y = x</m> and <m>y\sqcup z = y</m>. 
                By Property (b) we see that <m>x\sqcup z = (x\sqcup y)\sqcup z = x\sqcup (y\sqcup z) = x\sqcup y = x</m>. 
                It follows that <m>x\preccurlyeq z</m>. 
                Therefore <m>\preccurlyeq</m> is transitive. 
                Next, suppose that <m>x\preccurlyeq y</m> and <m>y\preccurlyeq x</m>. 
                Then <m>x\sqcup y = x</m> and <m>y\sqcup x = y</m>. 
                It follows from Property (a) that <m>x = y</m>. 
                Therefore <m>\preccurlyeq</m> is antisymmetric. 
                We conclude that <m>(A, \preccurlyeq)</m> is a poset.
              </p>

              <p>
                Finally, we show that <m>\sqcup</m> and <m>\sqcap</m> are the meet and join of <m>(A, \preccurlyeq)</m>, respectively. 
                It will then follow from this fact that meet and join always exist for any two elements of <m>A</m>, and hence <m>(A, \preccurlyeq)</m> is a lattice. 
                We start with <m>\sqcup</m>. 
                Using Property (b) and Fact (1) we see that <m>(x\sqcup y)\sqcup y = x\sqcup (y\sqcup y) = x\sqcup y</m>. 
                Hence <m>x\sqcup y\preccurlyeq y</m>. 
                Because <m>x\sqcup y = y\sqcup x</m> by Property (a), a similar argument shows that <m>x\sqcup y\preccurlyeq x</m>. 
                Therefore <m>x\sqcup y</m> is a lower bound of <m>\{x, y\}</m>. 
                Now suppose that <m>z\in A</m> is a lower bound of <m>\{x, y\}</m>. 
                Then <m>z\preccurlyeq x</m> and <m>z\preccurlyeq y</m>, and therefore <m>z\sqcup x = z</m> and <m>z\sqcup y = z</m>. 
                By Property (b) we see that <m>z\sqcup (x\sqcup y) = (z\sqcup x)\sqcup y = z\sqcup y = z</m>. 
                Hence <m>z\preccurlyeq (x\sqcup y)</m>. 
                It follows that <m>x\sqcup y</m> is the greatest lower bound of <m>\{x, y\}</m>, which means that <m>x\sqcup y</m> is the meet of <m>x</m> and <m>y</m>.
              </p>

              <p>
                We now turn to <m>\sqcap</m>. 
                By Property (c) we know that <m>x\sqcup (x\sqcap y) = x</m>. 
                Hence <m>x\preccurlyeq x\sqcap y</m>. 
                Because <m>x\sqcap y = y\sqcap x</m> by Property (a), a similar argument shows that <m>y\preccurlyeq x\sqcap y</m>. 
                Hence <m>x\sqcap y</m> is an upper bound of <m>\{x, y\}</m>. 
                Now suppose that <m>w\in  A</m> is an upper bound of <m>\{x, y\}</m>. 
                Then <m>x\preccurlyeq w</m> and <m>y\preccurlyeq w</m>, and therefore <m>x\sqcup w = x</m> and <m>y\sqcup w = y</m>. 
                By Fact (2) we deduce that <m>x\sqcap w = w</m> and <m>y\sqcap w = w</m>. 
                Property (b) then implies that <m>(x\sqcap y)\sqcap w = x\sqcap (y\sqcap w) = x\sqcap w = w</m>. 
                Hence <m>(x\sqcap y)\sqcup w = x\sqcap y</m> by Fact (2). 
                Therefore <m>x\sqcap y \preccurlyeq w</m>. 
                It follows that <m>x\sqcap y</m> is the least upper bound of <m>\{x, y\}</m>, which means that <m>x\sqcap y</m> is the join of <m>x and y</m>.
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-meet-join-homomorphism">
            <statement>
              <p>
                Let <m>(L, \preccurlyeq)</m> and <m>(M, \preccurlyeq′)</m> be lattices, and let <m>f : L \to  M</m> be a function. 
                Let <m>\wedge</m> and <m>\vee</m> be the meet and join for <m>L</m>, and let <m>\wedge  ′</m> and <m>\vee ′</m> be the meet and join for <m>M</m>. 
                The function <m>f</m> is a meet homomorphism if <m>f (x \wedge   y) = f (x) \wedge  ′ f (y)</m> for all <m>x, y\in  L</m>. 
                The function <m>f</m> is a join homomorphism if <m>f (x \vee  y) = f (x) \vee ′ f (y)</m> for all <m>x, y\in  L</m>. 
              </p>
            </statement>
          </definition>

          <example>
            <p>
              <ol>
                <li>
                  <p>
                    The function <m>f : D \to\cP(A)</m> in Example 7.4.17 (2) is both a meet homomorphism and a join homomorphism, as the reader can verify.
                  </p>
                </li>

                <li>
                  <p>
                    The function <m>s : PF (N) \to  Z</m> in Example 7.4.17 (1) is an order homomorphism, as was stated in that example. 
                    However, this function is neither a meet homomorphism nor a join homomorphism. 
                    For example, let <m>X = \{5, 7\}</m>, and let <m>Y = \{7, 9\}</m>. Then, as in Example 7.5.2 (2), we see that <m>X \wedge  Y = X \cap Y = \{7\}</m>, and <m>X \vee Y = X \cup Y = \{5, 7, 9\}</m>. 
                    Hence <m>s(X \wedge   Y ) = 1</m> and <m>s(X \vee  Y ) = 3</m>. 
                    However, as discussed in Example 7.5.2 (1), we see that <m>s(X) \wedge   s(Y ) = 2 \wedge   2 = 2</m>, and <m>s(X) \vee  s(Y ) = 2 \vee  2 = 2</m>.
                    Hence <m>s(X \wedge  Y ) \neq  s(X) \wedge   s(Y )</m> and <m>s(X \vee Y ) \neq  s(X) \vee  s(Y )</m>.
                  </p>
                </li>
              </ol>
            </p>
          </example>

          <theorem>
            <statement>
              <p>
                Let <m>(L, \preccurlyeq)</m> and <m>(M, \preccurlyeq′)</m> be lattices, and let <m>f : L \to  M</m> be a function.
                <ol>
                  <li>
                    <p>
                      If <m>f</m> is a meet homomorphism or a join homomorphism, then it is an order homomorphism.
                    </p>
                  </li>

                  <li>
                    <p>
                      If <m>f</m> is bijective and a meet (respectively, join) homomorphism, then <m>f\inv</m> is a meet (respectively, join) homomorphism.
                    </p>
                  </li>

                  <li>
                    <p>
                      The function <m>f</m> is an order isomorphism if and only if <m>f</m> is bijective and a meet homomorphism if and only if <m>f</m> is bijective and a join homomorphism.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                <ol>
                  <li>
                    <p>
                      Suppose that <m>f</m> is a meet homomorphism. 
                      Let <m>\wedge   and \wedge′</m> denote the meet for <m>L</m> and <m>M</m>, respectively. 
                      Let <m>x, y\in  L</m>. 
                      Suppose that <m>x\preccurlyeq y</m>. 
                      Then by Theorem 7.5.3 (6) we know that <m>x = x \wedge y</m>. 
                      Then <m>f (x) = f (x \wedge y) = f (x) \wedge ′ f (y)</m>, because <m>f</m> is a meet homomorphism. 
                      Using Theorem 7.5.3 (6) again, we deduce that <m>f (x) \preccurlyeq′ f (y)</m>. 
                      It follows that <m>f</m> is an order homomorphism. 
                      A similar argument works if <m>f</m> is a join homomorphism; we omit the details. 
                    </p>
                  </li>
                </ol>
              </p>
            </proof>
          </theorem>

          <theorem>
            <statement>
              <p>
                Let <m>(L, \preccurlyeq)</m> be a lattice, and let <m>f : L \to  L</m> be an order homomorphism. 
                Suppose that the least upper bound and greatest lower bound exist for all non-empty subsets of <m>L</m>. 
                Then there is some <m>a\in  L</m> such that <m>f(a) = a</m>.
              </p>
            </statement>

            <proof>
              <p>
                Let <m>C = \{x\in  L | x\preccurlyeq f (x)\}</m>. 
                Observe that <m>L</m> is non-empty because it is a poset, and all posets are assumed to be non-empty. 
                Let <m>m</m> be the greatest lower bound of <m>L</m>, which exists by hypothesis. 
                Then <m>m</m> is a lower bound of <m>L</m>, and therefore <m>m\preccurlyeq x</m> for all <m>x\in  L</m>. 
                In particular, we see that <m>m\preccurlyeq f(m)</m>. 
                It follows that <m>m\in  C</m>, and so <m>C</m> is non-empty.
              </p>

              <p>
                Let <m>a</m> be the least upper bound of <m>C</m>. 
                Let <m>x\in  C</m>. 
                Then <m>a</m> is an upper bound of <m>C</m>, and therefore <m>x\preccurlyeq a</m>. 
                Using the definition of <m>C</m> and the fact that <m>f</m> is an order homomorphism, we deduce that <m>x\preccurlyeq f (x)\preccurlyeq f(a)</m>. 
                It follows that <m>f(a)</m> is an upper bound for <m>C</m>. 
                Because <m>a</m> is the least upper bound of <m>C</m>, we deduce that <m>a\preccurlyeq f(a)</m>.
                Because <m>f</m> is an order homomorphism, it follows that <m>f(a)\preccurlyeq f ( f(a))</m>. 
                Hence <m>f(a)\in C</m>, and therefore <m>f(a)\into a</m>, because <m>a</m> is an upper bound of <m>C</m>. 
                By antisymmetry, we deduce that <m>f(a) = a</m>. 
              </p>
            </proof>
          </theorem>

          <corollary>
            <statement>
              <p>
                Let <m>(L, \preccurlyeq)</m> be a lattice, and let <m>f : L \to  L</m> be an order homomorphism. 
                If <m>L</m> is finite, then there is some <m>a\in L</m> such that <m>f(a) = a</m>.
              </p>
            </statement>
          </corollary>
          

        </section>

        <section xml:id="sec-axioms"><title>Axioms for Set Theory</title>

          <axiom xml:id="axiom-">
            <statement>
              <p>
                
              </p>
            </statement>
          </axiom>

        </section>


      </chapter>

    </part>

    <backmatter xml:id="backmatter"><title>Backmatter</title>

      <colophon>
        <p> This book was authored in <pretext />. </p>
      </colophon>

    </backmatter>

  </book>
</pretext>
